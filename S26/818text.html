<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Math 818: Introduction to Modern Algebra II (Spring 2026)</title>
<!-- MathJax (accessible by default) -->
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<style>
    :root{
      --accent:#1f2937; /* dark gray (good contrast) */
      --bg-soft:#f5f5f5; /* soft background for callouts */
      --border:#374151;  /* darker border for AA contrast */
      --link:#800000;    /* UNL scarlet */
      --text:#111827;    /* near-black text */
      --muted:#4b5563;   /* muted headings */
      --focus:#ffbf47;   /* high-contrast focus outline */
    }
    html:focus-within { scroll-behavior: smooth; }
    body{
      margin:0;
      color:var(--text);
      background:#fff;
     font-family: Baskerville, "Times New Roman", Times, serif;
     line-height:1.6;
    }
    a{ color:var(--link); }
    a:focus, button:focus, [tabindex]:focus{
      outline:3px solid var(--focus);
      outline-offset:2px;
    }
    .container{
      max-width: 900px;
      margin: 0 auto;
      padding: 1rem 1rem 3rem;
    }
    /* Skip link */
    .skip-link{
      position:absolute; left:-999px; top:auto; width:1px; height:1px; overflow:hidden;
    }
    .skip-link:focus{
      position:static; width:auto; height:auto; padding:.5rem .75rem; background:#000; color:#fff;
      display:inline-block; margin: .5rem 1rem;
    }

    header[role="banner"]{
      padding: 2rem 0 1rem;
      border-bottom: 2px solid var(--border);
    }
    header h1{
      margin:.25rem 0 0;
      font-family: "Helvetica Neue", Arial, sans-serif;
      font-weight: 700;
      line-height:1.25;
    }
    header p{
      margin: .25rem 0 0;
      color: var(--muted);
      font-family: "Helvetica Neue", Arial, sans-serif;
    }

    nav[aria-label="Table of contents"]{
      padding: 1rem 0 1rem;
      border-bottom: 1px solid var(--border);
    }
    nav[aria-label="Table of contents"] ul{
      margin:.25rem 0 0 1rem;
    }

    main h2, main h3{
      font-family: "Helvetica Neue", Arial, sans-serif;
      line-height:1.3;
    }
    main h2{ margin-top: 2rem; }
    main h3{ margin-top: 1.5rem; }

    /* Callout blocks */
    .callout{
      background: var(--bg-soft);
      border-left: 6px solid var(--border);
      padding: 1rem;
      margin: 1rem 0;
    }
    .callout h3{
      margin: 0 0 .5rem;
    }
    .callout p{ margin: .5rem 0; }

    blockquote{
      border-left: 6px solid var(--border);
      padding: .5rem 1rem;
      background: #fafafa;
      margin: 1rem 0;
      font-style: italic;
    }

    /* Math blocks helper (optional role hook) */
    .math-display{ margin: .75rem 0; }
    .visually-hidden{
      position:absolute !important;
      height:1px; width:1px;
      overflow:hidden; clip:rect(1px,1px,1px,1px);
      white-space:nowrap; border:0; padding:0; margin:-1px;
    }
    /* Link styles inside callouts for better contrast */
    .callout a{ text-decoration: underline; }

    /* Lists spacing */
    ul, ol{ padding-left: 1.25rem; }
  </style>


<style>
    .shapes-container {
      display: flex;
      justify-content: center;
      gap: 2rem; /* space between shapes */
      margin-top: 2rem;
    }
    figure {
      text-align: center;
    }
    svg {
      display: block;
      margin: 0 auto;
    }
  </style>

</head>
<body>
<a class="skip-link" href="#main-content">Skip to main content</a>
<div class="container">
<header role="banner">
<h1 id="page-title">Math 818: Introduction to Modern Algebra II (Spring 2026)</h1>
<p aria-label="Author">Instructor: Jack Jeffries</p>
</header>




















<!-- Table of contents (manual, descriptive, navigable) -->
<nav aria-label="Table of contents">
<h2 id="toc">Contents</h2>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#modules">An introduction to modules</a></li>
<ol start=11><li><a href="#sec-11">Modules</a></li>
<ol><li><a href="#sec-11-1-heading">Definitions and first examples</a></li>
<li><a href="#sec-11-2-heading">Submodules and restriction of scalars</a></li>
<li><a href="#sec-11-3-heading">Module homomorphisms and isomorphisms</a></li>
<li><a href="#sec-11-4-heading">Module generators, bases and free modules</a></li>
</ol>
<li><a href="#sec-12">Vector spaces</a></li>
<ol><li><a href="#sec-12-1-heading">Classification of vector spaces and dimension</a></li>
<li><a href="#sec-12-2-title">Linear transformations and homomorphisms between free modules</a></li>
<li><a href="#sec-12-3-title">Change of basis</a></li>
<li><a href="#sec-12-4-title">Determinants</a></li>
</ol>
<li><a href="#sec-13">Finitely generated modules over PIDs</a></li>
<ol><li><a href="#sec-13-1-heading">The module presented by a matrix</a></li>
<li><a href="#sec-13-2-title">Existence of presentations</a></li>
<li><a href="#sec-13-3-title">Classification of finitely generated modules over PIDs</a></li>
</ol>

</ol>
</ul></nav>












































<main aria-labelledby="page-title" id="main-content" role="main">
<section aria-labelledby="intro-heading" id="introduction">
<h1 id="intro-heading">Introduction</h1>
<p>
          These are the lecture notes and class materials for Math 818 Introduction to Modern Algebra II
          in Spring 2026. This is the second part of a two-part course on groups, rings, modules, and fields.
          In this second half, we will discuss module theory, with a focus on the structure theory of modules over PIDs and applications to linear algebra, field theory, and Galois theory.
          A major goal of this course is to prepare graduate students for the PhD qualifying exam in algebra.
        </p>

<p> The lecture notes for Math 817 Introduction to Modern Algebra I can be found here:
<a href="https://jack-jeffries.github.io/F25/817text.html">Math 817 lecture notes</a>.</p>

<p>
          The lecture notes draw heavily on
          <a aria-label="Eloísa Grifo’s Algebra Notes, PDF in a new tab" href="https://eloisagrifo.github.io/Teaching/algebra.pdf" rel="noopener" target="_blank">
            Eloísa Grifo’s Algebra Notes (PDF, opens in new tab)
          </a>,
          which in turn draw from earlier lecture notes of Mark Walker and Alexandra Seceleanu.
          The textbook <em>Abstract Algebra</em> by Dummit and Foote is a good resource covering similar material.
        </p>
</section>





<h1 id="Modules">Modules</h1>
<section aria-labelledby="lecture-heading" id="modules">
<h1 id="lecture-heading">11. An Introduction to Modules</h1>

<p>
          Modules are a generalization of the concept of a vector space to any ring of scalars in place of a field. While vector spaces are key examples of modules, many of the basic facts we are used to from linear algebra are often a little more subtle over a general ring.      </p>



<section id="modules-definition-and-examples" aria-labelledby="sec-11-1-heading">
  <h2 id="sec-11-1-heading">11.1 Definitions and first examples</h2>

  <section class="callout definition" role="region" aria-labelledby="def-11-1-1">
    <h3 id="def-11-1-1">Definition 11.1.1</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\). A <strong>left \(R\)-module</strong> is an abelian group \((M,+)\)  together with an action \(R \times M \to M\) of \(R\) on \(M\), written as \((r,m) \mapsto rm\), such that for all \(r,s \in R\) and \(m,n \in M\) we have the following:
    </p>
    <ul>
      <li>\((r + s)m = rm + sm\),</li>
      <li>\((rs)m = r(sm)\),</li>
      <li>\(r(m + n) = rm + rn\), and</li>
      <li>\(1m = m\).</li>
    </ul>
    <p>
      A <strong>right \(R\)-module</strong> is an abelian group \((M,+)\) together with an action of \(R\) on \(M\), written as \(M \times R \to M, (m,r)\mapsto mr\), such that for all \(r,s \in R\) and \(m,n \in M\) we have
    </p>
    <ul>
      <li>\(m(r + s) = mr + ms\),</li>
      <li>\(m(rs) = (mr)s\),</li>
      <li>\((m + n)r = mr + nr\), and</li>
      <li>\(m1 = m\).</li>
    </ul>
  </section>

  <p>
    By default, we will be studying left \(R\)-modules. To make the writing less heavy, we will sometimes say <strong>\(R\)-module</strong> rather than left \(R\)-module whenever there is no ambiguity.
  </p>

  <section class="callout remark" role="region" aria-labelledby="rmk-11-1-2">
    <h3 id="rmk-11-1-2">Remark 11.1.2</h3>
    <p>
      If \(R\) is a commutative ring, then any left \(R\)-module \(M\) may be regarded as a right \(R\)-module by setting \(m r := r m\). Likewise, any right \(R\)-module may be regarded as a left \(R\)-module. Thus for commutative rings, we just refer to modules, and not left or right modules.
    </p>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-1-3">
    <h3 id="lem-11-1-3">Lemma 11.1.3 (Arithmetic in modules)</h3>
    <p>
      Let \(R\) be a ring with \(1_R \neq 0_R\) and \(M\) be an \(R\)-module. Then \(0_Rm = 0_M\) and \((-1_R)m = -m\) for all \(m \in M\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-1-3">
    <h3 id="prf-11-1-3">Proof (of Lemma 11.1.3)</h3>
    <p>
      Let \(m \in M\). Then
      \[
        0_R m = (0_R + 0_R) m = 0_Rm + 0_Rm.
      \]
      Since \(M\) is an abelian group, the element \(0_Rm\) has an additive inverse, \(-0_Rm\), so adding it on both sides we see that
      \[
        0_M = 0_Rm.
      \]
      Moreover,
      \[
        m + (-1_R)m = 1_R m + (-1_R)m = (1_R - 1_R)m = 0_R m = 0_M,
      \]
      so \((-1_R)m = -m\).
    </p>
  </section>

  <p>
    Typically, one first encounters modules in an undergraduate linear algebra course: the vector spaces from linear algebra are modules over fields. Later we will see that vector spaces are much simpler modules than modules over other rings. So while one might take linear algebra and vector spaces as an inspiration for what to expect from a module, be warned that this perspective can often be deceiving.
  </p>

  <section class="callout definition" role="region" aria-labelledby="def-11-1-4">
    <h3 id="def-11-1-4">Definition 11.1.4</h3>
    <p>
      Let \(F\) be a field. A <strong>vector space</strong> over \(F\) is an \(F\)-module.
    </p>
  </section>

  <p>
    We will see more about vector spaces soon. Note that many of the concepts we will introduce have special names in the case of vector spaces. Here are some other important examples:
  </p>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-1-5">
    <h3 id="lem-11-1-5">Lemma 11.1.5</h3>
    <p>
      Let \(M\) be a set with a binary operation \(+\). Then
    </p>
    <ol style="margin-left:20px">
      <li>\(M\) is an abelian group if and only if \(M\) is a \(\mathbb{Z}\)-module.</li>
      <li>\(M\) is an abelian group such that \(nm:=\underbrace{ m + \cdots + m}_{n \textrm{ times}}=0_M\) for all \(m\in M\) if and only if \(M\) has a \(\mathbb{Z}/n\)-module structure.</li>
    </ol>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-1-5">
    <h3 id="prf-11-1-5">Proof (of Lemma 11.1.5)</h3>
    <p>
      First, we show 1). If \(M\) is a \(\mathbb{Z}\)-module, then \((M,+)\) is an abelian group by definition of module. Conversely, if \((M,+)\) is an abelian group then there is a unique \(\mathbb{Z}\)-module structure on \(M\) given by the formulas below. The uniqueness of the \(\mathbb{Z}\) action follows from the identities below in which the right hand side is determined only by the abelian group structure of \(M\). The various identities follow from the axioms of a module:
      \[
      \begin{cases}
      i \cdot m = (\underbrace{1 + \cdots + 1}_i) \cdot m = \underbrace{1   \cdot m + \cdots +1 \cdot m}_i
      = \underbrace{ m + \cdots + m}_i & \text{ if } i>0\\
      0 \cdot m = 0_M & \\
      i \cdot m = - (-i) \cdot m = - (\underbrace{m + \cdots + m}_{-i}) &  \text{ if } i<0.
      \end{cases}
      \]
      We leave it as an exercise to check that this \(\mathbb{Z}\)-action really satisfies the module axioms.
    </p>
    <p>
      Now we show 2). If \(M\) is a \(\mathbb{Z}/n\) module, then \((M,+)\) is an abelian group by definition, and \(nm= \underbrace{ m + \cdots + m}_n=\underbrace{[1]_n   \cdot m + \cdots +[1]_n \cdot m}_n=[0]_nm=0_M\).
    </p>
    <p>
      Conversely, there is a unique \(\mathbb{Z}/n\)-module structure on \(M\) given by the formulas below, which are analogous to the ones above:
      \[
      \begin{cases}
      [i]_n \cdot m = (\underbrace{[1]_n+ \cdots + [1]_n}_i) \cdot m = \underbrace{[1]_n   \cdot m + \cdots +[1]_n \cdot m}_i= \underbrace{ m + \cdots + m}_i & \text{ if } i>0\\
      0 \cdot m = 0_M &\\
      [i]_n \cdot m = - (-[i]_n) \cdot m = - (\underbrace{m + \cdots + m}_{-i}) &  \text{ if } i<0.
      \end{cases}
      \]
      These formulas are well-defined, meaning they are independent of the choice of representative for \([i]_n\), because of the assumption that \(nm=0_M\). Again checking that this \(\mathbb{Z}/n\)-action really satisfies the module axioms is left as an exercise.
    </p>
  </section>

  <p>
    The proposition above says in particular that any group of the form
    \[
      G=\mathbb{Z}^\ell\times \mathbb{Z}/d_1\times \dots\times \mathbb{Z}/d_m
    \]
    is a \(\mathbb{Z}\)-module, and if \(\ell=0, m \geqslant 1\) and \(d_i \mid n\) for \(1 \leqslant i \leqslant m\) then \(G\) is also a \(\mathbb{Z}/n\)-module. In particular, the Klein group is a \(\mathbb{Z}/2\)-module.
  </p>

  <p>
    In contrast to vector spaces, for \(M\) a module over a ring \(R\), it can happen that \(rm=0\) for some \(r \in R\) and \(m \in M\) such that \(r \neq 0_R\) and \(m \neq 0_M\). For example, in the Klein group \(K_4\) viewed as a \(\mathbb{Z}\)-module we have \(2m=0\) for all \(m \in K_4\).
  </p>

  <section class="callout example" role="region" aria-labelledby="ex-11-1-6">
    <h3 id="ex-11-1-6">Example 11.1.6</h3>
    <ol style="margin-left:20px">
      <li>The trivial \(R\)-module is \(0=\{0\}\) with \(r0=0\) for any \(r\in R\).</li>
      <li>If \(R\) is any ring, then \(R\) is a left and right \(R\)-module via the action of \(R\) on itself given by its internal multiplication.</li>
      <li>If \(I\) is a left (respectively, right) ideal of a ring \(R\) then \(I\) is a left (respectively, right) \(R\)-module with respect to the action of \(R\) on \(I\) by internal multiplication.</li>
      <li>
        If \(R\) is a subring of a ring \(S\), then \(S\) is a (left or right) \(R\)-module with respect to the action of \(R\) on \(S\) by internal multiplication in \(S\).
      </li>
      <li>
        If \(R\) is a ring with \(1 \neq 0\), then \(R[x_1,\ldots,x_n]\) is an \(R\)-module for any \(n \geqslant 1\). This is a special case of (4).
      </li>
   <li>
        The <strong>standard free module</strong> over \(R\) of rank \(n\) is the set
        \[
          R^n=\left\{\begin{bmatrix} r_1\\ \vdots\\r_n \end{bmatrix} \mid r_i\in R, 1 \leqslant i \leqslant n\right\}
        \]
        with componentwise addition and multiplication by elements of \(R\), as follows:
        \[
          \begin{bmatrix} r_1\\ \vdots\\r_n \end{bmatrix} +\begin{bmatrix} r'_1\\ \vdots\\r'_n \end{bmatrix} =\begin{bmatrix} r_1+r'_1\\ \vdots\\r_n +r'_n\end{bmatrix} \text{ and } r\begin{bmatrix} r_1\\ \vdots\\r_n \end{bmatrix}=\begin{bmatrix} rr_1\\ \vdots\\ rr_n \end{bmatrix}.
        \]
        We will often write the elements of \(R^n\) as \(n\)-tuples \((r_1, \ldots, r_n)\) instead. Notice that \(R\) is the free \(R\)-module of rank \(1\).
      </li>
      <li>
        More generally, given a collection of \(R\)-modules \(\{ A_i \}\), the abelian groups
\[ \prod_i A_i = \{ (a_i)_i \mid a_i \in A_i \}\]
and
        \[
          \bigoplus_i A_i = \{ (a_i)_i \mid a_i \in A_i, a_i = 0 \textrm{ for all but finitely many}\ i \,\}
        \]
        are \(R\)-modules with the \(R\)-action \(r(a_i) := (ra_i)\). They are called the <strong>direct product</strong> and <strong>direct sum</strong>, respectively.
      </li>
      <li>
        If \(R\) is a ring, let \( M_n(R)\) denote the ring of \(n \times n\) matrices with entries in \(R\). Then the set of \(n\times 1\) column vectors with entries in \(R\) is a left \(M_n(R)\)-module, and the set of \(1\times n\) row vectors with entries in \(R\) is a right \(M_n(R)\)-module, with the usual coordinatewise vector-plus-vector addition and usual matrix-times-vector multiplication.
      </li>
  
    </ol>
  </section>

</section>




<section id="submodules-and-restriction-of-scalars" aria-labelledby="sec-11-2-heading">
  <h2 id="sec-11-2-heading">11.2 Submodules and restriction of scalars</h2>

  <section class="callout definition" role="region" aria-labelledby="def-11-2-1">
    <h3 id="def-11-2-1">Definition 11.2.1</h3>
    <p>
      Let \(R\) be a ring and let \(M\) be a left \(R\)-module. An <strong>\(R\)-submodule</strong> of \(M\) is a subset \(N\subseteq M\) that is an \(R\)-module with the same addition and \(R\)-action as \(M\).
    </p>
  </section>


  <section class="callout exercise" role="region" aria-labelledby="ex-11-2-2">
    <h3 id="ex-11-2-2">Exercise 11.2.2</h3>
    <p> Show that a subset \(N\subseteq M\) is a submodule if and only if it is a
subgroup under addition of \(M\) satisfying \(rn \in N\) for all \(r \in R\) and \(n \in N\).    
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-2-3">
    <h3 id="ex-11-2-3">Example 11.2.3</h3>
    <p>
      Every \(R\)-module \(M\) has two <strong>trivial submodules</strong>: \(M\) itself and the <strong>zero module</strong> \(0 = \{ 0_M \}\). A submodule \(N\) of \(M\) is <strong>nontrivial</strong> if \(N \neq M\) and \(N \neq 0\).
    </p>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-2-4">
    <h3 id="lem-11-2-4">Lemma 11.2.4 (Submodule tests)</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq  0\) and let \(M\) be a left \(R\)-module.
      Let \(N\) be a nonempty subset of \(M\).
    </p>
    <ol style="margin-left:20px">
      <li>
        (Two-step test) \(N\) is an \(R\)-submodule of \(M\) if and only if \(n+n' \in N\) and \(rn \in N\) for all \(n,n'\in N\) and \(r\in R\).
      </li>
      <li>
        (One-step test) \(N\) is an \(R\)-submodule of \(M\) if and only if \(rn+n'\in N\) for all \(n,n'\in N\) and \(r\in R\).
      </li>
    </ol>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-2-4">
    <h3 id="prf-11-2-4">Proof (of Lemma 11.2.4)</h3>
    <p>
      Exercise.
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-2-5">
    <h3 id="ex-11-2-5">Example 11.2.5</h3>
    <p>
      Let \(R\) be a ring and let \(M\) be a subset of \(R\). Then \(M\) is a left (respectively, right)  \(R\)-submodule of \(R\) if and only if \(M\) is a left (respectively, right) ideal of R.
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-2-6">
    <h3 id="ex-11-2-6">Exercise 11.2.6</h3>
    <p>
      Let \(R\) be a ring and let \(A\) and \(B\) be submodules of an \(R\)-module \(M\). Then the <strong>sum</strong> of \(A\) and \(B\),
      \[
        A + B := \{ a + b \mid a \in A, b \in B \},
      \]
is a submodule of \(M\). If \(\{A_i \ | \ i\in I\}\) is a collection of submodules of \(M\), then the intersection \( \bigcap_{i\in I} A_i\) is a submodule of \(M\).
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-2-7">
    <h3 id="ex-11-2-7">Exercise 11.2.7</h3>
    <p>
      Let \(R\) be a commutative ring , let \(I\) be an ideal of \(R\) and let \(M\) be an \(R\)-module. Show that
      \[
        IM := \left\{\sum_{k=1}^n j_km_k \mid n \geqslant 0, j_k \in I, m_k \in M \text{ for } 1 \leqslant k \leqslant n \right\}
      \]
      is a submodule of \(M\).
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-2-8">
    <h3 id="ex-11-2-8">Example 11.2.8</h3>
    <p>
      When \(R\) is a field, the submodules of a vector space \(V\) are precisely the subspaces of \(V\).
      When \(R = \mathbb{Z}\), then the class of \(R\)-modules is simply the class of all abelian groups. The submodules of a \(\mathbb{Z}\)-module \(M\) coincide with the subgroups of the abelian group \(M\).
    </p>
  </section>

<!--  <section class="callout definition" role="region" aria-labelledby="def-11-2-9">
    <h3 id="def-11-2-9">Definition 11.2.9</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\) and let \(M\) be an \(R\)-module. Given elements \(m_1, \ldots, m_n \in M\), the <strong>submodule generated by</strong> \(m_1, \ldots, m_n\) is the subset of \(M\) given by
      \[
        Rm_1 + \cdots + Rm_n := \{ r_1 m_1 + \cdots + r_n m_n \mid r_1, \ldots, r_n \in R\}.
      \]
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-2-10">
    <h3 id="ex-11-2-10">Exercise 11.2.10</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\) and \(M\) be an \(R\)-module. Given \(m_1, \ldots, m_n \in M\), the submodule generated by \(m_1, \ldots, m_n\) is indeed a submodule of \(M\). Moreover, this is the smallest submodule of \(M\) that contains \(m_1, \ldots, m_n\), meaning that every submodule of \(M\) containing \(m_1, \ldots, m_n\) must also contain \(R m_1 + \cdots + R m_n\).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-2-11">
    <h3 id="def-11-2-11">Definition 11.2.11</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\). An \(R\)-module \(M\) is <strong>cyclic</strong> if there exists an element \(m \in M\) such that
      \[
        M = Rm := \{ rm \mid r \in R \}.
      \]
    </p>
  </section> -->

  <p>
    Given an \(R\)-module \(M\), the ring \(R\) is sometimes referred to as the <strong>ring of scalars</strong>, by analogy to the vector space case. Given an action of a ring of scalars on a module, we can sometimes produce an action of a different ring of scalars on the same set, producing a new module structure.
  </p>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-2-12">
    <h3 id="lem-11-2-12">Lemma 11.2.9 (Restriction of scalars)</h3>
    <p>
      Let \(\phi\!: R \to S\) be a ring homomorphism. Any left \(S\)-module \(M\) may be regarded via <strong>restriction of scalars</strong> as a left \(R\)-module with \(R\)-action  defined by \(r m := \phi(r)m\) for any \(m\in M\).
      In particular, if \(R\) is a subring of a ring \(S\), then any left \(S\)-module \(M\) may be regarded via restriction of scalars as a left \(R\)-module with \(R\)-action defined by the action of the elements of \(R\) viewed as elements of \(S\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-2-12">
    <h3 id="prf-11-2-12">Proof (of Lemma 11.2.9)</h3>
    <p>
      Let \(r,s \in R\) and \(m,n \in M\). One checks that the axioms in the definition of a module hold for the given action using properties of ring homomorphisms. For example:
      \[
        (r+s)m=\phi(r + s)m= (\phi(r)+\phi(s))m=\phi(r)m + \phi(s)m=rm+sm.
      \]
      The remaining properties are left as an exercise.
    </p>
  </section>

  <p>
    Note that the second module structure on \(M\) obtained via restriction of scalars is induced by the original module structure, so the two are related. In general, one can give different module structures on the same abelian group over different, possibly unrelated, rings.
  </p>

  <section class="callout example" role="region" aria-labelledby="ex-11-2-13">
    <h3 id="ex-11-2-13">Example 11.2.10</h3>
    <p>
      If \(I\) is an ideal of a ring \(R\), applying restriction of scalars along the quotient homomorphism \(q\!:R\to R/I\) tells us that any left \(R/I\)-module is also a left \(R\)-module. In particular, applying this to the \(R/I\)-module \(R/I\) makes \(R/I\) a left and right \(R\)-module by restriction of scalars along the quotient homomorphism. Thus the \(R\)-action on \(R/I\) is given by
      \[
        r \cdot (a + I) := ra + I.
      \]
    </p>
  </section>


  <p>
    The next example explains why restriction of scalars is called a <em>restriction</em>.
  </p>

  <section class="callout example" role="region" aria-labelledby="ex-11-2-15">
    <h3 id="ex-11-2-15">Example 11.2.11</h3>
    <p>
      Let \(R\) be a subring of \(S\), and let \(i\!: R \to S\) be the inclusion map, which must by definition be a ring homomorphism. Applying restriction of scalars to an \(S\)-module \(M\) via \(i\) is the same as simply <em>restricting</em> our scalars to the elements of \(R\).
    </p>
  </section>

</section>


<section id="module-homomorphisms-and-isomorphisms" aria-labelledby="sec-11-3-heading">
  <h2 id="sec-11-3-heading">11.3 Module homomorphisms and isomorphisms</h2>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-1">
    <h3 id="def-11-3-1">Definition 11.3.1</h3>
    <p>
      Given \(R\)-modules \(M\) and \(N\), an <strong>\(R\)-module homomorphism</strong> from \(M\) to \(N\) is a function \(f\!: M \to N\) such that for all \(r \in R\) and \(m,n \in M\) we have
    </p>
    <ul style="margin-left:20px">
      <li>\(f(m+n)=f(m)+f(n)\)</li>
      <li>\(f(rm) = rf(m)\).</li>
    </ul>
An \(R\)-module homomorphism is also called an <strong>\(R\)-linear</strong> map.
  </section>

  <section class="callout remark" role="region" aria-labelledby="rmk-11-3-2">
    <h3 id="rmk-11-3-2">Remark 11.3.2</h3>
    <p>
      The condition \(f(m+n)=f(m)+f(n)\) says that \(f\) is a homomorphism of abelian groups, and the condition \(f(rm) = rf(m)\) says that \(f\) is \(R\)-linear, meaning that it preserves the \(R\)-action. Since \(f\) is a homomorphism of abelian groups, it follows that \(f(0) = 0\) must hold.
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-3">
    <h3 id="def-11-3-3">Definition 11.3.3</h3>
    <p>
      Let \(M\) and \(N\) be vector spaces over a field \(F\). A <strong>linear transformation</strong> from \(M\) to \(N\) is an \(F\)-module homomorphism \(M \to N\).
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-3-4">
    <h3 id="ex-11-3-4">Example 11.3.4</h3>
    <p>
      Let \(R\) be a commutative ring and \(M\) be an \(R\)-module. For each \(r \in R\), the multiplication map \(\mu_r\!: M \to M\) given by \(\mu_r(m) = rm\) is a homomorphism of \(R\)-modules: indeed, by the definition of \(R\)-module we have
      \[
        \mu_r(m+n) = r(m+n) = rm+rn = \mu_r(m) + \mu_r(n),
      \]
      and
      \[
        \mu_r(sm) = r(sm) = (rs)m = (sr)m = s (rm) = s \mu_r(m).
      \]
      Note that \(R\) is not commutative, the left multiplication map \(\mu_r\!:M\to M\) is not a homomorphism of (left) \(R\)-modules.
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-5">
    <h3 id="def-11-3-5">Definition 11.3.5</h3>
    <p>
      An \(R\)-module homomorphism \(h\!: M \to N\) is an <strong>\(R\)-module isomorphism</strong> if there is an \(R\)-module homomorphism \(g: N \to M\) such that
      \(h \circ g = \mathrm{id}_N\) and \(g \circ h = \mathrm{id}_M\). We say \(M\) and \(N\) are <strong>isomorphic</strong>, denoted \(M \cong N\), if there exists an isomorphism \(M \to N\).
    </p>
  </section>

  <p>
    To check that an \(R\)-module homomorphism \(f\!: M \to N\) is an isomorphism, it is sufficient to check that it is bijective.
  </p>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-3-6">
    <h3 id="ex-11-3-6">Exercise 11.3.6</h3>
    <p>
      Let \(f\!: M \to N\) be a homomorphism of \(R\)-modules. Show that if \(f\) is bijective, then its set-theoretic inverse \(f^{-1}\!: N \to M\) is an \(R\)-module homomorphism. Therefore, every bijective homomorphism of \(R\)-modules is an isomorphism.
    </p>
  </section>

  <p>
    One should think of a module isomorphism as a relabelling of the names of the elements of the module. If two modules are isomorphic, that means that they are <em>essentially the same</em>, up to renaming the elements.
  </p>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-7">
    <h3 id="def-11-3-7">Definition 11.3.7</h3>
    <p>
      Let \(f\!: M \to N\) be a homomorphism of \(R\)-modules. The <strong>kernel</strong> of \(f\) is
      \[
        \ker(f) := \{ m \in M \mid f(m) = 0 \}.
      \]
      The <strong>image</strong> of \(f\), denoted \(\mathrm{im}(f)\) or \(f(M)\), is
      \[
        \mathrm{im}(f) := \{ f(m) \mid m \in M \}.
      \]
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-3-8">
    <h3 id="ex-11-3-8">Exercise 11.3.8</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq  0\), let \(M\) be an \(R\)-module, and let \(N\) be an \(R\)-submodule of \(M\). Then the inclusion map \(i\!: N \to M\) is an \(R\)-module homomorphism.
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-3-9">
    <h3 id="ex-11-3-9">Exercise 11.3.9</h3>
    <p>
      If \(f\!: M \to N\) is an \(R\)-module homomorphism, then \(\ker(h)\) is an \(R\)-submodule of \(M\) and \(\mathrm{im}(f)\) is an \(R\)-submodule of \(N\).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-10">
    <h3 id="def-11-3-10">Definition 11.3.10</h3>
    <p>
      Let \(R\) be a ring and let \(M\) and \(N\) be \(R\)-modules. Then \(\mathrm{Hom}_R(M,N)\) denotes the set of all \(R\)-module homomorphisms from \(M\) to \(N\), and \(\mathrm{End}_R(M)\) denotes the set \(\mathrm{Hom}_R(M,M)\). We call \(\mathrm{End}(M)\) the <strong>endomorphism ring</strong> of \(M\), and elements of \(\mathrm{End}(M)\) are called <strong>endomorphisms</strong> of \(M\).
    </p>
  </section>

  <p>
    The endomorphism ring of an \(R\)-module \(M\) is called that because it <em>is</em> a ring, with multiplication given by composition of endomorphisms, \(0\) given by the zero map (the constant equal to \(0\)), and \(1\) given by the identity map.
    However, two homomorphisms from \(M\) to \(N\) are not composable unless \(M = N\), so \(\mathrm{Hom}_R(M,N)\) is not a ring.
  </p>

  <p>
    When \(R\) is commutative, \(\mathrm{Hom}_R(M,N)\) is, however, an \(R\)-module; let us describe its \(R\)-module structure.
    Given \(f, g \in \mathrm{Hom}_R(M,N)\), \(f+g\) is the map defined by
    \[
      (f+g)(m) := f(m) + g(m),
    \]
    and given \(r \in R\) and \(f \in \mathrm{Hom}_R(M,N)\), \(r \cdot f\) is the \(R\)-module homomorphism defined by
    \[
      (r \cdot f) (m) := r \cdot f(m) = f(rm).
    \]
    The zero element of \(\mathrm{Hom}_R(M,N)\) is the <strong>zero map</strong>, the constant equal to \(0_N\).
  </p>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-3-11">
    <h3 id="lem-11-3-11">Lemma 11.3.11</h3>
    <p>
      Let \(M\) and \(N\) be \(R\)-modules over a commutative ring \(R\). Then the addition and multiplication by scalars defined above make \(\mathrm{Hom}_R(M,N)\) an \(R\)-module.
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-11">
    <h3 id="prf-11-3-11">Proof (of Lemma 11.3.11)</h3>
    <p>
      There are many things to check, including:
    </p>
    <ul style="margin-left:20px">
      <li>
        The addition and the \(R\)-action are both well-defined: given \(f,g\in \mathrm{Hom}_R(M,N)\) and \(r\in R\), we always have \(f+g, rf\in \mathrm{Hom}_R(M,N)\).
      </li>
      <li>
        The axioms of an \(R\)-module are satisfied for \(\mathrm{Hom}_R(M,N)\).
      </li>
    </ul>
    <p>
      We leave the details as exercises.
    </p>
  </section>

  <p>
    We will see later that for an \(n\)-dimensional vector space \(V\) over a field \(F\), there is an isomorphism of vector spaces \(\mathrm{Hom}_F(V)\cong M_n(F)\). This says that every linear transformation \(T:V\to V\) corresponds to some \(n\times n\) matrix. However, the story for general \(R\)-modules is a lot more complicated.
  </p>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-3-12">
    <h3 id="lem-11-3-12">Lemma 11.3.12</h3>
    <p>
      For any commutative ring \(R\)  and any \(R\)-module \(M\) there is an isomorphism of \(R\)-modules \(\mathrm{Hom}_R(R,M)\cong M\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-12">
    <h3 id="prf-11-3-12">Proof (of Lemma 11.3.12)</h3>
    <p>
      Let \(f\!:M\to \mathrm{Hom}_R(R,M)\) be given for each \(m\in M\) by \(f(m)=\phi_m\) where \(\phi_m\) is the map defined by \(\phi_m(r)=rm\) for all \(r\in R\). Now we have many things to check:
    </p>
    <ul style="margin-left:20px">
      <li>
        \(f\) is well-defined, meaning that for any \(m\in M\), its image \(f(m) = \phi_m\) is an element of \(\mathrm{Hom}_R(R,M)\), since
        \[
          \phi_m(r_1+r_2)=(r_1+r_2)m=r_1m+r_2m=\phi_m(r_1)+\phi_m(r_2)
        \]
        \[
          \phi_m(r_1r_2)=(r_1r_2)m=r_1(r_2m)=r_1\phi_m(r_2)
        \]
        for all \(r_1,r_2\in R\).
      </li>
      <li>
        \(f\) is an \(R\)-module homomorphism, since
        \[
          \phi_{m_1+m_2}(r)=r(m_1+m_2)=rm_1+rm_2=\phi_{m_1}(r)+\phi_{m_2}(r)
        \]
        \[
          \phi_{r'm}(r)=r(r'm)=(rr')m=r'(rm)=r'\phi_{m}(r)
        \]
      </li>
      <li>
        \(f\) is injective, since \(\phi_m=\phi_{m'}\) implies in particular that \(\phi_m(1_R)=\phi_{m'}(1_R)\), which by definition of \(\phi_{-}\) means that \(m=m'\).
      </li>
      <li>
        \(f\) is surjective, since for \(\psi \in \mathrm{Hom}_R(R,M)\) we have \(\psi(r)=\psi(r1_R)=r\psi(1_R)\) for all \(r\in R\), so \(\psi=\phi_{\psi(1_R)}\).
      </li>
    </ul>
    <p>
      This shows that \(f\) is an \(R\)-module isomorphism.
    </p>
  </section>

<!--  <section class="callout definition" role="region" aria-labelledby="def-11-3-13">
    <h3 id="def-11-3-13">Definition 11.3.13</h3>
    <p>
      Let \(R\) be a commutative ring with \(1_R \neq 0_R\). An <strong>\(R\)-algebra</strong> is a ring \(A\) with \(1_A \neq 0_A\) together with a ring homomorphism \(f\!: R \to A\) such that \(f(R)\) is contained in the center of \(A\).
    </p>
  </section>

  <p>
    Given an \(R\)-algebra \(A\), the \(R\)-algebra structure on \(A\) induces a natural \(R\)-module structure: given elements \(r \in R\) and \(a \in A\), the \(R\)-action is defined by
    \[
      r \cdot a := f(r) a,
    \]
    where the product on the right is the multiplication in \(A\). Similarly, we get a natural right \(R\)-module structure on \(A\), and since by definition \(f(R)\) is contained in the center of \(A\), we obtain what is called a <em>balanced bimodule</em> structure on \(A\).
  </p>

  <section class="callout example" role="region" aria-labelledby="ex-11-3-14">
    <h3 id="ex-11-3-14">Example 11.3.14</h3>
    <p>
      Let \(R\) be a commutative ring with \(1_R \neq 0_R\). The ring \(R[x_1,\ldots, x_n]\) together with the inclusion map \(R \hookrightarrow R[x_1,\ldots, x_n]\) is an \(R\)-algebra. More generally, any quotient of \(R[x_1,\ldots, x_n]\) is an \(R\)-algebra.
    </p>
    <p>
      The ring of matrices \(M_n(R)\) with the homomorphism \(r \mapsto r I_n\) is also an \(R\)-algebra.
    </p>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-3-15">
    <h3 id="lem-11-3-15">Lemma 11.3.15</h3>
    <p>
      Let \(R\) be a commutative ring with \(1 \neq 0\) and let M be an \(R\)-module. Then \(\mathrm{End}_R(M)\) is an \(R\)-algebra, with addition and \(R\)-action defined as above, and multiplication defined by composition \((fg)(m) = f(g(m))\) for all \(f,g \in \mathrm{End}_R(M)\) and all \(m \in M\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-15">
    <h3 id="prf-11-3-15">Proof (of Lemma 11.3.15)</h3>
    <p>
      There are many things to check here, including that:
    </p>
    <ul style="margin-left:20px">
      <li>The axioms of a (unital) ring are satisfied for \(\mathrm{End}_R(M)\).</li>
      <li>
        There is a ring homomorphism \(f\!:R\to \mathrm{End}_R(M)\) such that \(f(1_R)=1_{\mathrm{End}_R(M)}=\mathrm{id}_M\) and \(f(R)\subseteq \mathrm{Z}(\mathrm{End}_R(M))\).
      </li>
    </ul>
    <p>
      We will just check the last item and leave the others as exercises. Define \(f\!:R\to \mathrm{End}_R(M)\) by \(f(r)=r\mathrm{id}_M\). Notice that this element \(f(r)\) is the map \(\mu_r\). Then
      \[
        f(r+s)=(r+s)\mathrm{id}_M=r\mathrm{id}_M+s\mathrm{id}_M=f(r)+f(s)
      \]
      and
      \[
        f(rs)=(rs)\mathrm{id}_M=(r\mathrm{id}_M)\circ(s\mathrm{id}_M)=f(r)f(s)
      \]
      show that \(f\) is a ring homomorphism. Moreover, \(\mathrm{id}_M\in \mathrm{Z}(\mathrm{End}_R(M))\), and one can check easily that \(\mu_r \in \mathrm{Z}(\mathrm{End}_R(M))\): given any other \(g \in \mathrm{End}_R(M)\), and any \(m \in M\), since \(g\) is \(R\)-linear we have
      \[
        (g \circ \mu_r)(m) = g(\mu_r(m)) = g(rm) = rg(m) = (\mu_r \circ g) (m).
      \]
      This shows that \(f(R)\) is contained in the center of \(\mathrm{End}_R(M)\).
    </p>
  </section> -->

  <section class="callout remark" role="region" aria-labelledby="rmk-11-3-16">
    <h3 id="rmk-11-3-16">Remark 11.3.13</h3>
    <p>
      Let \(R\) be a commutative ring with \(1 \neq 0\) and let \(M\) be an \(R\)-module. Then \(M\) is also an \(\mathrm{End}_R(M)\)-module with the action \(\phi m=\phi(m)\) for any \(\phi\in \mathrm{End}_R(M)\), \(m\in M\).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-17">
    <h3 id="def-11-3-17">Definition 11.3.14</h3>
    <p>
      Let \(R\) be a ring, let \(M\) be an \(R\)-module, and let \(N\) be a submodule of \(M\). The <em>quotient module</em> \(M/N\) is the quotient group \(M/N\) with R action defined by
      \[
        r(m + N) := rm + N
      \]
      for all \(r \in R\) and \(m + N \in M/N\).
    </p>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-3-18">
    <h3 id="lem-11-3-18">Lemma 11.3.15</h3>
    <p>
      Let \(R\) be a ring, let \(M\) be an \(R\)-module, and let \(N\) be a submodule of \(M\). The quotient module \(M/N\) is an \(R\)-module, and the quotient map \(q\!: M \to M/N\) is an \(R\)-module homomorphism with kernel \(\ker(q) = N\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-18">
    <h3 id="prf-11-3-18">Proof (of Lemma 11.3.15)</h3>
    <p>
      Among the many things to check here, we will only check the well-definedness of the \(R\)-action on \(M\), and leave the others as exercises.
      To check well-definedness, consider \(m+N=m'+N\). Then \(m-m'\in N\), so \(r(m-m')\in N\) by the definition of submodule. This gives that \(rm-rm'\in N\), hence \(rm+N=rm'+N\).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-19">
    <h3 id="def-11-3-19">Definition 11.3.16</h3>
    <p>
      Given an \(R\)-module \(M\) and a submodule \(N\) of \(M\), the map \(q\!: M \to M/N\) is the <strong>canonical quotient map</strong>, or simply the canonical map from \(M\) to \(N\).
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-3-20">
    <h3 id="ex-11-3-20">Example 11.3.17</h3>
    <p>
      If \(R\) is a field, quotient modules are the same thing as quotient vector spaces.
      When \(R = \mathbb{Z}\), recall that \(\mathbb{Z}\)-modules are the same as abelian groups. Quotients of \(\mathbb{Z}\)-modules coincide with quotients of abelian groups.
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-3-21">
    <h3 id="thm-11-3-21">Theorem 11.3.18 (Universal mapping property for quotient modules)</h3>
    <p>
      Let \(N\) be a submodule of \(M\), let \(T\) be an \(R\)-module, and let \(f: M \to T\) be an \(R\)-module homomorphism.
      If \(N \subseteq \ker f\), then the function
      \[
\begin{aligned}
        M/N &\longrightarrow & T \\ m+N &\longmapsto& f(m)
\end{aligned}
      \]
      is a well-defined \(R\)-module homomorphism. In fact, \(\overline{f}: M/N \to T\) is the unique \(R\)-module homomorphism such that \(\overline{f} \circ q = f\), where \(q\!: M \to M/N\) denotes the canonical map.
    </p>
  </section>



  <section class="callout proof" role="region" aria-labelledby="prf-11-3-21">
    <h3 id="prf-11-3-21">Proof (of Theorem 11.3.18)</h3>
    <p>
      By 817, we already know that \(\overline{f}\) is a well-defined homomorphism of groups under \(+\) and that it is the unique one such that \(\overline{f} \circ q = f\).
      It remains only to show \(\overline{f}\) is an \(R\)-linear map:
      \[
        \overline{f}(r (m +N)) = \overline{f} (rm + N) = f(rm) = r f(m) = r \overline{f}(m + N).
      \]
      where the third equation uses that \(f\) preserves scaling.
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-3-22">
    <h3 id="thm-11-3-22">Theorem 11.3.19 (First Isomorphism Theorem)</h3>
    <p>
      Let \(N\) be an \(R\)-module and let \(h: M \to N\) be an \(R\)-module homomorphism. Then \(\ker(h)\) is a submodule of \(M\) and there is an \(R\)-module isomorphism \(M/\ker(h) \cong \mathrm{im}(h)\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-22">
    <h3 id="prf-11-3-22">Proof (of Theorem 11.3.19)</h3>
    <p>
      If we forget the multiplication by scalars in \(R\), by the First Isomorphism Theorem for Groups, we know that there is an isomorphism of abelian groups under \(+\), given by
      \[
\begin{aligned}
        M/\mathrm{ker}(h) &\longrightarrow & \mathrm{im}(h) \\ m+\mathrm{ker}(h) &\longmapsto& h(m).
\end{aligned}
      \]

      It remains only to show this map preserves multiplication by scalars. And indeed:
      \[
        \begin{aligned}
        \overline{h}(r(m+\ker(h))) & = \overline{h}(rm+\ker(h)) & \textrm{by definition of the \(R\)-action on } M/\ker(h)\\
        & = h(rm) & \textrm{by definition of } \overline{h} \\
        & = rh(m) & \textrm{ since \(h\) is an \(R\)-module homomorphism} \\
        & = r \overline{h}(m+ \ker h) & \textrm{by definition of } h.
        \end{aligned}
      \]
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-3-23">
    <h3 id="thm-11-3-23">Theorem 11.3.20 (Diamond Isomorphism Theorem)</h3>
    <p>
      Let \(A\) and \(B\) be submodules of \(M\), and let \(A + B = \{a+b \mid a \in A, b \in B\}\). Then \(A + B\) is a submodule of \(M\), \(A \cap B\) is a submodule of \(A\), and there is an \(R\)-module isomorphism \((A + B)/B \cong A/(A \cap B)\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-23">
    <h3 id="prf-11-3-23">Proof (of Theorem 11.3.20)</h3>
    <p>
      We know that \(A+B\) and \(A \cap B\) are submodules of \(M\). By the Diamond Isomorphism Theorem for Groups, there is an isomorphism of abelian groups
      \[\begin{aligned}
        A/(A \cap B) &\cong (A+B)/B \\ a + (A\cap B) &\mapsto a + B\end{aligned}
      \]
      It remains only to show \(h\) preserves multiplication by scalars:
      \[
        h(r(a+(A \cap B))) = h(ra + A \cap B) = ra + B = r(a +B) = rh(a + (A \cap B)).
      \]
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-3-24">
    <h3 id="thm-11-3-24">Theorem 11.3.21 (Cancelling Isomorphism Theorem)</h3>
    <p>
      Let \(A\) and \(B\) be submodules of \(M\) with \(A \subseteq B\). Then there is an \(R\)-module isomorphism \((M/A)/(B/A) \cong M/B\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-24">
    <h3 id="prf-11-3-24">Proof (of Theorem 11.3.21)</h3>
    <p>
      From 817, we know that \(B/A\) is a subgroup of \(M/A\) under \(+\).
      Given \(r \in R\) and \(b +A \in B/A\) we have \(r(b+A) = rb + A\) which belongs to \(B/A\) since \(rb \in B\). This proves \(B/A\) is a submodule of \(M/A\).
      By the Cancelling Isomorphism Theorem for Groups, there is an isomorphism of abelian groups

    \[\begin{aligned}
        (M/A)/(B/A) &\cong M/B \\ (m+A) + B/A  &\mapsto m + B \end{aligned}
      \]
      and it remains only to show this map is \(R\)-linear:
      \[
        \begin{aligned}
        h(r((m+A) + B/A)) = & h(r(m+A) + B/A) = h((rm + A) + B/A) \\
        & = rm   + B = r(m +B)\\
        & = r h((m+A) + B/A).
        \end{aligned}
      \]
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-3-25">
    <h3 id="thm-11-3-25">Theorem 11.3.22 (Lattice Isomorphism Theorem)</h3>
    <p>
      Let \(R\) be a ring, let \(N\) be a R-submodule of an \(R\)-module \(M\), and let \(q\!: M \to M/N\) be the quotient map. Then the function
\[
\begin{aligned}
\{\, R\text{-submodules of } M \text{ containing } N \,\} 
&\longrightarrow 
\{\, R\text{-submodules of } M/N \,\} \\
K &\longmapsto K/N .
\end{aligned}
\]

      is a bijection, with inverse defined by
      \[
        \Psi^{-1}(T) := q^{-1}(T) = \{ a \in M \mid a+N \in T \}
      \]
      for each \(R\)-submodule \(T\) of \(M/N\). Moreover, \(\Psi\) and \(\Psi^{-1}\) preserve sums and intersections of submodules.
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-25">
    <h3 id="prf-11-3-25">Proof (of Theorem 11.3.22)</h3>
    <p>
      From 817, we know there is a bijection between the set of subgroups of \(M\) and that contain \(N\) and subgroups of the quotient group \(M/N\), given by the same map \(\Psi\).
      We just need to prove that these maps send submodules to submodules.
      If \(K\) is a submodule of \(M\) containing \(N\), then by the Cancelling Isomorphism Theorem we know that \(K/N\) is a submodule of \(M/N\).
      If \(T\) is a submodule of \(M/N\), then \(\pi^{-1}(T)\) is an abelian group, by 817. For \(r \in R\) and \(m \in \pi^{-1}(T)\), we have \(\pi(m) \in T\), and hence \(\pi(rm) = r\pi(m) \in T\) too, since \(T\) is a submodule. This proves \(\pi^{-1}(T)\) is a submodule.
    </p>
  </section>

<!--

  <p>
    We come to a very important class of examples which will help us study linear transformations using module theory.
  </p>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-3-26">
    <h3 id="lem-11-3-26">Lemma 11.3.26 (\(F[x]\)-modules)</h3>
    <p>
      Let \(F\) be a field. There is a bijection
      \[
        \begin{aligned}
        \{V \ | \  V \ \text{a} \ F[x]\text{-module}\} &\longleftrightarrow \{(V,T) \ | \  V \ \text{a} \ F\text{-vector space}, \ T\in \mathrm{Hom}_F(V)\}\\
        V &\longmapsto  \ (V, \mu_x:V\to V).
        \end{aligned}
      \]
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-3-26">
    <h3 id="prf-11-3-26">Proof (of Lemma 11.3.26)</h3>
    <p>
      If \(V\) is an \(F[x]\) module then \(V\) is an \(F\)-vector space by restriction of scalars along the inclusion \(F \hookrightarrow F[x]\). Let \(T:V\to V\) be defined by \(T(v)=xv\). To show that \(T\in \mathrm{Hom}_F(V)\), note that for any \(c\in F\) and \(v,v_1, v_2\in V\) the axioms of the \(F[x]\)-module give us
      \[
        T(v_1+v_2)=x(v_1+v_2)=xv_1+xv_2=T(v_1)+T(v_2) \textrm{
        and } T(cv)=x(cv)=c(xv).
      \]
    </p>
    <p>
      Conversely, let \(V\) be an \(F\)-vector space and \(T\in \mathrm{Hom}_F(V)\). We claim that the action of of \(F[x]\) on \(V\) given by
      \[
        f(x)v=(f(T))(v)
      \]
      satisfies the axioms for a module (exercise!). Alternatively, we can explain this module structure in a more conceptual way, as follows. Consider the evaluation homomorphism \(\varphi:F[x]\to \mathrm{Hom}_F(V), \quad \varphi(f(x))=f(T)\). Since \(V\) is an  \(\mathrm{Hom}_F(V)\)-module by Remark \ref{rem:endmodule}, then \(V\) is also an \(F[x]\)-module by restriction of scalars along \(\varphi\); the \(F[x]\) action is the one we described above:
      \[
        f(x)v= \varphi(f)(v) = (f(T))(v)
      \]
    </p>
    <p>
      Finally, one can check that the two constructions above are inverse to each other.
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-3-27">
    <h3 id="def-11-3-27">Definition 11.3.27</h3>
    <p>
      We shall denote the \(F[x]\)-module structure on an \(F\)-vector space \(V\) induced by \(T \in \mathrm{Hom}_F(V)\) by \(V_T\).
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-3-28">
    <h3 id="ex-11-3-28">Example 11.3.28</h3>
    <p>
      The proposition above says that if we fix an \(F\)-vector space \(V\) then any linear transformation \(T\) gives a different \(F[x]\) module structure on \(V\). For example,
    </p>
    <ul style="margin-left:20px">
      <li>
        For \(T=0\), the action of \(F[x]\) on the module \(V_0\) is given by scaling by the constant coefficient of \(f\): if \(f=a^nx^n+\dots+a_0\), then
        \[
          f(x)v=(f(0))v=a_0v \text{ for all } f\in F[x].
        \]
      </li>
      <li>
        For \(T\) the shift operator that takes \(T(e_i)=e_{i-1}\), where \(e_i\) is the \(i\)-th standard basis vector, the action of \(F[x]\) on \(V_T\) is determined by
        \[
          x^m\begin{bmatrix}v_1\\\vdots\\v_{n-m}\\v_{n-m+1}\\\vdots\\v_n\end{bmatrix}=\begin{bmatrix}v_{m+1}\\\vdots\\v_n \\0\\\vdots\\0\end{bmatrix}.
        \]
      </li>
    </ul>
  </section> -->

</section>

<section id="module-generators-bases-and-free-modules" aria-labelledby="sec-11-4-heading">
  <h2 id="sec-11-4-heading">11.4 Module generators, bases and free modules</h2>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-1">
    <h3 id="def-11-4-1">Definition 11.4.1</h3>
    <p>
      Let \(M\) be an \(R\)-module. A <strong>linear combination</strong> of finitely many elements \(a_1,\dots,a_n\) of \(M\) is an element of \(M\) of the form \(r_1m_1 + \dots + r_nm_n\) for some \(r_1,\ldots,r_n \in R\).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-2">
    <h3 id="def-11-4-2">Definition 11.4.2</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\) and let \(M\) be an \(R\)-module. For a subset \(A\) of \(M\), the submodule of \(M\) <strong>generated by</strong> \(A\) is
      \[
        RA := \{r_1a_1 + \dots + r_na_n \mid n \geq  0,  r_i \in R,  a_i\in A\}.
      \]
      We say \(M\) is <strong>generated by</strong> \(A\) if \(M=RA\).
      If \(M\) is an \(F\)-vector space, we may say that \(M\) is <strong>spanned by</strong> a set \(A\) instead of generated by \(A\).
    </p>
    <p>
      A module M is <strong>finitely generated</strong> if there is a finite subset \(A\) of \(M\) that generates \(M\). If \(A = {a}\) has a single element, the module \(RA= Ra\) is called <strong>cyclic</strong>.
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-4-3">
    <h3 id="ex-11-4-3">Exercise 11.4.3</h3>
    <p>
      Let \(M\) be an \(R\)-module and let \(A \subseteq M\). Then \(RA\) is the smallest submodule of \(M\) containing \(A\), that is
      \[
        RA \quad = \bigcap\limits_{A\subseteq N, N \text{ submodule of }M} N.
      \]
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-4-4">
    <h3 id="ex-11-4-4">Exercise 11.4.4</h3>
    <p>
      Being finitely generated and being cyclic are \(R\)-module isomorphism invariants.
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-4-5">
    <h3 id="ex-11-4-5">Example 11.4.5</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\).
    </p>
    <ol style="margin-left:20px">
      <li>\(R = R1\) is cyclic.</li>
      <li>\(R \oplus R\) is generated by \(\{(1,0),(0,1)\}\).</li>
      <li>\(R[x]\) is generated as an \(R\)-module by the set \(\{1,x,x^2,\ldots, x^n,\ldots\}\) of monic monomials in the variable \(x\).</li>
      <li>
        Let \(M = \mathbb{Z}[x,y]\). \(M\) is generated by
        <ul style="margin-left:20px">
          <li>\(\{1,x,y\}\) as a ring,</li>
          <li>\(\{1,y,y^2,\ldots, y^n,\ldots\}\) as an \(\mathbb{Z}[x]\)-module, and</li>
          <li>\(\{x^iy^j \mid  i,j \in \mathbb{Z}_{\geqslant 0}\}\) as a group (\(\mathbb{Z}\)-module).</li>
        </ul>
      </li>
    </ol>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-4-6">
    <h3 id="lem-11-4-6">Lemma 11.4.6</h3>
    <p>
      Let \(R\) be a ring with \(1 \neq 0\), let \(M\) be an \(R\)-module, and let \(N\) be an \(R\)-submodule of \(M\).
    </p>
    <ol style="margin-left:20px">
      <li>If \(M\) is finitely generated as an \(R\)-module, then so is \(M/N\).</li>
      <li>If \(N\) and \(M/N\) are finitely generated as \(R\)-modules, then so is \(M\).</li>
    </ol>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-4-6">
    <h3 id="prf-11-4-6">Proof (of Lemma 11.4.6)</h3>
    <p>
      The proof of (2) will be a problem set question. To show (1), note that if \(M=RA\) then \(M/N=R\bar{A}\), where \(\bar{A}=\{a+N \mid a\in A\}\).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-7">
    <h3 id="def-11-4-7">Definition 11.4.7</h3>
    <p>
      Let \(M\) be an \(R\)-module and let \(A\) be a subset of \(M\). The set \(A\) is <strong>linearly independent</strong> if whenever \(r_1,\ldots,r_n \in R\) and \(a_1,\ldots ,a_n\) are distinct elements of \(A\) satisfying \(r_1a_1 + \dots + r_na_n = 0\), then \(r_1 = \dots = r_n = 0\). Otherwise \(A\) is <strong>linearly dependent</strong>.
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-8">
    <h3 id="def-11-4-8">Definition 11.4.8</h3>
    <p>
      A subset \(A\) of an \(R\)-module \(M\) is a <strong>basis</strong> of \(M\) if \(A\) is linearly independent and generates \(M\). An \(R\)-module M is a <strong>free</strong> \(R\)-module if \(M\) has a basis.
    </p>
  </section>

  <p>
    We will later see that over a field, every module is free. However, when \(R\) is not a field, there are \(R\)-modules that are not free; in fact, <em>most</em> modules are not free.
  </p>

  <section class="callout example" role="region" aria-labelledby="ex-11-4-9">
    <h3 id="ex-11-4-9">Example 11.4.9</h3>
    <p>
      Here are some examples of free modules:
    </p>
    <ol style="margin-left:20px">
      <li>If we think of \(R\) as a module over itself, it is free with basis \(\{1\}\).</li>
      <li>The module \(R \oplus R\) is free with basis \(\{(1,0),(0,1)\}\).</li>
      <li>The \(R\)-module \(R[x]\) is free, and \(\{1,x,x^2,\ldots, x^n,\ldots\}\) is a basis.</li>
      <li>
        Let \(M = \mathbb{Z}[x,y]\). Then \(\{1,y,y^2,\ldots, y^n,\ldots\}\) is a basis for the \(\mathbb{Z}[x]\)-module \(M\), and \(\{x^iy^j \mid  i,j \in \mathbb{Z}_{\geqslant 0}\}\) is a basis for the \(\mathbb{Z}\)-module \(M.\)
      </li>
    </ol>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-4-10">
    <h3 id="ex-11-4-10">Example 11.4.10</h3>
    <p>
      \(\mathbb{Z}/2\) is not a free \(\mathbb{Z}\)-module. Indeed suppose that \(A\) is a basis for \(\mathbb{Z}/2\) and \(a\in A\). Then \(2a=0\) so \(A\) cannot be linearly independent, a contradiction.
    </p>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-4-11">
    <h3 id="lem-11-4-11">Lemma 11.4.11</h3>
    <p>
      If \(A\) is a basis of \(M\) then every nonzero element \(0\neq m\in M\) can be written uniquely as \(m=r_1a_1 + \dots + r_na_n\) with \(a_i\) distinct elements of \(A\) and \(r_i\neq 0\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-4-11">
    <h3 id="prf-11-4-11">Proof (of Lemma 11.4.11)</h3>
    <p>
      Suppose that if \(m\neq 0\) and \(A_1,A_2\) are finite subsets of \(A\) such that
      \[
        m=\sum_{a\in A_1}r_aa=\sum_{b\in A_2}s_bb
      \]
      for some \(r_a, s_b \in R\).
      Then
      \[
        \sum_{a\in A_1\cap A_2} (r_a-s_a)a+\sum_{a\in A_1\setminus A_2} r_aa-\sum_{a \in A_2\setminus A_1} s_aa=0.
      \]
      Since \(A\) is a linearly independent set, we conclude that \(r_a=s_a\) for \(a\in A_1\cap A_2\), \(r_a=0_R\) for \(a\in A_1\setminus A_2\), and \(s_a=0_R\) for \(a \in A_2\setminus A_1\). Set
      \[
        B := \{a \in A_1\cap A_2 \mid r_a \neq 0_R\}.
      \]
      Then
      \[
        m = \displaystyle\sum_{a\in B}r_aa
      \]
      is the unique way of writing \(m\) as a linear combination of elements of \(A\) with nonzero coefficients.
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-4-12">
    <h3 id="thm-11-4-12">Theorem 11.4.12 (Universal mapping property for free modules)</h3>
    <p>
      Let \(R\) be a ring, \(M\) be a free \(R\)-module with basis \(B\), \(N\) be any \(R\)-module, and let \(j: B \to N\) be any function. Then there is a unique \(R\)-module homomorphism \(h: M \to N\) such that \(h(b) = j(b)\) for all \(b \in B\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-4-12">
    <h3 id="prf-11-4-12">Proof (of Theorem 11.4.12)</h3>
    <p>
      We have two things to prove: existence and uniqueness.
    </p>

    <p>
      <em>Existence:</em> Any \(0\neq m\in M\) can be written uniquely as
      \[
        m=r_1b_1+\dots+r_nb_n
      \]
      with \(b_i\in B\) distinct and \(0 \neq r_i \in R\). Define \(h\!: M \to N\) by
      \[
        \begin{cases}
        h(r_1b_1+\dots+r_nb_n) = r_1j(b_1) + \cdots +r_nj(b_n) & \text{ if } r_1b_1 + \cdots + r_nb_n \neq 0\\
        h(0_M)=0_N
        \end{cases}
      \]
      One can check that this satisfies the conditions to be an \(R\)-module homomorphism (exercise!).
    </p>

    <p>
      <em>Uniqueness:</em> Let \(h:M\to N\) be an \(R\)-module homomorphism such that \(h(b_i)=j(b_i)\). Then in particular \(h\!:(M,+)\to (N,+)\) is a group homomorphism and therefore \(h(0_M)=0_N\) by properties of group homomorphisms. Furthermore, if \(m=r_1b_1+\dots+r_nb_n\) then
      \[
        h(m)=h(r_1b_1+\dots+r_nb_n)=r_1h(b_1)+\dots+r_nh(b_n)=r_1j(b_1)+\dots+r_nj(b_n)
      \]
      by the definition of homomorphism, and because \(h(b_i)=j(b_i)\).
    </p>
  </section>

  <section class="callout corollary" role="region" aria-labelledby="cor-11-4-13">
    <h3 id="cor-11-4-13">Corollary 11.4.13</h3>
    <p>
      If \(A\) and \(B\) are sets of the same cardinality, and fix a bijection \(j:A\to B\). If \(M\) and \(N\) are free \(R\)-modules with bases \(A\) and \(B\) respectively, then there is an isomorphism of \(R\)-modules \(M \cong N\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-4-13">
    <h3 id="prf-11-4-13">Proof (of Corollary 11.4.13)</h3>
    <p>
      Let \(g:M\to N\) and \(h:N\to M\) be the module homomorphisms induced by the bijection \(j:A\to B\) and its inverse \(j^{-1}:B\to A\), which exist by the UMP for free module. We will show that \(h\) and \(g\) are inverse homomorphisms.
      First, note that \(g \circ h:N\to N\) is an \(R\)-module homomorphism and \((g \circ h)(b) = g(j^{-1}(b))=j(j^{-1}(b))=b\) for every \(b\in B\). Since the identity map \(\mathrm{id}_N\) is an \(R\)-module homomorphism and \(id_N(b)=b\) for every \(b\in B\), by the uniqueness in the UMP for free modules we have \(g \circ h = \mathrm{id}_n\). Similarly, one shows that \(h \circ g = \mathrm{id}_M\).
    </p>
  </section>

  <p>
    The corollary gives that, up to isomorphism, there is only one free module with basis \(A\), provided such a module exists. But does a free module generated by a given set \(A\) exist? It turns out it does.
  </p>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-14">
    <h3 id="def-11-4-14">Definition 11.4.14</h3>
    <p>
      Let \(R\) be a ring and let \(A\) be a set. The free \(R\)-module generated by \(A\), denoted \(F_R(A)\) is the set of formal sums
    </p>
    <p>
      \[
        \begin{align*}
        F_R(A) &= \{r_1a_1 + \dots + r_na_n \mid n \geqslant 0, r_i \in R, a_i \in A\} \\
        &= \left\lbrace \sum_{a \in A} r_aa \mid r_a \in R, r_a = 0 \text{ for all but finitely many }a \right\rbrace,
        \end{align*}
      \]
      with addition defined by
      \[
        \left(\sum_{a \in A} r_aa\right) + \left(\sum_{a \in A} s_aa \right) = \sum_{a \in A} (r_a + s_a)a
      \]
      and \(R\)-action defined by
      \[
        r \left(\sum_{a \in A} r_aa \right) = \sum_{a \in A} (rr_a)a.
      \]
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-4-15">
    <h3 id="ex-11-4-15">Exercise 11.4.15</h3>
    <p>
      This construction \(F_R(A)\) results in an \(R\)-module, which is free with basis \(A\), and \(F_R(A)\cong \bigoplus_{a\in A}R\).
    </p>
  </section>

  <section class="callout theorem" role="region" aria-labelledby="thm-11-4-16">
    <h3 id="thm-11-4-16">Theorem 11.4.16 (Uniqueness of rank over commutative rings)</h3>
    <p>
      Let \(R\) be a commutative ring with \(1 \neq 0\) and let \(M\) be a free \(R\)-module. If \(A\) and \(B\) are both bases for \(M\), then \(A\) and \(B\) have the same cardinality, meaning that there exists a bijection \(A \to B\).
    </p>
  </section>

  <section class="callout proof" role="region" aria-labelledby="prf-11-4-16">
    <h3 id="prf-11-4-16">Proof (of Theorem 11.4.16)</h3>
    <p>
      You will show this in the next problem set (at least in the case where \(M\) has a finite basis).
    </p>
  </section>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-17">
    <h3 id="def-11-4-17">Definition 11.4.17</h3>
    <p>
      Let \(R\) be a commutative ring  and let \(M\) be a free \(R\)-module. The <strong>rank</strong> of \(M\) is the cardinality of any basis of \(M\).
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-4-18">
    <h3 id="ex-11-4-18">Example 11.4.18</h3>
    <p>
      Let \(R\) be a commutative ring with \(1 \neq 0\). The rank of \(R^n\) is \(n\). Note that, any free \(R\)-module of rank \(n\) must be isomorphic to \(R^n\).
    </p>
  </section>

  <p>
    Earlier, we described the \(R\)-module structure on the direct sum of \(R\)-modules; this is how we construct \(R^n\), by taking the direct sum of \(n\) copies of the \(R\)-module \(R\). This construction can also be described as the direct product of \(n\) copies of \(R\). However, the direct sum and direct product are two different constructions.
  </p>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-19">
    <h3 id="def-11-4-19">Definition 11.4.19</h3>
    <p>
      Let \(R\) be a ring. Let \(\{ M_a \}_{a \in J}\) be a collection of \(R\)-modules. The <strong>direct product</strong> of the R-modules \(M_a\) is the Cartesian product
      \[
        \prod_{a \in J} M_a := \{ (m_a)_{a \in J} \mid m_a \in M_a \}
      \]
      with addition defined by
      \[
        (m_a)_{a \in J}+(n_a)_{a \in J} := (m_a+n_a)_{a \in J}
      \]
      and \(R\)-action defined by \[
        r(m_a)_{a \in J} = (rm_a)_{a \in J}.
      \]
    </p>
    <p>
      The <strong>direct sum</strong> of the \(R\)-modules \(M_a\) is the \(R\)-submodule \(\bigoplus_{a \in J} M_a\) of the direct product \(\prod_{a \in J} M_a\) given by
      \[
        \bigoplus_{a \in J} M_a = \{(m_a)_{a \in J} \mid m_a = 0 \text{ for all but finitely many } a \}.
      \]
    </p>
  </section>

  <section class="callout exercise" role="region" aria-labelledby="ex-11-4-20">
    <h3 id="ex-11-4-20">Exercise 11.4.20</h3>
    <p>
      The direct sum and the direct product of an arbitrary family of \(R\)-modules are \(R\)-modules.
    </p>
  </section>

  <section class="callout example" role="region" aria-labelledby="ex-11-4-21">
    <h3 id="ex-11-4-21">Example 11.4.21</h3>
    <p>
      Suppose that \(|A| = n &lt; \infty\). Let \(M_1,\ldots,M_n\) be \(R\)-modules. The direct product module \(M_1 \times \dots \times M_n\) is the abelian group \(M_1 \times \dots \times M_n\) with ring action given by \(r(m_1,\ldots,m_n) = (rm_1,\ldots,rm_n)\) for all \(r \in R\) and \(m_i \in M_i\). Comparing the definitions we see  that
      \[
        M_1 \times \dots \times M_n = M_1 \oplus \dots \oplus M_n.
      \]
    </p>
    <p>
      If \(M_i=R\) for \(1 \leqslant i \leqslant n\), then we denote \(R^n = \underbrace{R\times  \dots \times R}_n=\underbrace{R\oplus  \dots \oplus R}_n\).
    </p>
  </section>

  <p>
    It is useful to talk about maps from the factors/summands to the direct product/ direct sum and conversely.
  </p>

  <section class="callout definition" role="region" aria-labelledby="def-11-4-22">
    <h3 id="def-11-4-22">Definition 11.4.22</h3>
    <p>
      For \(i\in J\) the <em>inclusion of the \(i\)-th factor</em> into a direct product or direct sum is the map
      \[
        \iota_i\!: M_i \to \prod_{a \in J} M_a \text{ or } \iota_i\!: M_i \to \bigoplus_{a \in J} M_a, \iota_i(m)=(m_a)_{a \in J}, \text{ where } m_a=\begin{cases} m & \text{ if } a = i \\ 0 & \text{ if } a \neq i \end{cases}.
      \]
    </p>
    <p>
      For \(i\in J\) the \(i\)-th <em>projection map</em> from a direct product or a direct sum module is
      \[
        \pi_i\!: \prod_{a \in J} M_a \to M_i \text{ or } \pi_i:\bigoplus_{a \in J} M_a \to M_i, \pi_i \left((m_a)_{a \in J}\right)=m_i.
      \]
    </p>
  </section>

  <section class="callout lemma" role="region" aria-labelledby="lem-11-4-23">
    <h3 id="lem-11-4-23">Lemma 11.4.23</h3>
    <p>
      Projections from direct products or sums of \(R\)-module, inclusions into direct products or sums of \(R\)-modules, and products of \(R\)-module homomorphisms are \(R\)-module homomorphisms. Furthermore, inclusions are injective, projections are surjective, and
      \[
        \pi_i\circ \iota_i=\mathrm{id}_{M_i}.
      \]
      Also, \(\iota_i(M_i)\) is an \(R\)-submodule of the direct product/sum which is isomorphic to \(M_i\).
    </p>
  </section>

  <p>
    Note, however, that \(\iota_i\circ\pi_i\neq \mathrm{id}\).
  </p>
</section>





<h1 id="lecture-heading">12. Vector Spaces</h1>

<p> We now turn our focus to vector spaces: modules over fields.

    </p>

<section id="sec-12-1" class="section" aria-labelledby="sec-12-1-title">
  <h2 id="sec-12-1-heading">12.1 Classification of vector spaces and dimension</h2>

  <p>
    Recall that for a subset \(A\) of an \(F\)-vector space \(V\), the <strong>span</strong> of \(A\), denoted \(\mathrm{span}(A)\), is the subspace generated by \(A\):
  </p>
  \[
    \mathrm{span}(A) := \left\{\sum_{i=1}^n c_i a_i \mid n \geqslant 0, c_i\in F, a_i \in A \right\}.
  \]

  <section id="lem-12-1-1" class="callout lemma" aria-labelledby="lem-12-1-1-title">
    <h3 id="lem-12-1-1-title">Lemma 12.1.1</h3>
    <div class="callout-body">
      <p>
        Suppose \(I\) is a linearly independent subset of an \(F\)-vector space \(V\) and \(v \in V \setminus \mathrm{span}(I)\), then \(I \cup \{v\}\) is also linearly independent.
      </p>
    </div>
  </section>

  <section id="proof-lem-12-1-1" class="callout proof" aria-labelledby="proof-lem-12-1-1-title">
    <h3 id="proof-lem-12-1-1-title">Proof of Lemma 12.1.1</h3>
    <div class="callout-body">
      <p>
        Let \(w_1, \dots, w_n\) be any list of distinct elements of \(I \cup \{v\}\) and suppose that \(\sum_i c_i w_i = 0\) for some \(c_i \in F\).
        If none of the \(w_i\)'s is equal to \(v\), then \(c_i = 0\) for all \(i\), since \(I\) is linearly independent. Without loss of generality, say \(w_1 = v\). If \(c_1 = 0\) then \(c_i = 0\) for all \(i\) by the same reasoning as in the previous case. If \(c_1 \ne 0\), then
      </p>
      \[
        v = \sum_{i \geqslant 2} \frac{-c_i}{c_1} w_i \in \mathrm{span}(I),
      \]
      <p>
        contrary to assumption. This proves that \(I \cup \{v\}\) is a linearly independent set.
      </p>
    </div>
  </section>

  <section id="thm-12-1-2" class="callout theorem" aria-labelledby="thm-12-1-2-title">
    <h3 id="thm-12-1-2-title">Theorem 12.1.2</h3>
    <div class="callout-body">
      <p>
        Let \(V\) be an \(F\)-vector space and assume \(I \subseteq S \subseteq V\) are subsets such that \(I\) is linearly independent and \(S\) spans \(V\). Then there is a subset \(B\) with \(I \subseteq B \subseteq S\) such that \(B\) is a basis.
      </p>
    </div>
  </section>

  <p>Before we prove this theorem, we note the following corollary:</p>

  <section id="cor-12-1-3" class="callout corollary" aria-labelledby="cor-12-1-3-title">
    <h3 id="cor-12-1-3-title">Corollary 12.1.3 (Every vector space has a basis)</h3>
    <div class="callout-body">
      <p>
        Every vector space \(V\) has a basis, and hence is a free module. Moreover, every linearly independent subset of \(V\) is contained in some basis, and every set of vectors that spans \(V\) contains some basis.
      </p>
    </div>
  </section>

  <section id="proof-cor-12-1-3" class="callout proof" aria-labelledby="proof-cor-12-1-3-title">
    <h3 id="proof-cor-12-1-3-title">Proof of Corollary 12.1.3</h3>
    <div class="callout-body">
      <p>
        For this first part, apply the theorem with \(I = \varnothing\) and \(S = V\). For the second and third, use \(I\) arbitrary and \(S = V\) and \(I = \varnothing\) and \(S\) arbitrary, respectively.
      </p>
    </div>
  </section>

  <section id="ex-12-1-4" class="callout example" aria-labelledby="ex-12-1-4-title">
    <h3 id="ex-12-1-4-title">Example 12.1.4</h3>
    <div class="callout-body">
      <p>
        \(\mathbb{R}\) has a basis as a \(\mathbb{Q}\)-vector space; just don't ask me what it looks like.
      </p>
    </div>
  </section>

  <section id="proof-thm-12-1-2" class="callout proof" aria-labelledby="proof-thm-12-1-2-title">
    <h3 id="proof-thm-12-1-2-title">Proof of Theorem 12.1.2</h3>
    <div class="callout-body">
      <p>
        Let \(\mathcal{P}\) denote the collection of all subsets \(X\) of \(V\) such that \(I \subseteq X \subseteq S\) and \(X\) is linearly independent. We make \(\mathcal{P}\) into a poset by the order relation given by set containment \(\subseteq\). We note that \(\mathcal{P}\) is not empty since, for example \(I \in \mathcal{P}\).
      </p>

      <p>
        Let \(\mathcal{T}\) be any nonempty chain in \(\mathcal{P}\). Let \(Z = \bigcup_{Y \in \mathcal{T}} Y\). We claim \(Z \in \mathcal{P}\). Given \(z_1, \dots, z_m \in Z\), for each \(i\) we have \(z_i \in Y_i\) for some \(Y_i \in T\). Since \(T\) is totally ordered, one of \(Y_1, \dots, Y_m\) contains all the others and hence contains all the \(z_i\)'s.
        Since \(Y_i\) is linearly independent, this shows \(z_1, \dots, z_m\) are linearly independent. Thus \(Z\) is linearly independent. Since \(\mathcal{T}\) is non-empty, \(Z \supseteq I\) and hence \(Z \in \mathcal{P}\). It is an upper bound for \(\mathcal{T}\) by construction.
      </p>

      <p>
        By Zorn's Lemma, \(\mathcal{P}\) has a maximal element \(B\), which we claim is a basis for \(V\). Note that \(B\) is linearly independent and \(I \subseteq B \subseteq S\) by construction. We need to show that it spans \(V\). Suppose not. Since \(S\) spans \(V\), if \(S \subseteq \mathrm{span}(B)\), then \(\mathrm{span}(B)\) would have to be all of \(V\). So, there is at least one \(v \in S\) such that \(v \notin \mathrm{span}(B)\), and set \(X := B \cup \{v\}\).
        Clearly, \(I \subset X \subseteq S\) and, by Lemma 12.1.1, \(X\) is linearly independent. This shows that \(X\) is an element of \(\mathcal{P}\) that is strictly bigger than \(B\), contrary to the maximality of \(B\).
      </p>
    </div>
  </section>

  <section id="cor-12-1-5" class="callout corollary" aria-labelledby="cor-12-1-5-title">
    <h3 id="cor-12-1-5-title">Corollary 12.1.5</h3>
    <div class="callout-body">
      <p>
        Let \(F\) be a field and \(W\) be a subspace of the \(F\)-vector space \(V\). Then every basis of \(W\) extends to a basis of \(V\), that is, if \(B\) is a basis of \(W\) then there exists a basis \(\tilde{B}\) of \(V\) such that \(B\) is a subset of \(\tilde{B}\).
      </p>
    </div>
  </section>

  <section id="proof-cor-12-1-5" class="callout proof" aria-labelledby="proof-cor-12-1-5-title">
    <h3 id="proof-cor-12-1-5-title">Proof of Corollary 12.1.5</h3>
    <div class="callout-body">
      <p>
        Apply Theorem 12.1.2 with \(B = I\) and \(S = V\). Since \(B\) is a basis of \(W\), \(B\) is linearly independent, and \(B\) remains linearly independent when regarded as a subset of \(V\).
      </p>
    </div>
  </section>

  <section id="rmk-12-1-6" class="callout remark" aria-labelledby="rmk-12-1-6-title">
    <h3 id="rmk-12-1-6-title">Remark 12.1.6</h3>
    <div class="callout-body">
      <p>
        It is <em>not</em> true that, with the notation of the previous Corollary, if \(\tilde{B}\) is a basis of \(V\) then there exists a basis \(B\) of \(W\) such that \(B\) is a subset of \(\tilde{B}\). For instance, take \(F = \mathbb{R}\), \(V = \mathbb{R}^2\), \(\tilde{B} = \{(1,0), (0,1)\}\) and \(W\) the subspace spanned by \((1,1)\).
      </p>
    </div>
  </section>


  <p>
    The following is an essential property of vector spaces that eventually will allow us to compare bases in terms of size.
  </p>

  <section id="lem-12-1-8" class="callout lemma" aria-labelledby="lem-12-1-8-title">
    <h3 id="lem-12-1-8-title">Lemma 12.1.7 (Exchange Property)</h3>
    <div class="callout-body">
      <p>
        Let \(B\) be a basis for a vector space \(V\) and consider any set of linearly independent vectors \(I \subseteq V\). Then there is a subset \(A \subseteq B\) such that 
<ul><li>\(|I|=|A|\) (meaning that there is a bijection \( I \leftrightarrow A\)), and</li>
<li> \((B \smallsetminus A) \cup I\) is also a basis for \(V\).</li></ul>
      </p>
    </div>
  </section>

  <section id="proof-lem-12-1-7" class="callout proof" aria-labelledby="proof-lem-12-1-8-title">
    <h3 id="proof-lem-12-1-7-title">Proof of Lemma 12.1.7</h3>
    <div class="callout-body">
      <p>
        First we show we can swap out one element of \(B\) for one nonzero element \(\{v\}\). In this case, we will show the stronger statement that for any subset \(B_0 \subseteq B\), and any element \(a\notin \mathrm{span}(B_0)\), there is some \(b\in B\smallsetminus B_0\) such that \(B\smallsetminus \{b\} \cup \{v\}\) is a basis for \(V\).
      </p>

      <p>
        Since \(B\) is a basis, we can write
      </p>
      \[
        v = \sum_i \lambda_i b_i
      \]
      <p>
        for some elements \(b_i \in B\). Since \(v\notin \mathrm{span}(B_0)\), we have \(\lambda_i\neq 0\) for some \(b_i\notin B_0\); say \(\lambda_1\neq 0\). We claim that \(B' := B\smallsetminus \{ b_1\} \cup \{v\}\) is a basis.
      </p>

      <p>
<i>\(B'\) is linearly independent:</i> By Lemma 12.1.1, it suffices to show that \(v\notin \mathrm{span}(B\smallsetminus \{b_1\})\). Indeed, if it were, then writing \(v\) as a linear combination of \(B\smallsetminus \{b_1\}\) and the linear combination \(v = \sum_i \lambda_i b_i\) with \(b_1\neq 0\) would give two different expressions of \(v\) in the basis \(B\), a contradiction.
      </p>

      <p>
     <i>\(B'\) spans \(V\):</i> First, we note that it suffices to show that \(b_1\) in the span of \(V\): once we have shown this, we can write any element of \(V\) as a linear combination of elements of \(B\), and just replace the term with \(b_1\) with a linear combination of elements of \(B'\) by substituting. To this end, by the contrapositive of Lemma 12.1.1, it suffices to show that \(B' \cup \{b_1\}\) is not linearly dependent, and our starting expression \(v = \sum_i \lambda_i b_i\) does this.
      </p>
This concludes the case of one element. For the general case, we set up a Zorn's Lemma argument.

      <p>
        Consider the collection of pairs \((I', A')\) with \(I' \subseteq I\), \(A' \subseteq A\), and \(|I'|=|A'|\) with the property that \(B\smallsetminus A' \cup I'\) is a basis for \(V\). By a Zorn's Lemma argument (left as an exercise), there is a maximal such pair under the partial order \((I',A')\leq (I'',A'')\) if \(I'\subseteq I''\) and \(A'\subseteq A''\). Let \((I_0,A_0)\) be a maximal element. We will argue that \(I_0=I\).
      </p>

      <p>
        To obtain a contradiction, suppose otherwise, and let \(a\in I \smallsetminus I_0\). Apply the special case above to the basis \((B\smallsetminus A_0) \cup I_0\) and special subset \(I_0\): since \(I\) is linearly independent, \(a\notin \mathrm{span}(I_0)\). Then by the special case, there is some \(b\in B\smallsetminus A_0\) such that \( B\smallsetminus (A_0  \cup \{b\}) \cup (I_0 \cup \{a\})\) is a basis. This contradicts the maximality of \((I_0,A_0)\), so we deduce that \(I_0=I\) as required.
      </p>
    </div>
  </section>
</section>


  <p>
    It follows that all bases for the same vector space have the same cardinality.
  </p>

  <section id="thm-12-1-8" class="callout theorem" aria-labelledby="thm-12-1-9-title">
    <h3 id="thm-12-1-8-title">Theorem 12.1.8 (Dimension Theorem)</h3>
    <div class="callout-body">
      <p>
        Let \(V\) be a vector space, and \(B,B'\) be two bases for \(V\). Then \(|B| = |B'|\), meaning there is a bijection \(B\leftrightarrow B'\).
      </p>
    </div>
  </section>

  <section id="proof-thm-12-1-8" class="callout proof" aria-labelledby="proof-thm-12-1-9-title">
    <h3 id="proof-thm-12-1-8-title">Proof of Theorem 12.1.8</h3>
    <div class="callout-body">
      <p>
        Let \(B, B'\) be two bases for \(V\). Applying the Exchange Lemma with \(C=B'\), there is a subset \(C\subseteq B\)
        with \(|C|=|B'|\), so there is an injective map \(B' \hookrightarrow B\). Switching roles, there is an injective map \(B\hookrightarrow B'\). It follows from a result in set theory (the Cantor-Bernstein theorem) that there is a bijection \( B\leftrightarrow B'\).
      </p>
    </div>
  </section>

  <section id="thm-12-1-9" class="callout theorem" aria-labelledby="thm-12-1-9-title">
    <h3 id="thm-12-1-9-title">Corollary 12.1.9</h3>
    <div class="callout-body">
      <p>
        Let \(F\) be a field. Let \(V\) be a vector space with a basis \(B\) and \(V'\) be a vector space with a basis \(B'\). Then
\[ V\cong V' \quad \Longleftrightarrow \quad |B|=|B'|.\]
      </p>
    </div>
  </section>

  <section id="proof-thm-12-1-9" class="callout proof" aria-labelledby="proof-thm-12-1-9-title">
    <h3 id="proof-thm-12-1-9-title">Proof of Corollary 12.1.9</h3>
    <div class="callout-body">
      <p>
        The (\(\Leftarrow\)) implication is a special case of Corollary 11.4.13. For the (\(\Rightarrow\)) implication, we claim that if \(\phi: V\to V'\) is an isomorphism, then \(\phi(B)\) is a basis for \(V'\):</p>

<p><i>\(\phi(B)\) is linearly independent:</i> Let \(\phi(b_1),\dots,\phi(b_n)\in \phi(B)\) and \( \lambda_1 \phi(b_1) + \cdots+ \lambda_n \phi(b_n) = 0\). Then \[ 0=  \lambda_1 \phi(b_1) + \cdots+ \lambda_n \phi(b_n) = \phi(  \lambda_1 b_1 + \cdots+ \lambda_n b_n)\] and \(\phi\) is injective so \( \lambda_1 b_1 + \cdots+ \lambda_n b_n=0\). Since \(B\) is linearly independent, we have \(\lambda_1 = \cdots=\lambda_n=0\).
      </p>

<p><i>\(\phi(B)\) spans \(V'\):</i> Since \(\phi\) is surjective, for any \(v'\in V'\) we can write \(v'=\phi(v)\) for some \(v\in V\). Then we can write \(v=\lambda_1 b_1 + \cdots + \lambda_n b_n\) for some \(\lambda_i\in F\) and \(b_i\in B\), and then 
\[ v' = \phi(v) = \phi(\lambda_1 b_1 + \cdots + \lambda_n b_n) = \lambda_1 \phi(b_1) + \cdots+ \lambda_n \phi(b_n).\]
      </p>

<p>Thus, \(\phi(B)\) is a basis for \(V'\). Since \(\phi\) is a bijection, we have \(|B|=|\phi(B)|\), and by the previous Theorem, \(|\phi(B)|=|B'|\).</p>
    </div>
  </section>

  <section id="def-12-1-10" class="callout definition" aria-labelledby="def-12-1-10-title">
    <h3 id="def-12-1-10-title">Definition 12.1.10</h3>
    <div class="callout-body">
      <p>
        The <strong>dimension</strong> of a vector space \(V\), denoted \(\dim_F(V)\) or \(\dim(V)\), is the cardinality of
        any of its bases.
      </p>
    </div>
  </section>


  <section id="ex-12-1-11" class="callout example" aria-labelledby="ex-12-1-11-title">
    <h3 id="ex-12-1-11-title">Example 12.1.11</h3>
    <div class="callout-body">
      <p>
        \(\dim_F(F^n) = |\{e_1,e_2,\ldots,e_n\}| = n.\)
      </p>
    </div>
  </section>



  <p>
    While one can talk about infinite cardinals, we'll generally say that dimension is a natural number or \(\infty\). We restate the results above specifically in the finite-dimensional case for easy reference.
  </p>

  <section id="thm-12-1-12" class="callout theorem" aria-labelledby="thm-12-1-12-title">
    <h3 id="thm-12-1-12-title">Theorem 12.1.12 (Classification of finite dimensional vector spaces)</h3>
    <div class="callout-body">
      <p>Let \(F\) be a field. Let \(V\) be a vector space of dimension \(n\), and \(W\) be a vector space of dimension \(m\).</p>
      <ol class="enumerate" style="list-style-type: none; padding-left: 0; margin-left: 0;">
        <li>(1) \(V\cong W\) if and only if \(n = m\).</li>
        <li>(2) \(V \cong F^n\).</li>
     <li>(2) \(F^n \cong F^m\) if and only if \(m=n\).</li>
      </ol>
    </div>
  </section>

  <section id="proof-thm-12-1-12" class="callout proof" aria-labelledby="proof-thm-12-1-12-title">
    <h3 id="proof-thm-12-1-12-title">Proof of Theorem 12.1.12</h3>
    <div class="callout-body">
      <p>Part (1) follows from of Corollary 12.1.9. Part (2) and (3) are special cases, in light of Example 12.1.11.</p>
        
    </div>
  </section>

  <section id="rmk-12-1-13" class="callout remark" aria-labelledby="rmk-12-1-13-title">
    <h3 id="rmk-12-1-13-title">Remark 12.1.13</h3>
    <div class="callout-body">
The previous results says in particular that dimension is an isomorphism invariant for a vector space. You will show in the Homework that rank is an isomorphism invariant over commutative rings. 
    </div>
  </section>



  <p>Let us consider a few infinite-dimensional vector spaces.</p>

  <section id="ex-12-1-15" class="callout example" aria-labelledby="ex-12-1-15-title">
    <h3 id="ex-12-1-15-title">Example 12.1.14</h3>
    <div class="callout-body">
      <p>
        Consider the vector space \(F[x]\). This cannot be a finite dimensional vector space. For instance, if
        \(\{f_1 , \dots , f_n\}\) were a basis, then setting
      </p>
      \[
        M = \max_{1 \leqslant j \leqslant n}\{ \deg(f_j)\}
      \]
      <p>
        we see that the element \(x^{M+1}\) is not be in the span of \(\{f_1 , \dots , f_n\}\). We can find a basis for this
        space though. Consider the collection \(B = \{1, x, x^2 , \ldots \}\). This set is linearly independent and spans
        \(F[x]\), thus it forms a basis for \(F[x]\). This basis is <em>countable</em>, so
        \(\dim_F(F[x])= |\mathbb{N}|\).
      </p>
    </div>
  </section>

  <section id="ex-12-1-16" class="callout example" aria-labelledby="ex-12-1-16-title">
    <h3 id="ex-12-1-16-title">Example 12.1.15</h3>
    <div class="callout-body">
      <p>
        Consider the real vector space
      </p>
      \[
        V := \mathbb{R}^\mathbb{N} = \mathbb{R}\times \mathbb{R}\times \mathbb{R} \times \cdots.
      \]
      <p>
        This space can be identified with sequences \(\{a_n\}\) of real numbers. One might be interested in a basis for this
        vector space. At first glance, the most obvious choice for a basis would be \(E = \{e_1,e_2,\ldots\}\). It turns out
        that \(E\) is the basis for the direct sum \(\bigoplus_{i\in \N}\mathbb{R}\). However, it is immediate that this set
        does not span \(V\), as \(v = (1,1,\ldots)\) can not be represented as a finite linear combination of these elements.
        Since \(v\) is not in \(\mathrm{span}(E)\), then we know that \(E \cup \{v\}\) is a linearly independent set.
        However, this new set \(E \cup \{v\}\) does not span \(V\) either, as \((1, 2, 3, 4, \ldots)\) is not in the span of
        \(E \cup \{v\}\). We know that \(V\) has a basis, but it can be shown that no countable collection of vectors forms a
        basis for this space, and in fact \(\dim_\mathbb{R} (\mathbb{R}^\mathbb{N}) =|\mathbb{R}|\).
      </p>
    </div>
  </section>

  <section id="ex-12-1-17" class="callout example" aria-labelledby="ex-12-1-17-title">
    <h3 id="ex-12-1-17-title">Example 12.1.17</h3>
    <div class="callout-body">
      <p>
Since \(\mathbb{Q}\) is a subring of \(\mathbb{R}\), we have that \(\mathbb{R}\) is a \(\mathbb{Q}\)-vector space, and likewise with \(\mathbb{C}\).

        One can show that \(\dim_{\mathbb{Q}}(\mathbb{R})=|\mathbb{R}|\), and \(\dim_{\mathbb{Q}}(\mathbb{C})=|\mathbb{C}| = |\mathbb{R}|\), so \(\mathbb{R}\cong \mathbb{C}\) as \(\mathbb{Q}\)-vector spaces. In particular, \((\mathbb{R},+)\cong (\mathbb{C},+)\) as groups.
      </p>
    </div>
  </section>

  <p>
    We now deduce some formulas that relate the dimensions of various vector spaces.
  </p>

  <section id="thm-12-1-18" class="callout theorem" aria-labelledby="thm-12-1-18-title">
    <h3 id="thm-12-1-18-title">Theorem 12.1.18</h3>
    <div class="callout-body">
      <p>
        Let \(W\) be a subspace of a vector space \(V\). Then
        \[
          \dim(V) = \dim(W) + \dim(V/W).
        \]
      </p>
    </div>
  </section>

  <p>
    Here the dimension of a vector space is understood to be either a nonnegative integer or \(\infty\), and the arithmetic
    of the formula is understood to follow the rules \(n+\infty=\infty=\infty+\infty\) for any
    \(n\in \mathbb{Z}_{\geqslant 0}\). The proof follows from the Problem #1 in Problem Set #2.
  </p>

  <section id="ex-12-1-19" class="callout example" aria-labelledby="ex-12-1-19-title">
    <h3 id="ex-12-1-19-title">Example 12.1.19</h3>
    <div class="callout-body">
      <p>
        Consider the vector space \(V = \mathbb{R}^2\) and its subspace \(W=\mathrm{span}\{e_1\}\). Then the quotient vector
        space \(V/W\) is, by definition,
      </p>
      \[
        V/W=\{(x,y)+W \mid (x,y)\in \mathbb{R}^2\}.
      \]
      <p>
        Looking at each coset we see that
      </p>
      \[
        (x,y)+W=(x,y)+\mathrm{span}\{e_1\}=\{(x,y)+(a,0)\mid a\in \mathbb{R}\}=\{(t,y)\mid t\in \mathbb{R}\},
      \]
      <p>
        so \((x,y)+W\) is geometrically a line parallel to the \(x\)-axis and having the \(y\)-intercept \(y\). It is
        intuitively natural to identify such a line with its intercept, which gives a map
      </p>
      \[
        V/W\to \mathrm{span}\{e_2\} \quad (x,y)+W \mapsto (0,y).
      \]
      <p>
        It turns out that this map is a vector space isomorphism, hence
        \[
          \dim(V/W) = \dim(\mathrm{span}\{e_2\}) = 1
        \]
        and we can check that
        \[
          \dim(W) + \dim(V/W) = 1+1 = 2 = \dim(V).
        \]
      </p>
    </div>
  </section>

  <p>
    If \(V\) and \(W\) are both infinite dimensional vector spaces, it can happen that \(V/W\) is finite dimensional but
    also that it is infinite dimensional.
  </p>

  <section id="ex-12-1-20" class="callout example" aria-labelledby="ex-12-1-20-title">
    <h3 id="ex-12-1-20-title">Example 12.1.20</h3>
    <div class="callout-body">
      <p>
        Let \(V=F[x]\), which we saw in Example 12.1.15 is an infinite dimensional vector space over \(F\). Fix a polynomial
        \(f\) with \(\deg(f)=d\), and note that the ideal \((f)\) of \(F[x]\) generated by \(f\) is also an \(F\)-vector
        subspace of \(F[x]\) via restriction of scalars. We will show later that \(\dim(F[x]/(f))=d\). In contrast, the
        subspace \(E\) of all even degree polynomials in \(F[x]\) together with the zero polynomial satisfies
        \(\dim(F[x]/E)=\infty\).
      </p>
    </div>
  </section>

  <section id="def-12-1-21" class="callout definition" aria-labelledby="def-12-1-21-title">
    <h3 id="def-12-1-21-title">Definition 12.1.21</h3>
    <div class="callout-body">
      <p>
        Let \(T\!: V \to W\) be a linear transformation. The <strong>nullspace</strong> of \(T\) is \(\ker(T)\). The
        <strong>rank</strong> of \(T\) is \(\dim(\mathrm{im}(T))\).
      </p>
    </div>
  </section>

  <section id="cor-12-1-22" class="callout corollary" aria-labelledby="cor-12-1-22-title">
    <h3 id="cor-12-1-22-title">Corollary 12.1.22 (Rank-Nullity Theorem)</h3>
    <div class="callout-body">
      <p>
        Let \(f\!: V \to W\) be a linear transformation. Then
        \[
          \dim(\ker(f)) + \dim(\mathrm{im}(f)) = \dim(V).
        \]
      </p>
    </div>
  </section>

  <section id="proof-cor-12-1-22" class="callout proof" aria-labelledby="proof-cor-12-1-22-title">
    <h3 id="proof-cor-12-1-22-title">Proof of Corollary 12.1.22</h3>
    <div class="callout-body">
      <p>
        By the First Isomorphism Theorem for modules we have \(V/\ker(f)\cong\mathrm{im}(f)\),
        thus
        \[
          \dim\left(V/\ker(f)\right)=\dim(\mathrm{im}(V)).
        \]
        By Theorem 12.1.18, we have
        \[
          \dim(V)=\dim(\ker(V))+\dim\left(V/\ker(f)\right).
        \]
        Thus
        \[
          \dim(V)=\dim(\ker(V))+\dim\left(V/\ker(f)\right) = \dim(\ker(V)) + \dim(\mathrm{im}(V)).
        \]
      </p>
    </div>
  </section>


<section id="sec-12-2" class="section" aria-labelledby="sec-12-2-title">
  <h2 id="sec-12-2-title">12.2 Linear transformations and homomorphisms between free modules</h2>

  <section id="def-12-2-1" class="callout definition" aria-labelledby="def-12-2-1-title">
    <h3 id="def-12-2-1-title">Definition 12.2.1 (The matrix of a homomorphism between free modules)</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring .
        Let \(V\) be a finitely generated free \(R\)-module of rank \(n\), and let \(W\) be a finitely generated free \(R\)-module of rank \(m\). Let \(B=\{b_1, \dots, b_n\}\) and \(C=\{c_1, \dots, c_m\}\) be <em>ordered</em> bases of \(V,W\).
        Given an \(R\)-module homomorphism \(f: V \to W\), we define elements \(a_{ij}\in R\) for \(1 \leqslant i \leqslant m\) and \(1 \leqslant j \leqslant n\) by the formulas
      </p>

      \[
        f(b_i) = \sum_{j=1}^m a_{j,i} c_j.
        \tag{12.2.1}\label{eq-12-2-aij}
      \]

      <p>
        The matrix
      </p>

      \[
        [f]_B^C=
        \begin{bmatrix}
        a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
        a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{m,1} & a_{m,2} & \cdots & a_{m,n} \\
        \end{bmatrix}
      \]

      <p>
        is said to <strong>represent</strong> the homomorphism \(f\) with respect to the bases \(B\) and \(C\).
      </p>
    </div>
  </section>

  <section id="rmk-12-2-2" class="callout remark" aria-labelledby="rmk-12-2-2-title">
    <h3 id="rmk-12-2-2-title">Remark 12.2.2</h3>
    <div class="callout-body">
      <p>
        By Lemma 11.4.11, the coefficients \(a_{j,i}\) in equation \(\eqref{eq-12-2-aij}\) are uniquely determined by the \(f(b_i)\) and the elements of \(C\).
        The coefficients \(a_{j,i}\) corresponding to \(f(b_i)\) form the \(i\)th column of \([f]_B^C\).
        Note that \([f]_B^C\) is an \(m\times n\) matrix with entries in \(R\).
      </p>
    </div>
  </section>

  <section id="def-12-2-3" class="callout definition" aria-labelledby="def-12-2-3-title">
    <h3 id="def-12-2-3-title">Definition 12.2.3</h3>
    <div class="callout-body">
      <p>
        Let \(V\) and \(W\) be finite \(F\)-vector spaces of dimension \(n\) and \(m\) with ordered bases \(B\) and \(C\), respectively, and let \(f\!:V\to W\) be a linear transformation. The matrix \([f]_B^C\) is called the <strong>matrix of the linear transformation</strong> \(f\) with respect to the bases \(B\) and \(C\).
      </p>
    </div>
  </section>

  <section id="ex-12-2-4" class="callout example" aria-labelledby="ex-12-2-4-title">
    <h3 id="ex-12-2-4-title">Example 12.2.4</h3>
    <div class="callout-body">
      <p>
        If \(\mathrm{id}_V\!: V \to V\) is the identity automorphism of an \(n\)-dimensional free \(R\)-module \(V\), then for any basis \(B\) of \(V\) we have \(\mathrm{id}_V(b_i) = b_i\) for all \(i\) and hence
      </p>
      \[
        [\mathrm{id}_V]^B_B = I_n.
      \]
    </div>
  </section>

  <section id="ex-12-2-5" class="callout example" aria-labelledby="ex-12-2-5-title">
    <h3 id="ex-12-2-5-title">Example 12.2.5</h3>
    <div class="callout-body">
      <p>
        Let \(P_3\) denote the the \(F\)-vector space of polynomials of degree at most 3 (including the zero polynomial) and consider the linear transformation \(d:P_3\to P_3\) given by taking the derivative \(d(f)=f'\). Let \(B=\{1,x,x^2,x^3\}\). Then
      </p>
      \[
        [f]_B^B=
        \begin{bmatrix}
        0 & 1 &0 & 0 \\
        0 &0 & 2 & 0 \\
        0& 0& 0& 3 \\
        0 & 0 &0 & 0 \\
        \end{bmatrix}.
      \]
    </div>
  </section>

  <section id="ex-12-2-6" class="callout example" aria-labelledby="ex-12-2-6-title">
    <h3 id="ex-12-2-6-title">Example 12.2.6</h3>
    <div class="callout-body">
      <p>
        Let \(F\) be a field and consider a linear transformation \(f\!:V\to W\), where \(V=F^n\) and \(W=F^m\). Consider also the standard ordered bases \(B\) and \(C\), i.e. \(b_i=e_i\in V\) and \(c_i=e_i\in W\). Then for any
      </p>
      \[
        v =
        \begin{bmatrix}
        \ell_1\\
        \vdots\\
        \ell_n
        \end{bmatrix}
        =\sum_i \ell_i b_i
      \]
      <p>
        in \(V\) we have
      </p>
      \[
        f \left( \sum \ell_i b_i \right) = \sum_i \ell_i f(b_i).
      \]
      <p>
        Each \(f(b_i)\) can be written uniquely as a linear combination of the \(c_j\)'s as in \(\eqref{eq-12-2-aij}\):
      </p>
      \[
        f(b_i) = \sum_j a_{j,i} c_j.
      \]
      <p>
        Then we get
      </p>
      \[
        f(v) = \sum_i\ell_i\left( \sum_{j} a_{j,i} c_j \right)= \sum_j \left(\sum_i a_{j,i} \ell_i\right) c_j.
      \]
      <p>
        In other words, we have
      </p>
      \[
        f(v) =
        \begin{bmatrix}
        \sum_i a_{1,i} \ell_i \\
        \vdots\\
        \sum_i a_{m,i} \ell_i
        \end{bmatrix}
        =
        \begin{bmatrix}
        a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
        a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{m,1} & a_{m,2} & \cdots & a_{m,n} \\
        \end{bmatrix}
        \cdot
        \begin{bmatrix} \ell_1\\\vdots\\ \ell_n\end{bmatrix}
        =[f]_B^C\cdot v.
      \]
      <p>
        This says that any linear transformation \(f\!:F^n\to F^m\) is given by multiplication by a matrix, since we noticed above that \(f(v) = [f]_B^C\cdot v\). The same type of statement holds for free modules over commutative rings, and we will show it below in Proposition 12.2.7.
      </p>
    </div>
  </section>

  <section id="prop-12-2-7" class="callout theorem" aria-labelledby="prop-12-2-7-title">
    <h3 id="prop-12-2-7-title">Proposition 12.2.7</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring . Let \(V\) and \(W\) be finitely generated free \(R\)-modules of ranks \(n\) and \(m\) respectively. Fixing ordered bases \(B\) for \(V\) and \(C\) for \(W\) gives an isomorphism of \(R\)-modules
      </p>
      \[
        \mathrm{Hom}_R(V, W) \cong \mathrm{Mat}_{m,n}(R) \qquad f\mapsto [f]_B^C.
      \]
      <p>
        If \(V=W\), so that in particular \(m=n\), and \(B=C\), then the above map is an \(R\)-module isomorphism \(\mathrm{End}_R(V)\cong\mathrm{Mat}_n(R)\), and an isomorphism of rings as well.
      </p>
    </div>
  </section>

  <section id="proof-prop-12-2-7" class="callout proof" aria-labelledby="proof-prop-12-2-7-title">
    <h3 id="proof-prop-12-2-7-title">Proof of Proposition 12.2.7</h3>
    <div class="callout-body">
      <p>
        Let \(\varphi\!:\mathrm{Hom}_R(V, W) \to \mathrm{Mat}_{m,n}(R)\) be defined by \(\varphi(f)=[f]_B^C\).
        We need to check that \(\varphi\) is a homomorphism of \(R\)-modules, which translates into \([f+g]_B^C=[f]_B^C+[g]_B^C\) and \([\lambda f]_B^C=\lambda[f]_B^C\) for any \(f,g \in \mathrm{Hom}_R(V, W)\) and \(\lambda\in R\).
        Let \(A=[f]_B^C\) and \(A'=[g]_B^C\). Then
      </p>
      \[
        (f+g)(b_i)=f(b_i)+g(b_i)= \sum_j a_{j,i} c_j+ \sum_j a'_{j,i} c_j= \sum_j (a_{j,i}+a'_{i,j}) c_j
      \]
      <p>
        gives \([f+g]_B^C=A+A'\) and
      </p>
      \[
        (\lambda f)(b_i)=\lambda\left( \sum_j a_{j,i} c_j\right)= \sum_j (\lambda a_{j,i}) c_j
      \]
      <p>
        gives \([\lambda f]_B^C=\lambda A\).
        We leave the proof that for \(f,g\in \mathrm{End}_R(V)\) we have \([f\circ g]_B^B=[f]_B^B[g]_B^B\) as an exercise.
      </p>

      <p>
        Finally, the argument described in Example 12.2.6 also works for any ring \(R\), and it can be adapted for any two chosen basis \(B\) and \(C\), showing that \(\varphi\) is a bijection.
      </p>
    </div>
  </section>

  <section id="cor-12-2-8" class="callout corollary" aria-labelledby="cor-12-2-8-title">
    <h3 id="cor-12-2-8-title">Corollary 12.2.8</h3>
    <div class="callout-body">
      <p>
        For any field \(F\) and finite \(F\)-vector spaces \(V\) and \(W\) of dimension \(n\) and \(m\) respectively, \(\dim(\mathrm{Hom}_F(V, W))=mn\).
      </p>
    </div>
  </section>

  <section id="proof-cor-12-2-8" class="callout proof" aria-labelledby="proof-cor-12-2-8-title">
    <h3 id="proof-cor-12-2-8-title">Proof of Corollary 12.2.8</h3>
    <div class="callout-body">
      <p>
        The isomorphism \(\mathrm{Hom}_F(V, W) \cong \mathrm{Mat}_{m,n}(F)\) gives
      </p>
      \[
        \dim \left(\mathrm{Hom}_F(V, W) \right) = \dim \left( \mathrm{Mat}_{m,n}(F) \right)=mn.
      \]
    </div>
  </section>

 To explain in what sense the matrix \([f]_B^C\) represents the linear transformation \(f\), it is convenient to use the notion of coordinates with respect to a basis. We prepare for this with an exercise that we will also reuse later.


<section id="ex-12-2-9" class="callout exercise" aria-labelledby="ex-12-2-9-title">
  <h3 id="ex-12-2-9-title">Exercise 12.2.9</h3>
  <div class="callout-body">
    <p>
      Let \(R\) be a commutative ring and \(V\) be a free module with a basis \(B\).
      Let \(M\) be an arbitrary \(R\)-module and let \(\phi: V\to M\) be an \(R\)-module homomorphism. Then:
    </p>
    <ol>
      <li>\(\phi\) is injective if and only if \(\phi(B)\) is linearly independent.</li>
      <li>\(\phi\) is surjective if and only if \(\phi(B)\) generates \(M\).</li>
      <li>\(\phi\) is an isomorphism if and only if \(\phi(B)\) is a basis for \(M\).</li>
    </ol>
  </div>
</section>

<section id="def-12-2-10" class="callout definition" aria-labelledby="def-12-2-10-title">
  <h3 id="def-12-2-10-title">Definition 12.2.10</h3>
  <div class="callout-body">
    <p>
      Let \(R\) be a commutative ring and \(V\) be a free module with basis
      \(B=\{b_1,\dots,b_n\}\).
      Consider the \(R\)-module homomorphism \(\phi:V\to R^n\) with
      \(\phi(b_i)=e_i\).
      There is a unique such map by the UMP for free modules, and it is an
      isomorphism by the previous exercise.
      We call \(\phi(v)\) the <strong>vector of \(B\)-coordinates</strong> of \(v\),
      denoted \([v]_B\).
    </p>
  </div>
</section>

<section id="rmk-12-2-11" class="callout remark" aria-labelledby="rmk-12-2-11-title">
  <h3 id="rmk-12-2-11-title">Remark 12.2.11</h3>
  <div class="callout-body">
    <p>
      Note that
    </p>
    \[
      [v]_B = (r_1,\dots,r_n) \Longleftrightarrow
      v = r_1 b_1 + \cdots + r_n b_n,
    \]
    <p>
      since
      \(\phi(r_1 b_1 + \cdots + r_n b_n)
        = r_1 e_1 + \cdots + r_n e_n
        = (r_1,\dots,r_n)\)
      and \(\phi\) is injective.
    </p>
  </div>
</section>

<section id="prop-12-2-12" class="callout proposition" aria-labelledby="prop-12-2-12-title">
  <h3 id="prop-12-2-12-title">Proposition 12.2.12</h3>
  <div class="callout-body">
    <p>
      Let \(R\) be a commutative ring.
      Let \(V\) be a free module with ordered basis \(B\) and \(W\) be a free module
      with ordered basis \(C\).
      Let \(f:V\to W\) be a linear transformation. Then
    </p>
    \[
      [f(v)]_C = [f]_B^C \cdot [v]_B
    \]
    <p>
      for all \(v\in V\).
    </p>
  </div>
</section>

<section id="proof-prop-12-2-12" class="callout proof" aria-labelledby="proof-prop-12-2-12-title">
  <h3 id="proof-prop-12-2-12-title">Proof of Proposition 12.2.12</h3>
  <div class="callout-body">
    <p>
      Let \(v\in V\) and write \([v]_B = (r_1,\dots,r_n)\), so
      \(v=\sum_j r_j b_j\).
      Write \([f]_B^C=[a_{i,j}]\).
      Then
    </p>
    \[
      f(v)
      = f\!\left(\sum_j r_j b_j\right)
      = \sum_j r_j f(b_j)
      = \sum_j r_j \left(\sum_i a_{i,j} c_i\right)
      = \sum_i \left(\sum_j a_{i,j} r_j\right) c_i.
    \]
    <p>
      Thus the \(i\)-th entry of \([f(v)]_C\) is \(\sum_j a_{i,j} r_j\).
      On the other hand, multiplying out
      \([f]_B^C \cdot [v]_B = [a_{i,j}](r_1,\dots,r_n)\),
      the \(i\)-th entry is also \(\sum_j a_{i,j} r_j\).
    </p>
  </div>
</section>

</section>


<section id="sec-12-3" class="section" aria-labelledby="sec-12-3-title">
  <h2 id="sec-12-3-title">12.3 Change of basis</h2>

  <section id="def-12-3-1" class="callout definition" aria-labelledby="def-12-3-1-title">
    <h3 id="def-12-3-1-title">Definition 12.3.1</h3>
    <div class="callout-body">
      <p>
        Let \(V\) be a finitely generated free module over a commutative ring \(R\), and let \(B\) and \(C\) be bases of \(V\). Let \(\mathrm{id}_V\) be the identity map on \(V\). Then \([\mathrm{id}_V]_B^{C}\) is a matrix called the <strong>change of basis matrix</strong> from \(B\) to \(C\).
      </p>
    </div>
  </section>

  <p>
    In Theorem 12.3.6 we will show that \([\mathrm{id}_V]_B^{C}\) is invertible with inverse \(\left([\mathrm{id}_V]_B^{C}\right)^{-1}=[\mathrm{id}_V]_{C}^B\).
  </p>

  <section id="ex-12-3-2" class="callout example" aria-labelledby="ex-12-3-2-title">
    <h3 id="ex-12-3-2-title">Example 12.3.2</h3>
    <div class="callout-body">
      <p>
        Consider the subspace \(V = P_2\) of \(F[x]\) of all polynomials of degree up to \(2\), and the bases \(B = \{1, x, x^2\}\) and \(C = \{1,x-2,(x-2)^2\}\) of \(V\). We calculate the change of basis matrix. We have
      </p>
      \[
        \begin{aligned}
        \mathrm{id}_V(1) &=1 ,\\
        \mathrm{id}_V(x) &=2\cdot1+1\cdot(x-2), \\
        \mathrm{id}_V(x^2) &=4\cdot1 +4\cdot(x-2)+1\cdot(x-2)^2.
        \end{aligned}
      \]
      <p>
        Thus, the change of basis matrix is given by
        \([\mathrm{id}_V]_B^{C} = \begin{bmatrix}
        1 & 2 & 4\\
        0 & 1 & 4\\
        0 & 0 & 1
        \end{bmatrix}.\)
      </p>
    </div>
  </section>

  <section id="lem-12-3-3" class="callout lemma" aria-labelledby="lem-12-3-3-title">
    <h3 id="lem-12-3-3-title">Lemma 12.3.3</h3>
    <div class="callout-body">
      <p>
        If \(V,W,U\) are finitely generated free \(R\)-modules with ordered bases \(B\), \(C\), and \(D\), respectively, and \(f\!: V \to W\) and \(g\!: W \to U\) are \(R\)-module homomorphisms, then
        \([g\circ f]_B^D=[g]_C^D \cdot [f]_B^C.\)
      </p>
    </div>
  </section>

  <section id="proof-lem-12-3-3" class="callout proof" aria-labelledby="proof-lem-12-3-3-title">
    <h3 id="proof-lem-12-3-3-title">Proof of Lemma 12.3.3</h3>
    <div class="callout-body">
      <p>
        It suffices to check that \([g\circ f]_B^D \cdot p=[g]_C^D \cdot [f]_B^C \cdot p\) for any \(p\in R^n\) where \(n=\mathrm{rank}(V)\). (In fact, we can just take \(p=e_j\) for each \(j\), since \(Ae_j\) is the \(j\)th column of \(A\).) We can write \(p=[v]_B\) for some \(v\in V\). Then
      </p>
      \[
        [g\circ f]_B^D [v]_B = [(g\circ f)(v)]_D = [g(f(v))]_D = [g]_C^D [f(v)]_C = [g]_C^D ([f]_B^C [v]_B) = ([g]_C^D [f]_B^C) [v]_B.
      \]
    </div>
  </section>

  <section id="def-12-3-4" class="callout definition" aria-labelledby="def-12-3-4-title">
    <h3 id="def-12-3-4-title">Definition 12.3.4</h3>
    <div class="callout-body">
      <p>
        Let \(V\) be a finitely generated free module over a commutative ring \(R\). Two \(R\)-module homomorphisms \(f,g: V \to V\) are <strong>similar</strong> if there is a bijective linear transformation \(h: V \to V\) such that \(g = h\circ f \circ h^{-1}\). Two \(n \times n\) matrices \(A\) and \(B\) with entries in \(R\) are <strong>similar</strong> if there is an invertible \(n \times n\) matrix \(P\) such that \(B = PAP^{-1}\).
      </p>
    </div>
  </section>

  <section id="rmk-12-3-5" class="callout remark" aria-labelledby="rmk-12-3-5-title">
    <h3 id="rmk-12-3-5-title">Remark 12.3.5</h3>
    <div class="callout-body">
      <p>
        For elements \(A,B\in \textrm{GL}_n(R)\), the notions of similar and conjugate are the same.
      </p>
    </div>
  </section>

  <section id="thm-12-3-6" class="callout theorem" aria-labelledby="thm-12-3-6-title">
    <h3 id="thm-12-3-6-title">Theorem 12.3.6</h3>
    <div class="callout-body">
      <p>
        Let \(V, W\) be finitely generated free modules over a commutative ring \(R\), let \(B\) and \(B'\) be bases of \(V\), let \(C\) and \(C'\) be bases of \(W\), and let \(f: V \to W\) be a homomorphism. Then
      </p>
      \[
        [f]_{B'}^{C'} = [\mathrm{id}_W]_C^{C'} [f]_B^C [\mathrm{id}_V]_{B'}^{B}
      \]
      <p>
In particular,
 if \(g\!: V \to V\) is an \(R\)-module homomorphism, then \([g]_B^B\) and \([g]_{B'}^{B'}\) are similar.
      </p>
    </div>
  </section>

  <section id="proof-thm-12-3-6" class="callout proof" aria-labelledby="proof-thm-12-3-6-title">
    <h3 id="proof-thm-12-3-6-title">Proof of Theorem 12.3.6</h3>
    <div class="callout-body">
      <p>
        Since \(f=\mathrm{id}_W\circ f\circ \mathrm{id}_V\), by Lemma 12.3.3 we have
      </p>
      \[
        [f]_{B'}^{C'} = [\mathrm{id}_W]_C^{C'} [f]_B^C [\mathrm{id}_V]_{B'}^{B}.
      \]
      <p>
      <p>
        Now set \(V=W,B=C,B'=C'\) and \(f=g\) in the displayed equation to obtain
      </p>
      \[
        [g]_{B'}^{B'} = [\mathrm{id}_V]_B^{B'} [g]_B^B [\mathrm{id}_V]_{B'}^{B}=P[g]_B^B P^{-1}.
      \]
    </div>
  </section>

  <p>
    We now come to certain special changes of basis and their matrices:
  </p>

  <section id="def-12-3-7" class="callout definition" aria-labelledby="def-12-3-7-title">
    <h3 id="def-12-3-7-title">Definition 12.3.7</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring, let \(M\) be a free \(R\)-module of finite rank \(n\), and let \(B = \{b_1,\dots ,b_n\}\) be an ordered basis for \(M\). An <strong>elementary basis change operation</strong> on the basis \(B\) is one of the following three types of operations to produce a new basis \(B'=\{b'_1,\dots,b'_n\}\):
      </p>
      <ol class="enumerate" style="margin-top:0.25rem;">
        <li>
          Replacing \(b_j\) by \(r b_i + b_j\) for some \(i \neq j\) and some \(r\in R\); that is,  \(b'_j = rb_i + b_j\) and \(b'_k = b_k\) for \(k\neq j\).
        </li>
        <li>
          Replacing \(b_i\) by \(ub_i\) for some \(i\) and some unit \(u\) of \(R\); that is, \(b'_i=  u b_i\) and \(b'_k = b_k\) for \(k\neq i\).
        </li>
        <li>
          Swapping the indices of \(b_i\) and \(b_j\) for some \(i \neq j\); that is, \(b'_i= b_j\), \(b'_j=b_i\), and \(b'_k = b_k\) for \(k\neq i,j\).
        </li>
      </ol>
    </div>
  </section>

  <section id="def-12-3-8" class="callout definition" aria-labelledby="def-12-3-8-title">
    <h3 id="def-12-3-8-title">Definition 12.3.8</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring . An <strong>elementary column operation</strong> on a matrix \(A \in \mathrm{Mat}_{m,n}(R)\) is one of the following three types of operations:
      </p>
      <ol class="enumerate" style="margin-top:0.25rem;">
        <li>Adding an element of \(R\) times a column of \(A\) to a different column of \(A\).</li>
        <li>Multiplying a column of \(A\) by a unit of \(R\).</li>
        <li>Interchanging two columns of \(A\).</li>
      </ol>
      <p>
        We define a <strong>elementary row operation</strong> analogously.
      </p>
    </div>
  </section>

  <section id="def-12-3-9" class="callout definition" aria-labelledby="def-12-3-9-title">
    <h3 id="def-12-3-9-title">Definition 12.3.9</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring. An <strong>elementary matrix</strong> over \(R\) is an \(n \times n\) matrix of one of the following three forms:
      </p>
      <ol class="enumerate" style="margin-top:0.25rem;">
        <li>
          For \(r \in R\) and \(1 \leqslant i,j \leqslant n\) with \(i \neq j\), let \(E_{i,j}(r)\) be the matrix with \(1\)s on the diagonal, \(r\) in the \((i,j)\) position, and \(0\) everywhere else.
        </li>
        <li>
          For \(u \in R^\times\) and \(1\leqslant i \leqslant n\) let \(E_i(u)\) denote the matrix with \((i,i)\) entry \(u\), \((j,j)\) entry \(1\) for all \(j \neq i\), and \(0\) everywhere else.
        </li>
        <li>
          For \(1 \leqslant i,j \leqslant n\) with \(i \neq j\), let \(E_{(i,j)}\) denote the matrix with \(1\) in the \((i,j)\) and \((j,i)\) positions and in the \((l,l)\) positions for all \(l\not \in \{i,j\}\), and \(0\) in all other entries.
        </li>
      </ol>
    </div>
  </section>

  <section id="rmk-12-3-10" class="callout remark" aria-labelledby="rmk-12-3-10-title">
    <h3 id="rmk-12-3-10-title">Remark 12.3.10</h3>
    <div class="callout-body">
      <p>
        The elementary matrices \(E_i(u)\) and \(E_{(i,j)}\) are symmetric and the transpose of \(E_{i,j}(r)\) is \(E_{j,i}(r)\). In particular, the transpose of an elementary matrix is an elementary matrix.
      </p>
    </div>
  </section>

  <section id="lem-12-3-11" class="callout lemma" aria-labelledby="lem-12-3-11-title">
    <h3 id="lem-12-3-11-title">Lemma 12.3.11</h3>
    <div class="callout-body">
      <p>
        Let \(E\) be an \(n \times n\) elementary matrix.
      </p>
      <ol class="enumerate" style="margin-top:0.25rem;">
        <li>
          \(E\) is the change of basis matrix \([\mathrm{id}]_{B'}^B\) for the corresponding elementary basis change operation from \(B\) to \(B'\).
        </li>
        <li>
          If \(A \in \mathrm{Mat}_{m,n}(R)\), then the result of performing the corresponding elementary column operation on \(A\) is the product matrix \(AE\).
          Explicitly,
          <ul class="itemize" style="margin-top:0.25rem;">
            <li>
              \(AE_{i,j}(r)\) is the matrix obtained from \(A\) by replacing
              \[
                \mathrm{col}_j(A) \quad \rightsquigarrow \quad \mathrm{col}_j(A) + r \cdot \mathrm{col}_i(A).
              \]
            </li>
            <li>
              \(AE_{i}(u)\) is the matrix obtained from \(A\) by replacing
              \[
                \mathrm{col}_i(A)\quad \rightsquigarrow \quad  u \cdot \mathrm{col}_i(A).
              \]
            </li>
            <li>
              \(A E_{(i,j)}\) is the matrix obtained from \(A\) by replacing
              \[
                \begin{aligned} &\mathrm{col}_i(A)\quad \rightsquigarrow \quad  \mathrm{col}_j(A)\\
                 &\mathrm{col}_j(A)\quad \rightsquigarrow \quad  \mathrm{col}_i(A) \end{aligned}
              \]
            </li>
          </ul>
        </li>
        <li>
          If \(B \in \mathrm{Mat}_{n,q}(R)\), then the result of performing the corresponding elementary row operation on \(A\) is the product matrix \(E^T B\).
          Explicitly,
          <ul class="itemize" style="margin-top:0.25rem;">
            <li>
              \(E_{i,j}(r) B\) is the matrix obtained from \(B\) by replacing
              \[
                \mathrm{row}_i(A) \quad \rightsquigarrow \quad \mathrm{row}_i(A) + r \cdot \mathrm{row}_j(A).
              \]
            </li>
            <li>
              \(E_{i}(u) B\) is the matrix obtained from \(B\) by replacing
              \[
                \mathrm{row}_i(A)\quad \rightsquigarrow \quad  u \cdot \mathrm{row}_i(A).
              \]
            </li>
            <li>
              \(E_{(i,j)} B\) is the matrix obtained from \(B\) by replacing
              \[
                \begin{aligned} &\mathrm{row}_i(A)\quad \rightsquigarrow \quad  \mathrm{row}_j(A)\\
                 &\mathrm{row}_j(A)\quad \rightsquigarrow \quad  \mathrm{row}_i(A) \end{aligned}
              \]
            </li>
          </ul>
        </li>
      </ol>
    </div>
  </section>

  <section id="proof-lem-12-3-11" class="callout proof" aria-labelledby="proof-lem-12-3-11-title">
    <h3 id="proof-lem-12-3-11-title">Proof of Lemma 12.3.11</h3>
    <div class="callout-body">
      <ol class="enumerate" style="margin-top:0.25rem;">
        <li>
          By definition, the \(j\)-th column of \([\mathrm{id}]_{B'}^B\) gives the coefficients for \(b'_j\) as a linear combination of the elements of \(B\). In each case, we check that the matrix \(E\) agrees with the specified combinations in the definition of the basis operation.
        </li>
        <li>
          It suffices to check this for a row vector, since the \(i\)-th row of \(BE\) can be computed as the \(i\)-th row of \(B\) multiplied by \(E\). Then one can verify this by case-by-case multiplication.
        </li>
        <li>
          Similar to (2).
        </li>
      </ol>
    </div>
  </section>

  <section id="rmk-12-3-12" class="callout remark" aria-labelledby="rmk-12-3-12-title">
    <h3 id="rmk-12-3-12-title">Remark 12.3.12</h3>
    <div class="callout-body">
      <p>
        To remember the relationship between elementary matrices and elementary operations, it suffices to remember that
      </p>
      <ol class="enumerate" style="margin-top:0.25rem;">
        <li>Row operations correspond to multiplication on the left and column operations correspond to multiplication on the right, and</li>
        <li>The elementary matrix corresponding to an elementary row or column operation is the matrix that results from applying that operation to the identity matrix.</li>
      </ol>
      <p>
        Indeed, (2) follows from taking \(A=I\) or \(B=I\) in the Lemma.
      </p>
    </div>
  </section>
</section>


<section id="sec-12-4" class="section" aria-labelledby="sec-12-4-title">
  <h2 id="sec-12-4-title">12.4 Determinants</h2>

  <p>
    We briefly cover some of the key facts about determinants that we will need later.
  </p>

  <section id="def-12-4-1" class="callout definition" aria-labelledby="def-12-4-1-title">
    <h3 id="def-12-4-1-title">Definition 12.4.1</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring. We define the function
      </p>
      \[
        \det: \mathrm{Mat}_{n\times n}(R) \to R
      \]
      <p>
        by the rule
      </p>
      \[
        \det(A) = \sum_{i\in S_n} \mathrm{sgn}(\sigma) \prod_{i=1}^n {a_{i,\sigma(i)}}
      \]
      <p>
        for a matrix \(A=[a_{i,j}]\).
        We call \(\det(A)\) the <strong>determinant</strong> of \(A\).
      </p>
    </div>
  </section>

  <section id="ex-12-4-2" class="callout example" aria-labelledby="ex-12-4-2-title">
    <h3 id="ex-12-4-2-title">Example 12.4.2</h3>
    <div class="callout-body">
      <p>
        If \(A= \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22}\end{bmatrix}\), then \(\det(A)=a_{11} a_{22} - a_{12} a_{21}\).
      </p>

      <p>
        If \(A\) is an upper triangular matrix, so that \(a_{ij}=0\) for \(j>i\), then there is only one nonzero term in the sum, and \(\det(A)\) is the product of the diagonal entries.
      </p>
    </div>
  </section>

  <section id="def-12-4-3" class="callout definition" aria-labelledby="def-12-4-3-title">
    <h3 id="def-12-4-3-title">Definition 12.4.3</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring. Let \(\phi: \underbrace{R^n \times \cdots \times R^n}_{n-\text{times}} \to R\) be a function. We say that
      </p>

      <ol>
        <li>
          <p>
            \(\phi\) is <strong>multilinear</strong> if for each \(i=1,\dots,n\) we have
          </p>
          \[
            \phi( v_1,\dots,v_{i-1},  v_i + v'_i, v_{i+1},\dots, v_n) = \phi( v_1,\dots,v_{i-1},  v_i, v_{i+1},\dots, v_n) + \phi( v_1,\dots,v_{i-1},  v'_i, v_{i+1},\dots, v_n)
          \]
          <p>
            and
          </p>
          \[
            \phi( v_1,\dots,v_{i-1},  r v_i, v_{i+1},\dots, v_n) = \phi( v_1,\dots,v_{i-1},  v_i, v_{i+1},\dots, v_n) + r \phi( v_1,\dots,v_{i-1},  v_i, v_{i+1},\dots, v_n)
          \]
          <p>
            for all \(v_1,\dots,v_n, v'_i \in R^n\) and \(r\in R\); i.e., when all but one entry is fixed, the function \(R^n \to R\) in the remaining output is an \(R\)-module homomorphism.
          </p>
        </li>

        <li>
          <p>
            \(\phi\) is <strong>alternating</strong> if \(\phi(v_1,\dots,v_n)=0\) whenever \(v_i=v_j\) for some \(i\neq j\).
          </p>
        </li>
      </ol>
    </div>
  </section>

  <section id="lem-12-4-4" class="callout lemma" aria-labelledby="lem-12-4-4-title">
    <h3 id="lem-12-4-4-title">Lemma 12.4.4</h3>
    <div class="callout-body">
      <p>
        Let \(\phi: \underbrace{R^n \times \cdots \times R^n}_{n-\text{times}} \to R\) be a multilinear alternating function. Then for any \(\sigma\in S_n\) and any vectors \(v_1,\dots,v_n\in R^n\), we have
      </p>
      \[
        \phi(v_{\sigma(1)}, v_{\sigma(2)},\dots,v_{\sigma(n)}) = \mathrm{sgn}(\sigma) \phi(v_1, v_2,\dots,v_n).
      \]
    </div>
  </section>

  <section id="proof-lem-12-4-4" class="callout proof" aria-labelledby="proof-lem-12-4-4-title">
    <h3 id="proof-lem-12-4-4-title">Proof of Lemma 12.4.4</h3>
    <div class="callout-body">
      <p>
        First, we consider the case of the transposition \((1\, 2)\). Note that
      </p>
      \[
        \begin{aligned}
        0 &= \phi(v_1+v_2, v_1+ v_2,\dots,v_n) = \phi(v_1, v_1+ v_2,\dots,v_n) + \phi(v_2, v_1+ v_2,\dots,v_n) \\
        & = \phi(v_1, v_1,\dots,v_n) + \phi(v_2, v_1,\dots,v_n) +  \phi(v_1, v_2,\dots,v_n) + \phi(v_2, v_2,\dots,v_n) \\
        & =   \phi(v_2, v_1,\dots,v_n) +  \phi(v_1, v_2,\dots,v_n) ,
        \end{aligned}
      \]
      <p>
        so \(\phi(v_2, v_1,\dots,v_n) =  - \phi(v_1, v_2,\dots,v_n)\). The case of an arbitrary transposition follows in the same way. For an arbitrary permutation \(\sigma\), we can write \(\sigma\) as a product of \(t\) transpositions for some \(t\). Applying the case of one transposition \(t\) times yields
      </p>
    </div>
  </section>

  <section id="thm-12-4-5" class="callout theorem" aria-labelledby="thm-12-4-5-title">
    <h3 id="thm-12-4-5-title">Theorem 12.4.5</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring. Identify \(\mathrm{Mat}_{n\times n}(R)\) with \(\underbrace{R^n \times \cdots \times R^n}_{n-\text{times}}\) mapping \(A\) to the \(n\)-tuple of columns of \(A\). Then \(\det\) is the unique function \(\mathrm{Mat}_{n\times n} \to R\) that is multilinear, alternating, and satisfies \(\det(I) = 1\).
      </p>
    </div>
  </section>

  <section id="proof-thm-12-4-5" class="callout proof" aria-labelledby="proof-thm-12-4-5-title">
    <h3 id="proof-thm-12-4-5-title">Proof of Theorem 12.4.5 (Sketch)</h3>
    <div class="callout-body">
      <p>
        The verification that \(\det\) has these properties is straightforward but messy. To show uniqueness, we can use multlinearity to show that the value of a function with these properties is determined by the values when each column is a standard vector \(e_i\). We can then use the alternating property and Lemma 12.4.4 to show that the value is determined by the value at the identity matrix.
      </p>
    </div>
  </section>

  <p>
    Our next goal is to prove the familiar multiplicative property for determinants.
  </p>

  <section id="prop-12-4-6" class="callout proposition" aria-labelledby="prop-12-4-6-title">
    <h3 id="prop-12-4-6-title">Proposition 12.4.6</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring. Let \(A\) be a square matrix and let \(B\) be a matrix obtained from \(A\)
        by a single elementary column operation:
      </p>
      <ul>
        <li>If the operation is of type I, \(\det(B) = \det(A)\).</li>
        <li>If the operation is of type II, given by multiplying a column of \(A\) by a unit \(u\), then \(\det(B) = u \det(A)\).</li>
        <li>If the operation is of type III, \(\det(B) = - \det(A)\).</li>
      </ul>
      <p>
        In particular, if \(A\) is an arbitrary matrix and \(E\) is an elementary matrix, then \(\det(EA)=\det(E)\det(A)\).
      </p>
    </div>
  </section>

  <section id="proof-prop-12-4-6" class="callout proof" aria-labelledby="proof-prop-12-4-6-title">
    <h3 id="proof-prop-12-4-6-title">Proof of Proposition 12.4.6</h3>
    <div class="callout-body">
      <p>
        The first case follows from multilinearity and alternating properties: For notational simplicity say \(A = (v_1, v_2, \dots)\) and
        \(B = (v_1 + rv_2, v_2, \dots)\). Then
      </p>
      \[
        \det(B) = \det(v_1, v_2, \dots) + r \det(v_2, v_2, \dots) = \det(A) + r \cdot 0 = \det(A)
      \]
      <p>
        The second case is immediate from (the second part of) \(R\)-multilinearity.
        The last case is a special case of Lemma 12.4.4.
      </p>

      <p>
        The final claim comes from noting that \(\det(E)=1,u,-1\) in the three cases, respectively.
      </p>
    </div>
  </section>

  <section id="cor-12-4-7" class="callout corollary" aria-labelledby="cor-12-4-7-title">
    <h3 id="cor-12-4-7-title">Corollary 12.4.7</h3>
    <div class="callout-body">
      <p>
        For \(R = F\) a field, we have \(\det(A) \ne 0\) if and only if \(A\) is invertible.
      </p>
    </div>
  </section>

  <section id="proof-cor-12-4-7" class="callout proof" aria-labelledby="proof-cor-12-4-7-title">
    <h3 id="proof-cor-12-4-7-title">Proof of Corollary 12.4.7</h3>
    <div class="callout-body">
      <p>
        If \(A\) is not invertible, then the span of the columns of \(A\) is a proper subspace of \(F^n\) and hence
        the columns of \(A\) must be linearly dependent. Say the \(i\)-th column is a linear combination of the rest: \(v_i = \sum_{j \ne i} c_j v_j\).
        Then
      </p>
      \[
        \det(v_1, \dots, v_n) = \sum_{j \ne i} c_j \det(\text{a matrix with the \(i\)-th and \(j\)-th columns equal}) = 0.
      \]
      <p>
        If \(A\) is invertible, then we can write \(A\) as a product of elementary matrices (this is a result that we stated before, but will prove soon). The result thus follows from the Proposition 12.4.6 and the fact that \(\det(I_n) = 1\).
      </p>
    </div>
  </section>

  <section id="thm-12-4-8" class="callout theorem" aria-labelledby="thm-12-4-8-title">
    <h3 id="thm-12-4-8-title">Theorem 12.4.8</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring. Then for any matrices \(A, B \in \mathrm{Mat}_{n \times n}(R)\) we have
      </p>
      \[
        \det(AB) = \det(A) \det(B).
      \]
    </div>
  </section>

  <section id="proof-thm-12-4-8" class="callout proof" aria-labelledby="proof-thm-12-4-8-title">
    <h3 id="proof-thm-12-4-8-title">Proof of Theorem 12.4.8</h3>
    <div class="callout-body">
      <p>
        First we will consider the case where \(R=F\) is a field.
      </p>

      <p>
        If \(A\) is not invertible, neither is \(AB\), since \(\mathrm{im}(AB) \subseteq \mathrm{im}(A)\),
        and if \(B\) is not invertible, neither is is \(AB\), since \(\ker(AB) \supseteq \ker(A)\).
        So, by the Proposition 12.4.6, if either \(A\) or \(B\) is not invertible, both sides of the equation are \(0\).
      </p>

      <p>
        Assume now that \(A\) and \(B\) are both invertible. Then by the Proposition 12.4.6 we have
      </p>
      \[
        A = E_1 \cdots E_n
      \]
      <p>
        and
      </p>
      \[
        B = F_1 \cdots F_m
      \]
      <p>
        and hence
      </p>
      \[
        AB = E_1 \cdots E_n F_1 \cdots F_m
      \]
      <p>
        where the \(E_i\)'s and \(F_j\)'s are elementary matrices.
      </p>

      <p>
        Applying Corollary 12.4.7 repeatedly gives
      </p>
      \[
        \det(AB) = \det(E_1 \cdots E_n F_1 \cdots F_{m-1}) \det(F_m) = \cdots
        = \det(E_1) \cdots \det(E_n) \det(F_1) \cdots \det(F_m)
      \]
      <p>
        and similarly
      </p>
      \[
        \det(A) \det(B) = \left(\det(E_1) \cdots \det(E_n)\right) \left( \det(F_1) \cdots \det(F_m)\right).
      \]

      <p>
        Now, for an integral domain \(R\), consider its fraction field \(F\), and identify \(R\subseteq F\) as a subring. To compute \(\det(A)\), \(\det(B)\), and \(\det(AB)\) we can replace \(R\) by \(F\), and are done by the field case.
      </p>

<p>One can apply a similar trick for arbitrary commutative rings, but we'll skip this for now.</p>
    </div>
  </section>


<section id="prop-12-4-9" class="callout proposition" aria-labelledby="prop-12-4-9-title">
  <h3 id="prop-12-4-9-title">Proposition 12.4.9</h3>
  <div class="callout-body">
    <p>
      Let \(R\) be a commutative ring. Let \(A\in \mathrm{Mat}_{n\times m}(R)\) and
      \(B\in \mathrm{Mat}_{m\times n}(R)\) with \(m\geq n\).
      For a subset \(I=\{i_1,\dots,i_n\} \subseteq [m]\) with \(|I|=n\), let \(A_I\)
      denote the submatrix of \(A\) with columns indexed by \(I\) (in increasing order).
      Then
    </p>
    \[
      \det(AB) \in
      \left( \{ \det(A_I) \mid I\subseteq [m],\ |I|=n\} \right).
    \]
  </div>
</section>

<section id="proof-prop-12-4-9" class="callout proof" aria-labelledby="proof-prop-12-4-9-title">
  <h3 id="proof-prop-12-4-9-title">Proof of Proposition 12.4.9</h3>
  <div class="callout-body">
    <p>
      Let \(a_1,\dots,a_m\) be the columns of \(A\). We can write the \(j\)-th column
      of \(AB\) as \(\sum_{i=1}^m b_{i,j} a_i\). Then, by multilinearity,
    </p>
    \[
      \begin{aligned}
      \det(AB)
      &= \det
      \begin{bmatrix}
      \sum_{i_1=1}^m b_{i_1,1} a_{i_1} & \cdots &
      \sum_{i_n=1}^m b_{i_n,n} a_{i_n}
      \end{bmatrix} \\
      &= \sum_{1\leq i_1,\dots,i_n \leq m}
      b_{i_1,1} \cdots b_{i_n,n}
      \det
      \begin{bmatrix}
      a_{i_1} & \cdots & a_{i_n}
      \end{bmatrix}.
      \end{aligned}
    \]
    <p>
      By the alternating property, we can rewrite each
      \(\det\begin{bmatrix} a_{i_1} & \cdots & a_{i_n} \end{bmatrix}\)
      as either zero, or the determinant of a submatrix with columns
      \( i_1 < i_2 < \cdots < i_n \), up to sign. This gives \(\det(AB)\) as an
      \(R\)-linear combination of the determinants \(\det(A_I)\).
    </p>
  </div>
</section>

We also have the following:

<section id="ex-12-4-10" class="callout exercise" aria-labelledby="ex-12-4-10-title">
  <h3 id="ex-12-4-10-title">Exercise 12.4.10</h3>
  <div class="callout-body">
    <p>
      Let \(R\) be a commutative ring and \(A\in \mathrm{Mat}_{n\times n}(R)\). Then \(\det(A) =  \det(A^\mathrm{T})\), where \(A^\mathrm{T}\) is the transpose of \(A\).
    </p>
  </div>
</section>

</section>




<section id="ch-13" class="chapter" aria-labelledby="ch-13-title">
  <h1 id="ch-13-title">Chapter 13 Finitely generated modules over PIDs</h1>

  <p>
    We have seen that every module over a field is free. In contrast, whenever \(R\) is a commutative ring that is not a field, we can always construct modules that are not free. We will see that, however, every module is still a quotient of a free module. Describing that quotient explicitly is to give a presentation for the module, similarly to how we gave presentations for groups. We will study the particular case of finitely generated modules over PIDs in more detail.
  </p>

  <section id="sec-13-1" class="section" aria-labelledby="sec-13-1-title">
    <h2 id="sec-13-1-heading">13.1 The module presented by a matrix</h2>

    <p>
      Writing a given \(R\)-module \(M\) as a quotient of a free module is giving a <strong>presentation</strong> for \(M\).
      In 817, we studied presentations for groups; these consisted of a set of generators and a set (normal subgroup) of relations among these generators. Presentations are important for modules as well. In this case, the relations are encoded by a matrix, or equivalently by a homomorphism between a pair of free modules. We study below how the change of basis techniques can be applied to unravel the structure of a module starting with its presentation.
    </p>

    <section id="def-13-1-1" class="callout definition" aria-labelledby="def-13-1-1-title">
      <h3 id="def-13-1-1-title">Definition 13.1.1</h3>
      <div class="callout-body">
        <p>
          Let \(R\) be a commutative ring with \(1 \neq 0\), let \(A \in \mathrm{Mat}_{m,n}(R)\), and let \(t_A\!: R^n \to R^m\) be the \(R\)-module homomorphism represented by \(A\) with respect to the standard bases; i.e., the homomorphism given by the rule \(t_A(v)=Av\). The <strong>\(R\)-module presented by \(A\)</strong> is the \(R\)-module \(R^m/\mathrm{im}(t_A)\).
        </p>
      </div>
    </section>

    <p>
      The \(R\)-module \(M\) presented by \(A \in \mathrm{Mat}_{m,n}(R)\) has \(m\) generators and \(n\) relations. Each row of \(A\) corresponds to a generator for \(M\), while each column encodes a relation among those generators. More precisely, the relations among the \(m\) generators are themselves <em>generated</em> by the \(n\) generators of \(\mathrm{im}(t_A)\), which are the images of the standard basis of \(R^n\) by \(t_A\).
    </p>

    <section id="ex-13-1-2" class="callout example" aria-labelledby="ex-13-1-2-title">
      <h3 id="ex-13-1-2-title">Example 13.1.2</h3>
      <div class="callout-body">
        <p>
          The \(\mathbb{Z}\)-module \(M = \mathbb{Z}/6\) is presented by
        </p>
        \[
          \mathbb{Z} \xrightarrow{6} \mathbb{Z},
        \]
        <p>
          since \(M \cong \mathbb{Z}/ \mathrm{im}(t_6) = \mathbb{Z}/(6)\). Notice here we abused notation and wrote \(6\) instead of the \(1 \times 1\) matrix \(\left[ 6 \right]\).
        </p>
      </div>
    </section>

    <section id="ex-13-1-3" class="callout example" aria-labelledby="ex-13-1-3-title">
      <h3 id="ex-13-1-3-title">Example 13.1.3</h3>
      <div class="callout-body">
        <p>
          Let \(R = k[x,y]\), where \(k\) is a field, and \(I = (x,y)\). The \(R\)-module \(M = R/I\) has \(1\) generator, \(m = 1+I\), so we can write a presentation for \(M\) of the form \(F \xrightarrow{p} R\) for some free module \(F\) and some \(R\)-module homomorphism \(p\). To find such an \(F\), we need to ask about the relations among the generators of \(M\). For any \(a \in I\), we have the relation \(am = 0\), so \(I\) is the <strong>module of relations</strong> for this presentation of \(M\).
        </p>

        <p>
          How many generators does the module of relations have? In this case, we need \(2\): the relations \(xm = 0\) and \(ym=0\) generate <em>all</em> the relations, since for any \(a \in I\), we can write \(a = rx+sy\) for some \(x, y \in R\), and thus \(am = 0\) can be rewritten as \(r(xm) + s(ym) = 0\), which is a linear combination of the two relations \(xm=0\) and \(ym=0\). Finally, we have the following presentation for \(M\):
        </p>

        \[
          R^2 \xrightarrow{\begin{bmatrix} x & y \end{bmatrix}} R.
        \]
        <p>
          Indeed, the image of \(\begin{bmatrix} x & y \end{bmatrix}\) is \((x,y)\), and \(M \cong R/(x,y)\).
        </p>
      </div>
    </section>

    <p>
      Conversely, we might be given a matrix and ask about what module it represents; one thing to keep in mind is that some presentations might be inefficient, either by having more generators or more relations than necessary. We want to answer to key questions: given a presentation for a module, how to find a more efficient presentation; and how to decide if two different presentations actually give us isomorphic modules. Keeping these goals in mind, let's try a more elaborate example.
    </p>

    <section id="ex-13-1-4" class="callout example" aria-labelledby="ex-13-1-4-title">
      <h3 id="ex-13-1-4-title">Example 13.1.4</h3>
      <div class="callout-body">
        <p>
          Consider the matrix
        </p>
        \[
          A =
          \begin{bmatrix}
          2 & 1 & 0 \\
          3 & 9 & 5 \\
          1 & -2 & 7 \\
          0 & 1 & 2 \\
          \end{bmatrix}.
        \]
        <p>
          What \(\mathbb{Z}\)-module \(M\) is presented by \(A\)?
          Formally, \(M\) is the quotient module \(M=\mathbb{Z}^4/\mathrm{im}(t_A)\), where \(t_A \!:\mathbb{Z}^3 \to \mathbb{Z}^4\) is defined by \(t_A(v)=Av\). Since \(\mathbb{Z}^4\) is generated by its standard basis elements \(\{e_1,e_2,e_3,e_4\}\), we deduce as in Lemma \(\ref{lem:fg}\) that \(M=\mathbb{Z}^4/\mathrm{im}(t_A)\) is generated by the cosets of the \(e_i\). To keep the notation short, we set \(m_i=e_i+\mathrm{im}(t_A)\).
        </p>

        <p>
          Let \(N=\mathrm{im}(t_A)\) and note that \(N\) is the submodule of \(\mathbb{Z}^4\) generated by the columns of \(A\):
        </p>

        \[
          N=R\left\{\begin{bmatrix} 2 \\ 3 \\ 1\\ 0 \end{bmatrix}, \begin{bmatrix} 1 \\ 9 \\ -2 \\1 \end{bmatrix},\begin{bmatrix} 0 \\ 5 \\ 7\\2 \end{bmatrix}\right\}=R\{2e_1 + 3e_2 + e_3,e_1 + 9e_2 -2 e_3 + e_4, 5e_2 + 7 e_3 + 2 e_4  \}.
        \]

        <p>
          Since \(N\) maps to \(0\) under the quotient map \(q\!:\mathbb{Z}^4\to M=\mathbb{Z}^4/N\), the relations of \(M\)
          can be written as
        </p>

        \[
          \begin{cases}
          2m_1 + 3m_2 + m_3 & = 0 \\
          m_1 + 9m_2 -2 m_3 + m_4 & = 0 \\
          5m_2 + 7 m_3 + 2 m_4 & = 0.
          \end{cases}
        \]

        <p>
          We can now see that this is a rather inefficient presentation, since we can clearly use the first equation to solve for \(m_3=-2m_1 - 3m_2\). This implies that \(M\) can be generated using only \(m_1, m_2\) and \(m_4\), that is
        </p>

        \[
          M=R\{m_1,m_2,m_3,m_4\}=R\{m_1,m_2,m_4\}.
        \]

        <p>
          This eliminates the first equation and the latter two become
        </p>

        \[
          \begin{cases}
          5m_1 + 15m_2 + m_4 & = 0 \\
          -14m_1  -16m_2 + 2m_4 & = 0 \\
          \end{cases}
        \]

        <p>
          Now we can also eliminate \(m_4\), i.e  leaving just two generators \(m_1, m_2\) that satisfy
        </p>

        \[
          -24m_1 -46m_2 = 0.
        \]

        <p>
          Another way to do this is to look at the matrix \(A\) and use elementary row operations to ``make zeros&quot; on the 1st and 2nd columns, as follows:
        </p>

        \[
          A =
          \begin{bmatrix}
          2 & 1 & 0 \\
          3 & 9 & 5 \\
          1 & -2 & 7 \\
          0 & 1 & 2 \\
          \end{bmatrix}
          \rightarrow
          \begin{bmatrix}
          0 & 5 & -14 \\
          0 & 15 & -16 \\
          1 & -2 & 7 \\
          0 & 1 & 2 \\
          \end{bmatrix}
          \rightarrow
          \begin{bmatrix}
          0 & 0 & -24 \\
          0 & 0 & -46 \\
          1 & 0 & 11\\
          0 & 1 & 2 \\
          \end{bmatrix}
        \]

        <p>
          Eliminating the generators \(m_3\) and \(m_4\) amounts to dropping the first two columns (which are the 3rd and 4th standard basis vectors) as well as the last two rows. As we will prove soon, this shows that the \(\mathbb{Z}\)-module presented by \(A\) is isomorphic to the \(\mathbb{Z}\)-module presented by
        </p>

        \[
          B=
          \begin{bmatrix} -24 \\ - 46
          \end{bmatrix}.
        \]

        <p>
          We can go further. Set \(m_1' := m_1 + 2m_2\). Then \(m_1'\) and \(m_2\) also form a generating set of \(M\). The relation on \(m_1, m_2\) translates to
        </p>

        \[
          -24m'_1  +2 m_2 = 0
        \]
        <p>
          given by the matrix
        </p>

        \[
          C = E_{2,1}(-2)B=
          \begin{bmatrix} -24 \\ 2
          \end{bmatrix}.
        \]

        <p>
          Note that we have done a row operation (subtract twice row 1 from row 2) to get from \(B\) to \(C\).
          Continuing in this fashion by adding 12 row 2 to row 1 we also form
        </p>

        \[
          D = E_{1,2}(12)C=
          \begin{bmatrix} 0 \\ 2
          \end{bmatrix},
        \]

        <p>
          The last matrix \(D\) presents the module \(M'=\mathbb{Z}^2/\mathrm{im}(t_D)\) with generators \(a, b\), where
        </p>

        \[
          a=e_1+\mathrm{im}(t_D), \quad b=e_2+\mathrm{im}(t_D)
        \]
        <p>
          and relation \(2a = 0\). This module \(M'\) is isomorphic to our original module \(M\). As we will see, this proves \(M \cong \mathbb{Z} \oplus \mathbb{Z}/2\). An explicit isomorphism between \(M'\) and \(\mathbb{Z} \oplus \mathbb{Z}/2\) is given by sending \(\mathbb{Z}^2\to \mathbb{Z} \oplus \mathbb{Z}/2\) by the unique \(\mathbb{Z}\)-module homomorphism defined by
        </p>

        \[
          e_1\mapsto (1,0) \textrm{ and } e_2\mapsto (0,[1]_2).
        \]

        <p>
          Now notice that the kernel of this homomorphism is the submodule \((2e_2)\mathbb{Z}=\mathrm{im}(t_D)\). Then the first isomorphism theorem gives
          \(M'=\mathbb{Z}^2/\mathrm{im}(t_D)\cong \mathbb{Z} \oplus \mathbb{Z}/2\).
        </p>
      </div>
    </section>

    <section id="lem-13-1-5" class="callout lemma" aria-labelledby="lem-13-1-5-title">
      <h3 id="lem-13-1-5-title">Lemma 13.1.5</h3>
      <div class="callout-body">
        <p>
          Let \(R\) be a commutative ring with \(1 \neq 0\), \(A \in \mathrm{Mat}_{m,n}(R)\) and \(B \in M_{m',n'}(R)\) for some \(m,n,m',n' \geqslant 1\). Then \(A\) and \(B\) present isomorphic \(R\)-modules if \(B\) can be obtained from \(A\) by any finite sequence of operations of the following form:
        </p>

        <ol class="paren-list">
          <li>an elementary row operation,</li>
          <li>an elementary column operation,</li>
          <li>deletion of the \(j\)th column and \(i\)th row of \(A\) if \(Ae_j = e_i\), that is, if the \(j\)th column of \(A\) is the vector \(e_i\),</li>
          <li>the reverse of 3: insertion of a row and column satisfying \(Ae_j = e_i\),</li>
          <li>deletion of a column of all \(0\)'s,</li>
          <li>the reverse of 5: insertion of a column of all \(0\)s.</li>
        </ol>
      </div>
    </section>

    <section id="proof-lem-13-1-5" class="callout proof" aria-labelledby="proof-lem-13-1-5-title">
      <h3 id="proof-lem-13-1-5-title">Proof of Lemma 13.1.5</h3>
      <div class="callout-body">
        <p>
          It is sufficient to show that each individual operation gives an isomorphism, as the composition of isomorphisms is an isomorphism.
        </p>

        <p>
          For operations (1) and (2), consider matrices \(A\) and \(A'\) where \(A'\) is obtained from \(A\) by the given elementary row/column operation, and set \(M = R^m/\mathrm{im}(t_A)\) and \(M' = R^{m'}/\mathrm{im}(t_{A'})\). We need to prove that there is an isomorphism \(M \cong M'\).
        </p>

        <p>
          In case (1), where we have an elementary row operation, let \(E\) be the corresponding elementary matrix. Since \(A' = E A\), the isomorphism \(E: R^n \to R^n\) maps \(\mathrm{im}(A)\) bijectively onto \(\mathrm{im}(A')\). Thus \(Q\) induces an isomorphism
        </p>

        \[
          M = R^m/\mathrm{im}(t_A) \xrightarrow{\cong} R^m/\mathrm{im}(t_{A'}) = M'.
        \]

        <p>
          In case (2), where we have an elementary column operation, let \(E\) be the corresponding elementary matrix. Since \(A'=AE\) and since \(E\) is an isomorphism, we have
        </p>

        \[
          \mathrm{im}(t_{A'}) = \mathrm{im}(t_{AE})=\mathrm{im}(t_A\circ t_E)=\mathrm{im}(t_A)
        \]
        <p>
          and so \(m=m'\) and \(M = R^m/\mathrm{im}(t_A) = R^{m'}/\mathrm{im}(t_{A'}) = M'\). In fact, note that for this one we get equality, not merely an isomorphism.
        </p>

        <p>
          For case (3), we have \(m'=m-1\) and \(n'=n-1\).
          Since \(R^m\) is free, by the <a href="#UMPfreemod">UMP for free modules</a> there is a unique \(R\)-module homomorphism
          \(p\!: R^{m} \to R^{m-1}\) sending
        </p>

        \[
          \begin{aligned}
          e_1 \mapsto e'_1, & \ldots, e_{i-1} \mapsto e'_{i-1}\\
          & e_i \mapsto 0\\
          e_{i+1} \mapsto e'_{i}, & \ldots, e_{m} \mapsto e'_{m-1}
          \end{aligned}
        \]

        <p>
          Similarly, there is a unique \(R\)-module homomorphism \(q\!: R^{n} \to R^{n-1}\) sending
        </p>

        \[
          \begin{aligned}
          e_1 \mapsto e'_1, &\ldots, e_{j-1} \mapsto e'_{j-1}, \\
          e_j &\mapsto 0, \\
          e_{j+1} \mapsto e'_{j}, &\ldots, e_n \mapsto e'_{n-1}.
          \end{aligned}
        \]

        <p>
          Here the elements \(e_i\) are part of a standard basis for \(R^n\) or for \(R^m\), while the elements \(e'_i\) are part of a standard basis for \(R^{n-1}\) or for \(R^{m-1}\).
          Then the diagram
        </p>

       \[
\begin{array}{ccc}
R^n & \xrightarrow{\;A\;} & R^m \\
\Big\downarrow\rlap{\scriptstyle q} & & \Big\downarrow\rlap{\scriptstyle p} \\
R^{n-1} & \xrightarrow{\;A'\;} & R^{m-1}
\end{array}
\]

        <p>
          commutes by the definition of \(A'\). In particular, \(p(\mathrm{im}(t_A)) \subseteq \mathrm{im}(t_{A'})\) and so \(p\) induces an \(R\)-module homomorphism
        </p>

        \[
          \overline{p}\!: M \to M',
        \]
        <p>
          and we claim \(\overline{p}\) is bijective.
        </p>

        <p>
          Since \(p\) is onto, so is \(\overline{p}\). Suppose \(m \in \ker(\overline{p})\). Then \(m = v + \mathrm{im}(t_A)\) for some \(v \in R^m\) and \(p(v) \in \mathrm{im}(t_{A'})\). Say \(p(v) = A' w\). Since \(q\) is onto, \(w = q(u)\) for some \(u\). Then
        </p>

        \[
          p(v - Au) = p(v) - pA(u) = p(v) - A'q(u) = p(v) - A'w = p(v) - p(v) = 0,
        \]

        <p>
          and thus \(v - Au \in \ker(p)\). Now, the kernel of \(p\) is
          clearly \(Re_i\), so that \(v - Au = re_i\) for some \(r\). Finally, since \(Ae_j = e_i\), we have \(A(re_j) = re_i = v - Au\) and hence \(v = A(u + re_j)\), which proves
          \(v=t_A(u+re_j) \in \mathrm{im}(t_A)\) and hence that  \(m = 0\).
        </p>

        <p>
          For (5), it is clear that the columns of \(A'\) generate the same submodule of \(R^m\) as do the columns of \(A\), and thus \(M = M'\).
        </p>

        <p>
          Finally, for operations (4) and (6), since the isomorphism relation is reflexive, the statements of parts (3) and (5) show that parts (4) and (6) are true as well.
        </p>
      </div>
    </section>
  </section>
</section>




<section id="sec-13-2" class="section" aria-labelledby="sec-13-2-title">
  <h2 id="sec-13-2-heading">13.2 Existence of presentations</h2>

  <p>
    Which modules have presentations? If we take this in a broad sense, the answer is every module.
  </p>

  <section id="thm-13-2-1" class="callout theorem" aria-labelledby="thm-13-2-1-title">
    <h3 id="thm-13-2-1-title">Theorem 13.2.1</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a ring and \(M\) be a module. Then there exist free modules \(F,G\) and a homomorphism \(\alpha\colon G\to F\) such that \(M\cong F/ \mathrm{im}(\alpha)\).
      </p>
    </div>
  </section>

  <section id="proof-thm-13-2-1" class="callout proof" aria-labelledby="proof-thm-13-2-1-title">
    <h3 id="proof-thm-13-2-1-title">Proof of Theorem 13.2.1</h3>
    <div class="callout-body">
      <p>
        Let \(S\) be a generating set for \(M\), and let \(F= F_R(S)\) be the free module with basis \(S\). By the UMP for free modules, there is a unique homomorphism \(\phi\) such that for each \(s\in S\), \(\phi(s) =s\). Since \(S\) generates \(M\), this map is surjective by an Exercise from earlier.
      </p>

      <p>
        Let \(K=\ker(\phi)\), and let \(S'\) be a generating set for \(K\). Set \(G=F_R(S')\) to be the free module with basis \(S'\). By the UMP for free modules again, there is a unique \(\alpha\colon G\to F\) such that for each \(s'\in S'\), \(\alpha(s') =s'\). We claim that \(\mathrm{im}(\alpha) = K\) (left as an exercise).
      </p>

      <p>
        Thus, the First Isomorphism Theorem, \(M\cong F/K = F/\mathrm{im}(\alpha)\).
      </p>
    </div>
  </section>

  <p>
    Suppose that \(R\) is commutative. In the setting of the previous Theorem, if \(F\) is free of rank \(m\), and \(G\) is free of finite rank \(n\), then by picking bases for \(F\) and \(G\), we can rewrite \(\alpha:G\to F\) as \(t_A: R^n \to R^m\) for some matrix \(A\).
  </p>

  <p>
    Since this would yield \(m\) generators for \(M\), this can only happen if \(M\) is finitely generated. This in general does not suffice to guarantee that there will only be finitely many generators for the submodule of relations.
  </p>

  <p>
    It might seem like no submodule of a finitely generated module could ever fail to itself be finitely generated, but indeed this happens!
  </p>

  <section id="ex-13-2-2" class="callout example" aria-labelledby="ex-13-2-2-title">
    <h3 id="ex-13-2-2-title">Example 13.2.2</h3>
    <div class="callout-body">
      <p>
        Let \(k\) be a field and \(R = k[x_1, x_2, \ldots]\) be a polynomial ring in infinitely many variables. When we think of \(R\) as a module over itself, it is finitely generated, by the element \(1\). However, there are submodules of \(R\) that are not finitely generated: for example, the ideal \((x_1, x_2, \ldots)\) generated by all the variables.
      </p>
    </div>
  </section>

We will need the following fact.

  <section id="ex-13-2-3" class="callout exercise" aria-labelledby="ex-13-2-3-title">
    <h3 id="ex-13-2-3-title">Exercise 13.2.3</h3>
    <div class="callout-body">
      <p>
        Let \(M\) be a module and \(N\) be a submodule. If \(N\) and \(M/N\) are finitely generated, then \(M\) is finitely generated.
    </div>
  </section>



  <section id="thm-13-2-4" class="callout theorem" aria-labelledby="thm-13-2-4-title">
    <h3 id="thm-13-2-4-title">Theorem 13.2.4</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a PID. Then every submodule of a finitely generated module is also finitely generated.
      </p>
    </div>
  </section>

  <section id="proof-thm-13-2-4" class="callout proof" aria-labelledby="proof-thm-13-2-3-title">
    <h3 id="proof-thm-13-2-4-title">Proof of Theorem 13.2.4</h3>
    <div class="callout-body">
      <p>
        We will first prove that for each \(n \geqslant 1\), every submodule of \(R^n\) is finitely generated. The base case \(n=1\) holds by the definition, since a submodule of \(R^1\) is the same thing as an ideal of \(R\), and every ideal is generated by one element.
        Assume \(n &gt; 1\) and that every submodule of \(R^{n-1}\) is finitely generated. Let \(M\) be any submodule of \(R^n\). Define
      </p>
      \[
        \pi\!: R^n \twoheadrightarrow R^1
      \]
      <p>
        to be the projection onto the last component of \(R^n\). The kernel of \(\pi\) may be identified with \(R^{n-1}\), and so \(N := \ker(\pi) \cap M\) is a submodule of \(R^{n-1}\). By assumption, \(N\) is finitely generated. The image \(\pi(M)\) is a submodule of \(R^1\), that is, an ideal of \(R\), and so it too is principal. Furthermore, by the First Isomorphism Theorem \(M/\ker(\pi)\cong \pi(M)\).
        By the Exercise above, we deduce that \(M\) is a finitely generated module.
      </p>

      <p>
        Now let \(T\) be any finitely generated \(R\)-module and \(N \subseteq T\) any submodule. Since \(T\) is finitely generated, there exists a surjective \(R\)-module homomorphism \(q\!: R^n \twoheadrightarrow T\) for some \(n\). Then \(q^{-1}(N)\) is a submodule of \(R^n\) and hence it is finitely generated by the case we already proved, say by element \(v_1, \dots , v_m \in q^{-1}(N)\). We claim that \(q(v_1), \dots, q(v_m)\) generate \(N\). Given any \(a \in N\), since \(q\) is surjective we can find some \(b \in q^{-1}(N)\) such that \(q(b) = a\). Since \(v_1, \ldots, v_m\) generated \(q^{-1}(N)\), we can find \(c_1, \ldots, c_m \in R\) such that
      </p>
      \[
        b = c_1 v_1 + \cdots + c_m v_m \implies c_1 q(v_1) + \cdots + c_m q(v_m) = q(c_1 v_1 + \cdots + c_m v_m) = q(b) = a.
      \]
    </div>
  </section>

  <section id="thm-13-2-5" class="callout theorem" aria-labelledby="thm-13-2-5-title">
    <h3 id="thm-13-2-5-title">Theorem 13.2.5</h3>
    <div class="callout-body">
      <p>
        Any finitely generated module \(M\) over a PID \(R\) has a finite presentation given by an \(m \times n\) matrix \(A\), that is, there is an isomorphism
      </p>
      \[
        M\cong R^m/\mathrm{im}(t_A),
      \]
      <p>
        where \(t_A\!: R^n \to R^m\) is the map on free modules \(t_A(v)=Av\) induced by \(A\).
      </p>
    </div>
  </section>

  <section id="proof-thm-13-2-5" class="callout proof" aria-labelledby="proof-thm-13-2-4-title">
    <h3 id="proof-thm-13-2-5-title">Proof of Theorem 13.2.5</h3>
    <div class="callout-body">
      <p>
        Let \(M\) be a finitely generated module over a PID. We follow the argument of Theorem 13.2.1. Choose a finite generating set \(y_1, \dots y_m\) of \(M\) and obtain an \(R\)-module map
        \(\pi\!: R^m \to M\)
        that sends \(e_i\) to \(y_i\), by using the UMP for free modules. Since every element in \(M\) is given as a linear combination of the \(y_i\), the map \(\pi\) is surjective. Notice, however, that this representation as a linear combination of the \(y_i\) is not necessarily unique, so \(\pi\) might have a nontrivial kernel.
      </p>

      <p>
        Since \(R^m\) is finitely generated and \(R\) is a PID, the submodule \(\ker(\pi)\) is also finitely generated, say by \(z_1, \dots, z_n\). This too leads to a
        surjective \(R\)-module map \(g\!: R^n \to \ker(\pi)\) that sends \(e_i \mapsto z_i\).
        The composition of \(g\!: R^n \twoheadrightarrow \ker(\pi)\) followed by the inclusion of \(\iota\!: \ker(\pi) \hookrightarrow R^m\) is an \(R\)-module homomorphism \(t=\iota \circ g:R^n \to R^m\) and hence by the correspondence between matrices and homomorphisms, we know \(t\) is given by a \(m \times n\) matrix \(A=[t]_B^C\) with respect to the standard bases of \(R^m\) and \(R^n\) respectively, meaning \(t=t_A\).
      </p>

      <p>
        It remains to show that \(M\cong R^m/\mathrm{im}(t_A)\). First note that since \(t_A=\iota \circ g\) and \(g\) is surjective we have
      </p>
      \[
        \mathrm{im}(t_A)=\mathrm{im}(\iota \circ g)=\iota(\mathrm{im}(g))=\iota(\ker(\pi))=\ker(\pi).
      \]
      <p>
        By the First Isomorphism Theorem we now have
      </p>
      \[
        M = \mathrm{im}(\pi)\cong R^m/\ker(\pi)= R^m/\mathrm{im}(t_A).
      \]
    </div>
  </section>
</section>


<section id="sec-13-3" class="section" aria-labelledby="sec-13-3-title">
  <h2 id="sec-13-3-heading">13.3 Classification of finitely generated modules over PIDs</h2>

  <p>
    We just showed that any finitely generated module \(M\) over a PID has a finite presentation matrix \(A\). We will discuss a canonical form for such a matrix \(A\) and the consequences it has on determining the isomorphism type of \(M\).
  </p>

  <section id="thm-13-3-1" class="callout theorem" aria-labelledby="thm-13-3-1-title">
    <h3 id="thm-13-3-1-title">Theorem 13.3.1 (Smith Normal Form (SNF))</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a PID and let \(A \in \mathrm{Mat}_{m,n}(R)\). Then there exist invertible matrices \(P\) and \(Q\) such that \(M = PAQ = [a_{ij}]\) satisfies the following: all nondiagonal entries of \(M\) are \(0\), meaning \(a_{ij} = 0\) if \(i \neq j\), and the diagonal entries of \(M\) satisfy
      </p>
      \[
        a_{11} \mid a_{22} \mid a_{33} \mid \cdots.
      \]
      <p>
        Moreover, the number \(\ell\) of nonzero entries of \(M\) is uniquely determined by \(A\), and the nonzero diagonal entries \(a_{11},\ldots, a_{\ell \ell}\) are unique up to associates.
      </p>
      <p>
        Furthermore, if \(R\) is a Euclidean domain, then \(P\) and \(Q\) can be chosen to be a product of elementary matrices.
      </p>
    </div>
  </section>

  <p>
    Elementary row and column operations correspond to multiplication by elementary matrices, which are invertible, and that the composition of invertible matrices is invertible. So whenever we apply elementary row and column operations, we can translate it into multiplication by an invertible matrix on the left or the right, respectively.
  </p>

  <p>
    To transform a matrix \(A\) into its Smith Normal Form, we will use a sequence of steps that all correspond to multiplication by invertible matrices. Many of those steps will actually be elementary row and column operations, which correspond to multiplication by an elementary matrix. Elementary matrices are invertible, and a product of invertible matrices is invertible, and so any finite sequence of elementary row and column operations can be described by multiplication by an invertible matrix. However, in general not every invertible matrix can be obtained as a product of elementary matrices. In fact, there are examples of PIDs \(R\) and matrices \(A\) for which the Smith Normal Form cannot be obtained by simply taking a sequence of elementary row and column operations. However, it is not easy to give such an example, in part because when our PID \(R\) is nice enough, the Smith Normal Form can in fact be obtained by simply taking a sequence of elementary row and column operations. This is the case for Euclidean domains: over such rings, the Euclidean Algorithm for finding the gcd of two elements works, and it's the key step we will need to find a Smith Normal Form. When \(R\) is a general PID, however, we need to work a little harder.
  </p>

  <p>
    Before we prove Theorem 13.3.1, let's see how to classify modules over PIDs using the Smith Normal Form for their presentation matrix. First, we need a lemma on how to interpret the module presented by a matrix in Smith Normal Form; we leave the proof as an exercise.
  </p>

  <section id="lem-13-3-2" class="callout lemma" aria-labelledby="lem-13-3-2-title">
    <h3 id="lem-13-3-2-title">Lemma 13.3.2</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a commutative ring with \(1 \neq 0\), let \(m \geqslant n\), let \(A = [a_{ij}] \in \mathrm{Mat}_{m,n}(R)\) be a matrix such that all nondiagonal entries of \(A\) are \(0\), and let \(M\) be the \(R\)-module presented by \(A\). Then \(M \cong R^{m-n} \oplus R/(a_{11}) \oplus \dots \oplus R/(a_{nn})\).
      </p>
    </div>
  </section>

  <section id="thm-13-3-3" class="callout theorem" aria-labelledby="thm-13-3-3-title">
    <h3 id="thm-13-3-3-title">Theorem 13.3.3 (Classification of finitely generated modules over a PID using invariant factors)</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a PID and let \(M\) be a finitely generated module. Then there exist \(r \geqslant 0\), \(k \geqslant 0\), and nonzero nonunit elements \(d_1,\ldots, d_k\) of \(R\) satisfying \(d_1 \mid  d_2 \mid \dots \mid d_k\) such that
      </p>
      \[
        M \cong R^r \oplus R/(d_1) \oplus \dots \oplus R/(d_k).
      \]
      <p>
        Moreover \(r\) and \(k\) are uniquely determined by \(M\), and the \(d_i\) are unique up to associates.
      </p>
    </div>
  </section>

  <section id="proof-thm-13-3-3" class="callout proof" aria-labelledby="proof-thm-13-3-3-title">
    <h3 id="proof-thm-13-3-3-title">Proof of Theorem 13.3.3</h3>
    <div class="callout-body">
      <p>
        By Theorem 13.2.3, \(M\) has a presentation matrix \(A\). By Theorem 13.3.1, \(A\) can be put into Smith Normal Form \(B\), where the diagonal entries of \(B\) are \(b_1, \ldots, b_\ell\) and satisfy \(b_1 \mid b_2 \mid \cdots \mid b_k\). Moreover, \(k\) is unique and the \(d_i\) are uniquely determined up to associates (ie, up to multiplication by units) by \(A\), hence by \(B\). By Theorem 13.2.3, \(M\) is isomorphic to the module presented by \(B\).
        By Lemma 13.3.2, this is isomorphic to
      </p>
      \[
        M \cong R^r \oplus R/(b_1) \oplus \dots \oplus R/(b_\ell).
      \]
      <p>
        Finally, some of these \(b_i\) might be units; let \(d_1 \mid \cdots \mid d_k\) be the nonunits among the \(b_i\), and note that if \(u\) is a unit, then \(R/(u) \cong (0)\). We conclude that
      </p>
      \[
        M \cong R^r \oplus R/(d_1) \oplus \dots \oplus R/(d_k),
      \]
      <p>
        as desired.
      </p>
    </div>
  </section>

  <section id="def-13-3-4" class="callout definition" aria-labelledby="def-13-3-4-title">
    <h3 id="def-13-3-4-title">Definition 13.3.4</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a PID, let \(r \geqslant 0, k \geqslant 0\), and let \(d_1,\ldots, d_k\) be nonzero nonunit elements of \(R\) satisfying \(d_1 \mid d_2 \mid \dots \mid d_k\). Let \(M\) be any \(R\)-module such that
      </p>
      \[
        M \cong R^r \oplus R/(d_1) \oplus \dots \oplus R/(d_k).
      \]
      <p>
        We say \(M\) has <strong>free rank</strong> \(r\) and <strong>invariant factors</strong> \(d_1,\ldots,d_k\).
      </p>
    </div>
  </section>

  <p>
    Notice that the invariant factors of \(M\) are only defined up to multiplication by units.
  </p>

  <section id="rmk-13-3-5" class="callout remark" aria-labelledby="rmk-13-3-5-title">
    <h3 id="rmk-13-3-5-title">Remark 13.3.5</h3>
    <div class="callout-body">
      <p>
        The classification theorem can be interpreted as saying that \(M\) decomposes into a free submodule \(R^r\) and a torsion submodule \(\mathrm{Tor}(M)=R/(d_1) \oplus \dots \oplus R/(d_k)\).
      </p>
    </div>
  </section>

  <section id="cor-13-3-6" class="callout corollary" aria-labelledby="cor-13-3-6-title">
    <h3 id="cor-13-3-6-title">Corollary 13.3.6 (Classification of finitely generated abelian groups)</h3>
    <div class="callout-body">
      <p>
        Let \(G\) be a finitely generated abelian group. Then
      </p>
      \[
        G \cong \mathbb{Z}^r \oplus \mathbb{Z}/n_1 \oplus \dots \oplus \mathbb{Z}/n_k
      \]
      <p>
        for some \(r \geqslant 0\), \(k \geqslant 0\), and \(n_i \geqslant 2\) for all \(i\), satisfying \(n_{i+1} \mid n_i\) for all \(i\). Moreover, the integers \(r\), \(k\), and \(n_1,\ldots n_k\) are uniquely determined by \(G\).
      </p>
    </div>
  </section>

  <section id="ex-13-3-7" class="callout example" aria-labelledby="ex-13-3-7-title">
    <h3 id="ex-13-3-7-title">Example 13.3.7</h3>
    <div class="callout-body">
      <p>
        Consider the \(\mathbb{Z}\)-module \(M\) presented by the matrix
      </p>
      \[
        A=\begin{bmatrix}
        1 & 6 & 5 & 2 \\
        2 & 1 & -1 & 0 \\
        3 & 0 & 3 & 0
        \end{bmatrix}.
      \]
      <p>
        We can obtain the Smith Normal Form as follows:
      </p>
      \[
        A=\begin{bmatrix}
        1 & 6 & 5 & 2 \\
        2 & 1 & -1 & 0 \\
        3 & 0 & 3 & 0
        \end{bmatrix} \xrightarrow[R3 \to R3-3R1]{R2 \to R2-2R1}
        \begin{bmatrix}
        1 & 6 & 5 & 2 \\
        0 & -11 & -11 & -4 \\
        0 & -18 & -12 & -6
        \end{bmatrix} \rightarrow
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & -11 & -11 & -4 \\
        0 & -18 & -12 & -6
        \end{bmatrix}
      \]
      \[
        \xrightarrow{C2 \leftrightarrow C4}
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & -4 & -11 & -11 \\
        0 & -6 & -12 & -18
        \end{bmatrix}
        \xrightarrow[C4 \to C4 + 3C1]{C3 \to C3+2C2}
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & -4 & -3 & 1 \\
        0 & -6 & 0 & 0
        \end{bmatrix}
        \xrightarrow{C2 \leftrightarrow C4}
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & 1 & -3 & -4 \\
        0 & 0 & 0 & -6
        \end{bmatrix}
      \]
      \[
        \rightarrow
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & 1 & 0 & 0\\
        0 & 0 & 0 & -6
        \end{bmatrix}
        \xrightarrow{C3 \leftrightarrow C4}
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & 1 & 0 & 0\\
        0 & 0 & -6 & 0
        \end{bmatrix}
        \xrightarrow{C3 \to -C3}
        \begin{bmatrix}
        1 & 0 & 0  & 0 \\
        0 & 1 & 0 & 0\\
        0 & 0 & 6 & 0
        \end{bmatrix}
        .
      \]
      <p>
        Thus the Smith normal form of \(A\) is
      </p>
      \[
        M=\begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        0 & 0 & 6 & 0
        \end{bmatrix},
      \]
      <p>
        with invariant factor \(d_1=6\). Notice that the two ones are not invariant factors: we only care about nonunits. Therefore we have
      </p>
      \[
        M\cong \mathbb{Z}/(1)\oplus \mathbb{Z}/(1)\oplus \mathbb{Z}/(6)\cong \mathbb{Z}/(6).
      \]
    </div>
  </section>

  <p>
    Here is a spinoff of the classification theorem.
  </p>

  <section id="thm-13-3-8" class="callout theorem" aria-labelledby="thm-13-3-8-title">
    <h3 id="thm-13-3-8-title">Theorem 13.3.8 (Classification of finitely generated modules over a PID using elementary divisors)</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a PID and let \(M\) be a finitely generated module. Then there exist \(r \geqslant 0\), \(s \geqslant 0\), prime elements \(p_1,\ldots,p_s\) of \(R\) (not necessarily distinct), and \(e_1,\ldots ,e_s \geqslant 1\) such that
      </p>
      \[
        M \cong R^r \oplus R/(p_1^{e_1}) \oplus \cdots \oplus R/(p_s^{e_s}).
      \]
      <p>
        Moreover, \(r\) and \(s\) are uniquely determined by \(M\), and the list \(p_1^{e_1},\ldots, p_s^{e_s}\) is unique up to associates and reordering.
      </p>
    </div>
  </section>

  <section id="proof-thm-13-3-8" class="callout proof" aria-labelledby="proof-thm-13-3-8-title">
    <h3 id="proof-thm-13-3-8-title">Proof of Theorem 13.3.8</h3>
    <div class="callout-body">
      <p>
        First, write \(M\) in invariant factor form \(M \cong R^r \oplus R/(d_1) \oplus \dots \oplus R/(d_k)\). Then write each invariant factor as a product of prime powers
      </p>
      \[
        d_i := \prod_{j=n_i}^{n_{i+1}} p_j^{e_j},
      \]
      <p>
        and recall that by the CRT we have
      </p>
      \[
        R/(d_i)\cong R/(p_{n_i}^{e_{n_i}})\oplus\dots\oplus R/(p_{n_{i+1}}^{e_{n_{i+1}}}).
      \]
      <p>
        Substituting into the invariant factor form gives the desired result. Uniqueness follows from the uniqueness of the invariant factor form and of the prime factorizations of each \(d_i\).
      </p>
    </div>
  </section>

  <section id="def-13-3-9" class="callout definition" aria-labelledby="def-13-3-9-title">
    <h3 id="def-13-3-9-title">Definition 13.3.9</h3>
    <div class="callout-body">
      <p>
        Let \(R\) be a PID, let \(r \geqslant 0\), \(s \geqslant 0\), \(p_1,\ldots,p_s\) be prime elements of \(R\), and let \(e_1,\ldots,e_s \geqslant 1\). Let \(M\) be the \(R\)-module \(M \cong R^r \oplus R/(p_1^{e_1}) \oplus \dots \oplus R/(p_s^{e_s})\). The elements \(p_1^{e_1},\ldots, p_s^{e_s}\) of \(R\) are the <strong>elementary divisors</strong> of \(M\).
      </p>
    </div>
  </section>

  <p>
    Careful that a particular prime might appear repeatedly in the elementary divisors of a particular module.
  </p>

  <section id="ex-13-3-10" class="callout example" aria-labelledby="ex-13-3-10-title">
    <h3 id="ex-13-3-10-title">Example 13.3.10</h3>
    <div class="callout-body">
      <p>
        When \(R = \mathbb{Z}\) and \(M = \mathbb{Z}/(6)\), we can write \(M\cong \mathbb{Z}/(2)\oplus \mathbb{Z}/(3)\), so the elementary divisors are \(2\) and \(3\).
      </p>
    </div>
  </section>

  <section id="cor-13-3-11" class="callout corollary" aria-labelledby="cor-13-3-11-title">
    <h3 id="cor-13-3-11-title">Corollary 13.3.11</h3>
    <div class="callout-body">
      <p>
        Let \(G\) be a finitely generated abelian group. Then there exist \(r,s \geqslant 0\), prime integers \(p_1, \ldots, p_s\), and positive integers \(e_i \geqslant 1\) such that
      </p>
      \[
        G \cong \mathbb{Z}^r\oplus \mathbb{Z}/p_1^{e_1} \oplus \dots \oplus \mathbb{Z}/p_s^{e_s}.
      \]
      <p>
        Moreover, \(r\), \(p_i\), and \(e_i\) are all uniquely determined by \(G\).
      </p>
    </div>
  </section>

</section>



</main>
<footer aria-label="Course footer" role="contentinfo">
<p>© 2026 Math 818 — Introduction to Modern Algebra II</p>
</footer>
</div>
</body>
</html>
