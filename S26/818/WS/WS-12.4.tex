\documentclass[12pt]{amsart}


\usepackage{times}
\usepackage[margin=1in]{geometry}
\usepackage{paralist,amsmath,amssymb,multicol,graphicx,framed,ifthen,color,xcolor,stmaryrd,enumitem,colonequals}
\usepackage[outline]{contour}
\contourlength{.4pt}
\contournumber{10}
\newcommand{\Bold}[1]{\contour{black}{#1}}

\definecolor{chianti}{rgb}{0.6,0,0}
\definecolor{meretale}{rgb}{0,0,.6}
\definecolor{leaf}{rgb}{0,.35,0}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\e}{\varepsilon}
\newcommand{\inv}{^{-1}}
\newcommand{\dabs}[1]{\left| #1 \right|}
\newcommand{\ds}{\displaystyle}
\newcommand{\solution}[1]{\ifthenelse {\equal{\displaysol}{1}} {\begin{framed}{\color{meretale}\noindent #1}\end{framed}} { \ }}
\newcommand{\solutione}[1]{\ifthenelse {\equal{\displaysol}{1}} {\begin{framed}{\color{leaf}This solution is embargoed.}\end{framed}} { \ }}
\newcommand{\showsol}[1]{\def\displaysol{#1}}

\newcommand{\rsa}{\rightsquigarrow}


\newcommand\itemA{\stepcounter{enumi}\item[{\Bold{(\theenumi)}}]}
\newcommand\itemB{\stepcounter{enumi}\item[(\theenumi)]}
\newcommand\itemC{\stepcounter{enumi}\item[{\it{(\theenumi)}}]}
\newcommand\itema{\stepcounter{enumii}\item[{\Bold{(\theenumii)}}]}
\newcommand\itemb{\stepcounter{enumii}\item[(\theenumii)]}
\newcommand\itemc{\stepcounter{enumii}\item[{\it{(\theenumii)}}]}
\newcommand\itemai{\stepcounter{enumiii}\item[{\Bold{(\theenumiii)}}]}
\newcommand\itembi{\stepcounter{enumiii}\item[(\theenumiii)]}
\newcommand\itemci{\stepcounter{enumiii}\item[{\it{(\theenumiii)}}]}
\newcommand\ceq{\colonequals}


\DeclareMathOperator{\ord}{ord}

\DeclareMathOperator{\res}{res}
\setlength\parindent{0pt}
%\usepackage{times}

%\addtolength{\textwidth}{100pt}
%\addtolength{\evensidemargin}{-45pt}
%\addtolength{\oddsidemargin}{-60pt}

\pagestyle{empty}
%\begin{document}\begin{itemize}

%\thispagestyle{empty}




\begin{document}
\showsol{0}
	
	\thispagestyle{empty}
	
	\section*{Determinants}
	
\begin{framed}
\textsc{Definition:} Let $R$ be a commutative ring, and $A\in \mathrm{Mat}_{n\times n}(R)$. The \textbf{determinant} of $A$ is 
\[ \det(A) = \sum_{\sigma \in S_n} \mathrm{sgn}(\sigma) \prod_{i=1}^n x_{i, \sigma(i)}.\]

\


\textsc{Theorem 1:} Identify $\mathrm{Mat}_{n\times n}(R)$ with $\underbrace{R^n \times \cdots \times R^n}_{n \, \text{times}}$ by considering a matrix as an $n$-tuple of columns. The determinant is the unique function 
\[ \det\colon \underbrace{R^n \times \cdots \times R^n}_{n \text{times}}\to R\] that satisfies the following three properties:
\begin{itemize}
\item  $\det$ is \textbf{multilinear}, meaning 
\[\begin{aligned}  \det(v_1,\dots,v_{i-1}, \boldsymbol{v + w},v_{i+1},\dots,v_n) &=  \det(v_1,\dots,v_{i-1}, \boldsymbol{v},v_{i+1},\dots,v_n) \\&  + \det(v_1,\dots,v_{i-1}, \boldsymbol{w},v_{i+1},\dots,v_n) \\ \det(v_1,\dots,v_{i-1}, \boldsymbol{rv},v_{i+1},\dots,v_n) &= \boldsymbol{r} \det(v_1,\dots,v_{i-1}, \boldsymbol{v},v_{i+1},\dots,v_n) \end{aligned} \]
\item $\det$ is \textbf{alternating}, meaning
\[ \det(v_1,\dots,v_n) = 0 \qquad \text{if} \ v_i=v_j \ \text{for some} \ i\neq j.\]
\item $\det(e_1,\dots,e_n) = 1$.
\end{itemize}
 \end{framed}

\begin{enumerate}
\itemA Working with Theorem 1:
\begin{enumerate}
\itema Use Theorem 1 to explain why the determinant of a diagonal matrix is the product of its diagonal entries.
\itema Use Theorem 1 to show that if some column of $A$ is a linear combination of the other columns of $A$, then $\det(A)=0$.
\itema Use part (b) to show that if $R=F$ is a field, and $A$ is not invertible, then $\det(A)=0$.
\itema Use Theorem 1 to show\footnote{Hint: Consider $\det(\boldsymbol{v_1} + \boldsymbol{v_2},\boldsymbol{v_1}+ \boldsymbol{v_2}, v_3,\dots,v_n)$.} that 
\[  \det(\boldsymbol{v_2},\boldsymbol{v_1}, v_3,\dots,v_n) = - \det(\boldsymbol{v_1},\boldsymbol{v_2}, v_3,\dots,v_n).\]
Likewise, the same holds for swapping any two entries.
\end{enumerate}


\solution{
\begin{enumerate}
\itema We have 
\[ \det \begin{bmatrix} r_1 & 0 & \cdots & 0 \\ 0 & r_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & r_n\end{bmatrix} = \det( r_1 e_1 , r_2 e_2 , \dots, r_n e_n) = r_1 r_2 \cdots r_n \det(e_1,e_2,\dots,e_n) = r_1 r_2 \cdots r_n.\]
\itema Say $v_1 = \sum_{j>1 } r_j v_j$; then 
\[ \det( \sum_{j>1 } r_j v_j, v_2,\dots,v_n) = \sum_{j>1 } r_j \det(v_j, v_2,\dots,v_n) = 0.\]
A similar argument applies when another entry is a sum of the others.
\itema Note that if one column is a linear combination of the others that the columns are linearly dependent, and conversely, if the columns are linearly dependent, since $F$ is a field, one can solve for one of the columns as a linear combination of the others. Now we claim that if the columns of $A$ are linearly independent, then $A$ is invertible. Indeed, if the columns are linearly independent then the kernel of the linear transformation $t_A: F^n \to F^n$ of multiplication by $A$ is zero (since a vector in the null space gives a dependence relation on the columns), and the dimension of the image is $n$ by Rank-Nullity, so $t_A$ is bijective, and hence an isomorphism. Thus $A$ has an inverse, given by the matrix of the inverse of $t_A$ in the standard bases.

Thus, if $A$ is not invertible, some columns of $A$ is a linear combination of the others, and $\det(A)=0$ by part (b).
\itema We have
\[\begin{aligned} 0 &=\det(v_1+v_2,v_1+v_2, \dots) = \det(v_1+v_2,v_1,\dots) +  \det(v_1+v_2,v_2,\dots) \\
&=  \det(v_1,v_1,\dots) +  \det(v_1,v_2,\dots) +  \det(v_2,v_1,\dots) +  \det(v_2,v_2,\dots) \\
&=  \det(v_1,v_2,\dots) +  \det(v_2,v_1,\dots)\end{aligned}\]
and the claim follows.
\end{enumerate}
}


\itemB Uniqueness part of Theorem 1:
\begin{enumerate}
\itemb Use 1(d) to show that for any $\sigma\in S_n$,
\[  \det(v_{\boldsymbol{\sigma(1)}},\dots,v_{\boldsymbol{\sigma(n)}}) = \mathrm{sgn}(\sigma) \det(v_1,\dots,v_n).\]
\itemb Explain the following claim: if $F\colon  \underbrace{R^n \times \cdots \times R^n}_{n \text{times}}\to R$ is multilinear, then $F$ is completely determined by $F(e_{i_1},\dots,e_{i_n})$ for $1\leq i_1,\dots,i_n \leq n$.
\itemb Explain the following claim:  if $F\colon  \underbrace{R^n \times \cdots \times R^n}_{n \text{times}}\to R$ is multilinear and alternating, then $F$ is completely determined by $F(e_1,\dots,e_n)$.
\end{enumerate}


\end{enumerate}

\newpage

\begin{framed}
\textsc{Theorem 2:} Let $R$ be a commutative ring and $A,B\in \mathrm{Mat}_{n\times n}(R)$. Then \[ \det(AB) = \det(A) \det(B).\]

\

\textsc{Proposition:} Let $R$ be a commutative ring. Let $A$ be a square matrix, and $B$ be a matrix obtained from $A$ by an elementary column operation.
\begin{itemize}
\item For the operation ``add $r\in R$ times column $i$ to column $j$'' we have $\det(B) = \det(A)$.
\item For the operation ``multiply column $i$ by $u\in R^\times$'' we have  $\det(B) = u \det(A)$.
\item For the operation ``swap column $i$ and column $j$'' we have  $\det(B) = -\det(A)$.
\end{itemize}
 \end{framed}


\begin{enumerate}
\setcounter{enumi}{2}

\itemA  Use Theorem 1 to prove the Proposition.

\solution{Write $A= \begin{bmatrix} v_1 & v_2 & \cdots & v_n\end{bmatrix}$. 

Say that $B$ is obtained from $A$ by adding $r$ times column $1$ to column $2$. Then $B= \begin{bmatrix} v_1 & v_2 + r v_1 & \cdots & v_n\end{bmatrix}$ and 
\[ \det(B) = \det(\begin{bmatrix} v_1 & v_2  & \cdots & v_n\end{bmatrix}) +  r \det(\begin{bmatrix} v_1 & v_1 & \cdots & v_n\end{bmatrix} ) = \det(A).\]
Similarly for $i$ and $j$ in place of $1$ and $2$.

Say that $B$ is obtained from $A$ by multiplying column $1$ by $u$. Then
$B= \begin{bmatrix} u v_1 & v_2  & \cdots & v_n\end{bmatrix})$ and 
\[ \det(B)= \det(\begin{bmatrix} u v_1 & v_2  & \cdots & v_n\end{bmatrix}) = u \det(A).\]
Similarly for general $i$.

The column swap operation was 1(d).}

\itemA Use the Proposition (and not the definition) to compute $\mathrm{det} \begin{bmatrix} 1 & 2 & 3 \\ 2 & 5 & 8 \\ 3 & 7 & 13 \end{bmatrix} \in \mathrm{Mat}_{3\times 3}(\Q)$.

\solution{$2$}

\itemA Proof of Theorem 2 in the case $R=F$ is a field:
\begin{enumerate}
\itema Prove Theorem 2 in the case $B=E$ is an elementary matrix.
\itema Prove\footnote{Hint: You can use the fact that over a field, every invertible matrix is a product of elementary matrices} Theorem 2 in the case $A$ and $B$ are both invertible matrices.
\itema Show that $AB$ is invertible if and only if $A$ and $B$ are both invertible.
\itema Show\footnote{Hint: Use part (a) and 1(c).} that $\det(A)\in F^\times$ if and only if $A$ is invertible.
\itema Complete the proof of Theorem 2 in the field case.
\end{enumerate}

\solution{
\begin{enumerate}
\itema Recall that $AE$ is the matrix obtained from $A$ by an elementary column operation of the same ``type''. Moreover, $E$ is the matrix obtained from the identity by the same elementary column operation. Thus, when $E$ is type I, we have $\det(E) = 1$ and $\det(AE) = \det(A)$ by the Proposition, so the claim holds. We check type II and type III in the same way.
\itema Let $B= E_1 \dots E_n$. By part (a) and induction on $n$, we have $\det(B) = \det(E_1) \cdots \det(E_n)$, and also by part (a) and induction on $n$, we have $\det(AB) = \det(A) \det(E_1) \cdots \det(E_n)$, so $\det(AB) = \det(A) \det(B)$.
\itema If $A$ and $B$ are invertible, then $(AB)B^{-1}A^{-1} = B^{-1} A^{-1} (AB) = I$. If $AB$ is invertible, then $A (B (AB)^{-1}) = I$ implies that $t_A$ is surjective, and hence bijective by a Rank-Nullity argument akin to 1(c). Similarly, $((AB)^{-1} A) B = I$ implies that $t_B$ is injective, and hence surjective by a Rank-Nullity argument akin to 1(c).
\itema If $A$ is invertible, then $A$ is a product of elementary matrices, which all have nonzero determinant, so $\det(A)\in F^\times$ by (b). If $A$ is not invertible, then $\det(A)=0$ by 1(c).
\itema The case where $\det(A)=0$ or $\det(B)=0$ follows from (c) and (d). The case where $\det(A)\neq 0$ and $\det(B)\neq 0$ follows from (d) and (b).
\end{enumerate}

}

\itemB Prove that $\det(A)=\det(A^T)$.

\

\itemB Prove the Laplace expansion formula (along the first column): for $A\in \mathrm{Mat}_{n\times n}(R)$,
\[ \det(A) = \sum_{i=1}^n (-1)^{i+1} a_{i,1} \det(\widehat{A}_{i,1}),\]
where $\widehat{A}_{i,1}$ is the $(n-1)\times(n-1)$ matrix obtained from $A$ by removing the $i$th row and first column.


\end{enumerate}









\end{document}
