\documentclass[12pt]{amsart}
\usepackage{graphicx, framed}
\usepackage{comment}
\usepackage{amscd}
\usepackage{amssymb,xcolor}
\usepackage{multicol}
\usepackage[all, knot]{xy}
\usepackage{enumitem}
%\usepackage[top=1.2in, bottom=1.2in, left=1.2in, right=1.2in]{geometry}
\xyoption{all}
\xyoption{arc}
\usepackage{hyperref}



\renewcommand\labelitemii{$\diamondsuit$}


% The following causes equations to be numbered within sections
\numberwithin{equation}{section}


\theoremstyle{plain} %% This is the default, anyway
\newtheorem{thm}[equation]{Theorem}
\newtheorem{preproof}{Preproof Discussion}
\newtheorem{obs}{Observation}
\newtheorem{thmdef}[equation]{TheoremDefinition}
\newtheorem{introthm}{Theorem}
\newtheorem{introcor}[introthm]{Corollary}
\newtheorem*{introthm*}{Theorem}
%\newtheorem{question}{Question}
\newtheorem*{question}{Question}
\newtheorem{cor}[equation]{Corollary}
\newtheorem{lem}[equation]{Lemma}
\newtheorem{prop}[equation]{Proposition}
\newtheorem{porism}[equation]{Porism}
\newtheorem{slogan}[equation]{Slogan}
\newtheorem{algorithm}[equation]{Algorithm}
\newtheorem{axiom}[equation]{Axiom}
\newtheorem*{axioms*}{Axioms}
\newtheorem*{axiom*}{Axiom}
\newtheorem{conj}[equation]{Conjecture}
\newtheorem{quest}[equation]{Question}


\newcommand{\Aug}[1]{\section{August #1, 2022}}
\newcommand{\Sept}[1]{\section{September #1, 2022}}
\newcommand{\Oct}[1]{\section{October #1, 2022}}
\newcommand{\Nov}[1]{\section{November #1, 2022}}
\newcommand{\Dec}[1]{\section{December #1, 2022}}

\newcommand{\rsa}{\rightsquigarrow}


\theoremstyle{definition}
\newtheorem{defn}[equation]{Definition}
\newtheorem{chunk}[equation]{}
\newtheorem{ex}[equation]{Example}
\newtheorem{idea}[equation]{Idea}

\newtheorem{exer}[equation]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[equation]{Remark}

\newtheorem{notation}[equation]{Notation}
\newtheorem{terminology}[equation]{Terminology}

%%%%%%%%%%%%%
% local definitions
%%%%%%%%%%%%%


\newcommand{\R}{\mathbb{R}}

\makeindex

\begin{document}


\setcounter{tocdepth}{1}
\tableofcontents


\Aug{23}

This class is, as its name makes clear, is all about differential equations. Let's start with an example that is probably similar to something you've seen in Calculus.

\begin{ex}
The equation
\[ \frac{dy}{dx} = 7 y\]
is a differential equation. The unknown in this equation, $y$, stands for a function. What makes this equation a differential equation is that the equation relates the mystery function and its derivative.

Let's see if we can guess a solution. This equation might remind us of a curious calculus coincidence. If the $7$ wasn't there, we would be looking for a function whose derivative is equal to itself; $e^x$ would work. 

Let's try $y=7e^x$ for our original equation. To test it, we plug it in:
\[ y = 7 e^x \rsa y' = (7e^x)' = 7e^x \neq 7y = 49e^x.\]
How about putting the $7$ somewhere else:
\[  y = e^{7x} \rsa y' = (e^{7x})' = e^{7x} (7x)' = 7 e^{7x} = 7y.\]
So $e^{7x}$ is a solution!

Could there be any others?
\[  y = 5e^{7x} \rsa y' = (5e^{7x})' = 5e^{7x} (7x)' = 7 (5e^{7x}) = 7y.\]

In general, $y(x) = C e^{7x}$ is a solution for any constant $C$.
\end{ex}

Of course, at the end of the day, nothing was special about $7$. If we replaced $7$ by any real number $a$, for the same reason, we would find that for the differential equation
\[ y' = ay\]\index{$y'=ay$}
the \emph{general solution}\index{general solution} is
\[ y(x) = C e^{ax}.\]

Guessing, while successful here, is not going to be our preferred method in the class. Let's savor this victory, and be prepared to collect many methods for solving differential equations as we progress through the course.

\subsection*{Types of differential equations (\S1.1)}
There are many different ways of throwing together functions and derivatives in an equation, so we'll need some terminology to orient ourselves.

\begin{defn} An \emph{ordinary differential equation (ODE)}\index{ordinary differential equation}\index{ODE} is a differential equation involving only one independent variable; i.e., derivatives with respect to just one variable.
\end{defn}
 For example,
 \[ \frac{d^2 y}{dt^2} + t \frac{dy}{dt} = -y + \cos(ty)\]
 is an ordinary differential equation.
 
In general an ODE is an equation of the form \[F(t,y,y',y'',\dots,y^{(n)})=0\] for some function $F$ where $y=y(t)$: an equation relating the function $y$ with its derivative(s).

\begin{defn} A \emph{partial differential equation (PDE)}\index{partial differential equation}\index{PDE} is a differential equation involving multiple independent variable; i.e., derivatives with respect to different variables.
\end{defn}
For example, 
\[ \frac{\partial u}{\partial t} - 5 \frac{\partial u}{\partial x} = 0\]
and 
\[ \frac{\partial^2 z}{\partial x \partial y} -z^2 = xy\]
are PDEs. A solution of the first PDE would be a function $u(x,t)$ that depends two independent variables $x$ and $t$.
 
The ``ordinary'' vs ``partial'' refers to what type of derivatives see. 

This is a class about ODEs. Almost all of the rest of the differential equations we see this semester will be ordinary!


\begin{defn} The \emph{order}\index{order} of a differential equation is the highest order derivative that occurs in the equation.
\end{defn}

For example,
\[ y y'' +  y''' + \frac{1}{y} = 5x\]
is a third order ODE, due to the $y'''$ term and
 \[ \frac{d^2 y}{dt^2} + t \frac{dy}{dt} = -y + \cos(ty)\]
 is a second order ODE.
 
 \begin{defn} A \emph{linear}\index{linear} ODE is any ODE of the form
 \[ a_n(t) y^{(n)} + a_{n-1}(t) y^{(n-1)} + \cdots + a_2(t) y'' + a_1(t) y' + a_0(t) y = f(t).\]
 \end{defn}
 For example,
 \[ 5t y'' + \ln(t) y' + y = \cos(t)\]
 is a second order linear ODE, but 
 \[ y y' + 5y = 7\]
 and 
 \[ (y')^3 - t y^2 = 3 e^t\]
are first order nonlinear ODEs.

We will be especially interested in linear ODEs in this course!

 
\subsection*{Discussion Questions}
\begin{enumerate}
\item Is the differential equation $y' = y^{2/3}$ ordinary? linear? What is its order?
\begin{framed}
Ordinary yes, linear no, order 1.
\end{framed}
\item Which of the following is a solution to the differential equation $y' =y^{2/3}$:
\begin{enumerate}
\item $y=8 t^2$
\item $y= e^{{2t/3}}$
\item $y=\frac{1}{27} t^3$
\item $y=0$ (constant function 0)
\end{enumerate}
\begin{framed}
\begin{enumerate}
\item No: $y' = 16t \neq y^{2/3} = 4t^{4/3}$.
\item No: $y' = 2/3 e^{2t/3} \neq y^{2/3} = (e^{2t/3})^{2/3} = e^{4t/9}$.
\item Yes: $y' = \frac{1}{9} t^2 = y^{2/3}$.
\item Yes: $y'=0=y^{2/3}$.
\end{enumerate}
\end{framed}
\item There is a solution to $x y'' = (4x -4) y$ of the form $y=xe^{ax}$ for some real number $a$. Find $a$.
\begin{framed}
By the product rule, \[y'=(ax+1) e^{ax} \quad \text{and} \quad y''=(a^2 x + 2a) e^{ax},\] so  \[xy'' - (4x-4)y = (a^2 x^2 +2ax) e^{ax} - (4x-4)x e^{ax}.\] If this is zero, we must have \[a^2 x^2 + 2ax = 4x^2 - 4x\] as functions of $x$, so $a=-2$.
\end{framed}
\item[(4*)] If $f,g$ are solutions to $y^{(3)} + 2e^x y^{(2)} -y = \cos(x)$, show that $\frac{f+g}{2}$ is too.
\item[(5*)] Using only calculus, justify the claim we made earlier that $y=Ce^{ax}$ is the general solution to $y'=ay$ for any $a\in \R$. That is, explain why there aren't any other solutions (exponential or otherwise).
\end{enumerate}

\subsection*{Initial value problems}

In our first example, we saw that there are many solutions to the differential equation $y'=7y$. To pin one down, we might specify a value for our function at a point. The system
\[\begin{cases} y' = 7y \\ 
y(2)=4 \end{cases}\]
is a example of an \emph{initial value problem (IVP)}\index{initial value problem}\index{IVP}. Geometrically, $y(2)=4$ corresponds to the condition that the graph of our solution passes through $(2,4)$.




\Aug{25}

\begin{ex}\label{ex:first IVP}
\[\begin{cases} y' = 7y \\ 
y(2)=4 \end{cases}\]
is a example of an \emph{initial value problem}. Geometrically, $y(2)=4$ corresponds to the condition that the graph of our solution passes through $(2,4)$.


We can solve this using our solution of $y'=7y$ from earlier. We have
\[ y= Ce^{7x} \qquad y(2)=4\]
so \[ 4 = C e^{7 \cdot 2}\]
and \[ C= 4e^{-14}.\]
That is,
\[ y= 4e^{-14}e^{7x} = 4 e^{7x-14}.\]
\end{ex}

\subsection*{Modeling with differential equations (\S1.3)}

Differential equations is one of the most useful areas of math for applications, since so many real life things are described effectively by differential equations. A \emph{mathematical model}\index{mathematical model} is a description of some system or phenomenon by an equation or a formula. A model is rarely perfect, since we can't even know all of the factors that might affect something, but we can often use them to understand things better.

Let's start with a basic example.

\begin{ex} \index{population model}A classical model of human population growth is based on the assumption that the rate at which the population of a country grows is proportional to the population of that country. To express this as a differential equation, let $P$ the population of a country. We are interested in how it changes, so let $t$ be a variable for time and view $P$ as a function of $t$.  To say that two things are \emph{proportional}\index{proportional} means that the exists a constant $k$ (called the \emph{constant of proportionality}) such that $k$ times the first quantity is the second quantity. The rate of change of the population is $\frac{dP}{dt}$. Thus, our equation is
\[ \frac{dP}{dt} = kP \]
for some constant $k$. We do not know what $k$ is without further information.

This is the only differential equation we've solved! We must have 
\[ P(t) = C e^{kt}.\]
Given two data points for any specific population, we can determine $C$ and $k$.
\end{ex}



Let us try to set up a more complicated model.

\begin{ex} \index{mixing model}Say that we have a tank of water. At first, it holds $500$ liters of pure water (no salt). After  switch is flipped, salt water that has 7 grams of salt per liter starts flowing in at a rate of 2 liters per minute, and water from the bottom of the tank starts flowing out at a rate of 2 liters per minute. 
%We assume that the water stays well mixed so that the water flowing out is as salty as the average water in the tank. 
Let's model the amount of salt in the tank at a given time after the switch is flipped.

Let $A$ be the amount of salt in the tank, in grams, and $t$ be the amount of time since the switch is flipped in minutes.
We need to understand the rate of change of $A$. Salt enters at a rate of $7 \cdot 2 = 14$ grams per minute. To find the rate at which salt exits, the amount of salt in an average liter of water is $A/500$ grams per liter, so the amount of salt exiting is $2 \cdot A/500 = A/250$.

We obtain the differential equation
\[ \frac{dA}{dt} = 14 - \frac{A}{250}.\]
We also have the initial condition $A(0)=0$.

We will learn how to solve systems like this soon.
\end{ex}







\subsection*{Discussion Questions}

\index{counterfeit money}
The government of a country wants to remove counterfeit money from circulation. Say there are 20 million total bills in circulation. Every day, 4 million of its bills pass though federal banks, and every counterfeit bill collected is replaced by a legal one. Say that half of the total bills in circulation today are counterfeit. Let's assume that the total number of bills in circulation stays constant and that no more counterfeit bills are being introduced. Our goal is to find an initial value problem modeling the percentage of counterfeit bills in circulation as time passes. 

\begin{enumerate}
\item Introduce variables to keep track of the quantities we are interested in. What is the independent variable and what is the dependent variable? What are the units for each?
\item To set up a differential equation, we want to relate the dependent variable with its rate of change. On average, what is the change in the number of counterfeit bills each day\footnote{Hint: First figure out how many counterfeit bills pass through federal banks each day, on average.}?
\item Express the previous part as a differential equation.
\item We also need an initial condition. Write it down.
\item This is a type of differential equation we've solved already. Find an explicit solution.
\item Based on your model, when will the total number of counterfeit bills pass below 3 million?
\end{enumerate}
\begin{framed}
\begin{enumerate}
\item Take $t$ for time (number of days after today), and $C$ to be the number of millions of counterfeit bills in circulation. $C$ is dependent on $t$.
\item First the number of bills that pass through banks on an average day is $4C/20 = C/5$: the proportion of counterfeit bills times the total number of millions of bills passing through the banks. Thus, $C$ decreases by $C/5$ on average each day.
\item $C'=-C/5$.
\item $C(0)=10$.
\item $C(t)=ke^{-t/5}$ is the general solution. We plug in $C(0)=10$ to get $k=10$, so $C(t)=10 e^{-t/5}$.
\item $C(t)=3$ gives us $10e^{-t/5}=3$. Then $t=-5 \ln(3/10) \approx 6$. It should take about $6$ days.
\end{enumerate}
\end{framed}

Let's do an experiment to test our model. Each coin you've been given represents a million bills. Some represent valid coins and some represent counterfeits. Every day, take four random coins; replace the counterfeits with legal ones, and leave the legal ones alone.

\begin{enumerate}
\item Discuss whether your model for the previous situation is relevant to this experiment. What aspects fit the story well, and what ones don't?
\item Run the experiment, keeping track of the number of counterfeit bills each day, and how long it takes to get down to 3 counterfeits. Even better, run the experiment a few times.
\end{enumerate}

Now let's change our original story. As before, every day, 4 million of its bills pass though federal banks, and every counterfeit bill collected is replaced by a legal one. Say that half of the 20 million total bills in circulation today are counterfeit. But now, let's assume that 1 million new legal bills and 1 million new counterfeit bills are put into circulation each day.

\begin{enumerate}
\item Create a new differential equation and initial value problem to model this situation\footnote{Hint: You might find it helpful to write a closed formula for the number of total bills in circulation at a given time first.}. 
%You might find it helpful to write a closed formula for the number of total bills in circulation at a given time first.
%\item This is not a differential equation that we have solved yet. We will learn how to find explicit solutions of equations like this soon! But even without knowing what exactly the solution is, explain why there is one and only one solution to this initial value problem.
\item Run an experiment similar to the one above adapted to this situation.
\item Based on the experiment, what do we expect to happen to the currency as time passes?
\end{enumerate}
\begin{framed}
\begin{enumerate}
\item Let's use $t$ and $C$ as names again. The total number of bills at time $t$ is now $20+2t$. Now $C'(t) = 1 - \frac{4 C}{20+2t} = 1-\frac{2C}{10+t}$, and $C(0)=10$ again.
\end{enumerate}
\end{framed}




\Aug{30}

We will now spend a while focusing on first-order ODEs and corresponding initial value problems: all of Section 1.2 and Chapter 2 will be about this setting.

\subsection*{Existence and uniqueness for initial value problems (\S1.2)}
If our goal in solving an initial value problem
\[\begin{cases} y' = f(x,y) \\ y(x_0) = y_0\end{cases}\]
 is to find \emph{the} function that satisfies the two conditions, for this goal to make sense, there should be a function, and only one function that satisfies the two conditions. The \emph{existence}\index{existence} question for an IVP is whether there is any function that satisfies both conditions; the \emph{uniqueness}\index{uniqueness} question for an IVP is whether there is at most function that satisfies both conditions. (Actually \emph{finding} this function is a different question.)

Let's consider these things in some examples we have seen before.

\begin{ex} In Example~\ref{ex:first IVP}, we considered the IVP
\[\begin{cases} y' = 7y \\ 
y(2)=4 \end{cases}\]
and saw that the function $y= 4 e^{7x-14}$ was the one and only solution. Thus, there exists a unique solution in this case.
\end{ex}


On the other hand, we have the following.

\begin{ex} Consider the IVP
\[\begin{cases} y' = y^{2/3} \\ 
y(0)=0 \end{cases}.\]
We saw in the Discussion Questions from Aug 25 that $y=0$ and $y=\frac{1}{27} t^3$ both satisfy the first differential equation. Both of these functions also satisfy the initial condition, so they are also both solutions to the IVP. Here we have an IVP for which the solution is not unique.
\end{ex}

We can even have no solution sometimes.

\begin{ex} Consider the IVP
\[\begin{cases} y' = \begin{cases} 1 & \text{if } y\geq 0 \\ -1 & \text{if } y  <0\end{cases}\\ y(0) = 0\end{cases}.\]
This IVP has no solution, no matter how small of an interval! (Challenge: why not?)
\end{ex}

Luckily, there is a theorem that guarantees existence and uniqueness of solutions IVP's under certain hypotheses.

\begin{thm}[Picard-Lindel\"of]\index{Picard-Lindel\"of} For the IVP
\[\begin{cases} \frac{dy}{dx} = f(x,y) \\ 
y(x_0) = y_0 \end{cases}\]
and some rectangle $R$ in the $(x,y)$-plane containing $(x_0,y_0)$ in its interior,
there exists a unique solution on some possibly smaller interval $(x_0 - h, x_0+h)$, so long as $f$ and $\frac{\partial f}{\partial y}$ are continuous on $R$.
\end{thm}

There's a lot of fine print, but here is the upshot: There exists a unique solution to the IVP
\[\begin{cases} \frac{dy}{dx} = f(x,y) \\ 
y(x_0) = y_0 \end{cases}\]
near $x_0$, so long as $f$ and $\frac{\partial f}{\partial y}$ are continuous around $(x_0,y_0)$.

\begin{ex} Consider the differential equation
\[ \frac{dy}{dx} = 5 xy.\]
We want to use the Picard-Lindel\"of Theorem to show that for any initial condition $y(x_0)=y_0$, there is a unique solution near $x_0$. The $f(x,y)$ of the Theorem is $5xy$; this is continuous on all of $\mathbb{R}^2$. We also need to look at $\frac{\partial f}{\partial y} = 5x$. This is also continuous on all of $\mathbb{R}^2$.
We conclude that 
\[\begin{cases} \frac{dy}{dx} = 5xy \\ 
y(x_0) = y_0 \end{cases}\]
has a unique solution, no matter what $x_0$ and $y_0$ are.
\end{ex}

\begin{ex} Let's consider
\[\begin{cases} y' = y^{2/3} \\ 
y(x_0) = y_0 \end{cases}.\]
Here $f(x,y) = y^{2/3}$ and $\frac{\partial f}{\partial y}(x,y) = \frac23 y^{-1/3}$. $f$ is continuous everywhere, but $f'$ is only continuous where $y_0\neq 0$.
Thus, if $y_0\neq 0$, then there is a unique solution.

However, if $y_0=0$, the theorem does not apply. We looked at this example earlier and saw that the solutions were not unique for $(x_0,y_0) = (0,0)$.
\end{ex}


\begin{ex} Let's consider
\[ \begin{cases} y' = \frac{y^2}{t^2-4} \\
y(-1) = 3 \end{cases}.\]
What is the largest interval on which the Picard-Lindel\"of Theorem guarantees the existence of a unique solution?
We have, in the notation of the Theorem,
\[ f = \frac{y^2}{t^2-4} \qquad \frac{\partial f}{\partial y}=\frac{2y}{t^2-4}.\]
These are continuous except when $t=\pm 2$. Thus, any rectangle whose base is contained in $(-2,2)$ will satisfy the hypotheses of the theorem, so $(-2,2)$ is the interval we seek.
\end{ex}

\subsection*{Solution curves from slope fields (\S 2.1)} There is a great way to visualize solutions to differential equations without solving them. The idea is to think of $\frac{dy}{dt}$ geometrically as the slope of the graph of $y$.

\begin{ex}\label{ex:first aut} Consider the differential equation 
\[ y' = 3-y.\]
We won't try to write down a solution yet. Instead, on the plane, we draw little lines with slope $3-y$ at various points.\\
\begin{center}\includegraphics[scale=.5]{sf1}\end{center}
We can use this to sketch the solution to the IVP
\[\begin{cases} y' = 3-y \\
y(2)= 2 \end{cases}\]
by starting at $(2,2)$ and going along with the flow.
\begin{center}\includegraphics[scale=.5]{sf2}\end{center}

Or 
\[\begin{cases} y' = 3-y \\
y(-4)= 4 \end{cases}:\]
\begin{center}\includegraphics[scale=.5]{sf3}\end{center}
\end{ex}

The picture we drew above is called a \emph{slope field}.\index{slope field}

\subsection*{Discussion Questions} Draw a slope field for the differential equation
\[ y'= x+y\] and use it to sketch the solutions with initial conditions
\begin{enumerate}
\item $(0,1)$
\item $(0,0)$
\item $(0,-1)$
\item $(0,-2)$
\end{enumerate}
\begin{framed}
\begin{center}\includegraphics[scale=.5]{sf4}\end{center}
\end{framed}

%\begin{comment}



\Sept{1}

\begin{ex} As we discussed, we can use slope fields to try to understand solutions of an IVP without finding a formula for an explicit solution. Let's return to our counterfeiting example (where new good and bad bills were being introduced, and the banks replaced bad ones with good ones). We found the following IVP for our situation:
\[ \begin{cases} C'(t) = 1-\frac{2C}{10+t} \\
C(0)=10\end{cases}.\]
We wanted to know whether the number of counterfeits would continue to grow (and if so, how fast).
Let's sketch a slope field for our differential equation:
\begin{center}\includegraphics[scale=.5]{sf7}\end{center}
and sketch a curve for the initial condition:
\begin{center}\includegraphics[scale=.5]{sf8}\end{center}
It looks like the number of counterfeits decreases at first and maybe starts to rebound. We will solve this analytically very soon to confirm our guess.
\end{ex}




\subsection*{Autonomous differential equations}
Example~\ref{ex:first aut} belongs to a class of equations that is worth singling out.
\begin{defn} A differential equation of the form \[ y' = f(y)\]
 is said to be \emph{autonomous}.\index{autonomous}
 \end{defn}
 
 The behavior of a solution of an autonomous differential equation is determined entirely by the current value of the function (and not the independent variable).
 
For an autonomous differential equation, whether a solution is increasing, decreasing, or constant at a point only depends on the $y$-value at that point. We can determine this either algebraically or using the slope field.

\begin{ex}
Consider the autonomous differential equation 
\[ y' = y^3 - 2y^2.\]
To figure out when $y$ is increasing, we figure out when $0<y' =  y^3 - 2y^2$.
We do a little algebra to figure out. Factoring, we see that the zeroes of the right-hand side are $0$ and $2$, so the sign of $y$ can only change at $0$ and $2$. On $(-\infty, 0)$, $y^3 - 2y^2<0$; at $0$, it is zero; on $(0,2)$ it is negative; at $2$, it is $0$; on $(2,\infty)$, it is positive.

Thus, a solution $y$ is increasing when $2 < y <\infty$, is decreasing on $(-\infty,0) \cup (0,\infty)$, and is constant if $y=0$ or $2$.

We can also use the slope field to determine when it is increasing or decreasing.
\begin{center}\includegraphics[scale=.5]{sf5}\end{center}
Let's sketch some solutions:
\begin{center}\includegraphics[scale=.5]{sf6}\end{center}
\end{ex}

A constant solution to an autonomous differential equation is also called an \emph{equilibrium solution}\index{equilibrium solution}.


\subsection*{Review of integration} Now we will start to collect some techniques for solving differential equations. Of course integration will play a big role. Let's review some basic techniques of integration. We will usually be using \emph{indefinite integration} or \emph{antidifferentiation} in this class. First, let's recall a list of building block functions whose integrals we need to know. 

\begin{itemize}
\item $\int x^n \, dx = \frac{x^{n+1}}{n+1} + C$ when $n\neq -1$.
\item $\int \frac{1}{x} \, dx = \ln|x| + C$.
\item $\int e^x \, dx = e^x + C$.
\item $\int \sin(x) \, dx = -\cos(x) + C$.
\item $\int \cos(x) \, dx = \sin(x) + C$.
\end{itemize}

Here are a couple more special ones.

\begin{itemize}
\item $\int \frac{dx}{\sqrt{1-x^2}} = \arcsin(x) + C$.
\item $\int \frac{dx}{1 + x^2} = \arctan(x) + C$.
\end{itemize}

We also have many rule for how to integrate complicated functions in terms of integrating smaller parts. There are two easy rules to get us started.

\begin{itemize}
\item $\int f(x) + g(x) \, dx = \int f(x)  \, dx + \int g(x) \, dx$.
\item $ \int c f(x) \, dx = c \int f(x)  \, dx$ for any constant $c$.
\end{itemize}

Unlike with derivatives, there is no direct rule for computing the integral of a composition or a product. Instead, we have ``$u$-substitutions''\index{u-substitution} and ``integration by parts''\index{integration by parts}. 

$u$-substitution is a technique that is likely to work when we can see some function and something like its derivative inside the function we are trying to integrate. In this case, we set the function to be $u$, we set $du= u'(x) \, dx$, and we try to rewrite our integrand as some function of $u$  times $du$ (and get rid of our starting variable entirely). $u$-substitutions also work well when instead of some function of $x$, we have a function of $x-a$ or a function of $ax$ for some constant $a$.
This is the main technique that we will want to use, other than the basic rules.

\begin{ex}
To compute $\int x^2 \cos(x^3) \, dx$, take $u=x^3$, so ${du=3x^2 \, dx}$. Then we have ${x^2 \, dx = \frac13 \, du}$, so our integral is \[\int \frac13 \cos(u)\,  du = {\frac13 \sin(u) + C}= \frac13 \sin(x^3) +C.\]
\end{ex}


Integration by parts is a technique that might work when our integrand is a product of two things, one of which we know how to integrate (i.e., looks like the derivative of something). The general rule is if we can find functions $u(x), v(x)$ such that our integral is $\int u \, dv$ (where $dv = v'(x) \, dx$), the we have
\[ \int  u \, dv = uv -  \int v \, du;\]
and if we can integrate $ \int v \, du$, we are done. A rule of thumb for what to choose for $u$ vs what to choose for $dv$ in integration by parts is LIATE (log, inverse trig, algebraic, trig, exponential): stuff on the left is usually better for $u$'s and stuff on the right is usually better for $dv$'s.

\begin{ex}
To compute $\int x e^x \, dx$, take $u=x$ and $dv= e^x \, dx$. Then $du = dx$ and $v=e^x$. Then we have \[\int x e^x \, dx = x e^x - \int e^x \, dx = x e^x - e^x +C = (x-1) e^x +C.\]
\end{ex}

Last but not least, we have a big table of integrals in the front cover of our text. 


\Sept{6}

\subsection*{Separable first-order equations (\S2.2)} Now we are ready to solve some differential equations! First we will address first-order equations of a special form: separable eqautions.

\begin{defn} A first-order ODE is \emph{separable}\index{separable} if it can be written in the form
\[ y' = f(x) g(y)\]
for some function $f$ that only involves the independent variable and some function $g$ that only involves the dependent variable.
\end{defn}

For example,
\[ y' = x^2/y, \quad y' = \frac{3 \sqrt{y^2+1}}{\cos(x)}, \quad \text{and} \ y' = 3-y \]
are all separable (with $f(x)=x^2$ and $g(y)=1/y$ in the first one), but
\[ y' = x+y \quad \text{and} \quad y'=\sin(xy) \]
are not. Note that a separable equation may or may not be linear, but is always a first order ODE.

Here's how to solve a separable ODE: Write $y'$ as $\frac{dy}{dx}$ and pretend that the $dy$ and $dx$ are separate things. Take
\[ \frac{dy}{dx} = f(x)g(y)\]
and multiply by $dx$ and divide by $dy$ on both sides to get
\[ \frac{dy}{g(y)} = f(x) \, dx.\]
(This is why we call the equation separable: the independent and dependent variables now occur on separate sides of the equation.) Now integrate both sides:
\[ \int \frac{dy}{g(y)} = \int f(x) \, dx,\]
to get an equation for $x$ and $y$ that is no longer differential!

\begin{slogan} To solve a separable equation, separate and integrate!\end{slogan}

\begin{ex} Let's start with an equation we saw in Example~\ref{ex:first aut}:
\[ y' = 3-y.\]
Write this as 
\[ \frac{dy}{dx} = 3-y\]
and rearrange to get
\[ \frac{dy}{3-y} = dx.\]
Integrate both sides. For the LHS with use the $u$-sub $u=3-y$, so $du = - dy$. The integral becomes
\[ \int  \frac{dy}{3-y} = \int \frac{-du}{u} = -\ln|u| +C = -\ln|3-y|+C = \ln\frac{1}{|3-y|} +C.\]
We then get 
\[ \ln\frac{1}{|3-y|}  = \int  \frac{dy}{3-y} =\int \,dx = x + C.\]
Note that we only need the constant of integration on one side.
Then to solve for $y$, take exponentials:
\[ e^{\ln(\frac{1}{|3-y|})} = e^{x+C},\]
\[ \frac{1}{|3-y|} = e^{x+C}.\]
Then 
\[ |3-y| ={e^{-x-C}}\]
\[ 3-y =  \pm {e^{-x-C}}\]
\[ y =  3 \pm {e^{-x-C}}\]
Since $e^{-x-C}=e^{-x} e^{-C}$ is just some other constant $C'$ times $e^{-x}$, we could also write
\[ y= 3 + C' e^{-x}.\]
\end{ex}

\begin{ex} Take
\[ \frac{dy}{dt} = t + ty^2.\]
It doesn't look separable yet, but once we factor
\[ \frac{dy}{dt} = t (1 +y^2),\]
it becomes clear that it's separable. Separate variables:
\[ \frac{dy}{1+y^2} = t \, dt,\]
integrate:
\[ \int \frac{dy}{1+y^2} = \int t \, dt,\]
\[ \arctan(y) = \frac{t^2}{2} + C,\]
and solve for $y$ by taking tangent of both sides:
\[ y=\tan(\arctan(y)) = \tan\left(  \frac{t^2}{2} + C\right).\]
This is our general solution!
\end{ex}


\subsection*{Discussion Questions}
\begin{enumerate}
\item Which of the following equations is separable?
\begin{enumerate}
\item $y' + 2y = x^3$.
\item $\cos(x) y' = \sin(y)$.
\item $y' - xy = 1+x+y$.
\end{enumerate}
\begin{framed}
(b) and (c), but not (a)
\end{framed}
\item Find the particular solution to the IVP
\[ \begin{cases} 
e^{x} \, y' = \frac{1}{y} \\
y(0) = 1\end{cases}.\]
\begin{framed}
This is separable since we rewrite as $y' = e^{-x} \frac{1}{y}$. Then
\[ y y' = e^{-x} \rsa y  \ dy = e^{-x} \ dx \rsa \int  y  \ dy = \int e^{-x} \ dx,\]
\[ \rsa \frac{y^2}{2} = -e^{-x} + C \rsa y = \sqrt{C - 2 e^{-x}},\]
and using the initial condition,
\[ 1 = y(0) = \sqrt{C - 2 e^{0}} = \sqrt{C-2} \rsa C=3,\]
so we have
\[ y = \sqrt{3 - 2 e^{-x}}.\]
\end{framed}
\end{enumerate}

Sometimes we encounter integrals that are just impossible:

\begin{comment}
\begin{ex} Take 
\[ \frac{dy}{dt} = y e^{-t^2} \, dt\]
\[\rsa\quad \frac{dy}{y} = e^{-t^2} \, dt\]
\[\rsa\quad \int \frac{dy}{y} = \int e^{-t^2} \, dt.\]
The function $e^{-t^2}$ has no elementary antiderivative: it simply is not a function for which we have a name (in the way we usually name functions). Let's just leave it as an integral.
\[\rsa\quad \ln |y| = \int e^{-t^2} \, dt\]
\[\rsa\quad |y| = e^{\left(\int e^{-t^2} \, dt\right)}\]
\[\rsa\quad y =  \pm e^{\left(\int e^{-t^2} \, dt\right)}.\]
Here we have solved for $y$ \emph{up to an integral} in $t$.\index{solved up to an integral}
\end{ex}
\end{comment}

\subsection*{Linear equations (\S2.3)} Now we solve another large class of differential equations: first order linear ODE's.\index{first order linear ODE} Let's recall that a differential equation is a first order linear ODE if we can write it in the form
\[ a_1(t) y' + a_0(t) y = f(t)\]
for some functions $a_1(t),a_0(t),f(t)$ that only involve the independent variable $t$.

We are going to learn a magic trick to solve these: this really is a rabbit-in-the-hat idea. To motivate this wacky idea, I want to consider a couple of small examples to get the idea.

\begin{ex}
Consider the differential equation
\[ t y' + y=t^2.\]
After trying a few things, we realize this isn't separable. However, the left-hand side, as written, is interesting. Notice that, by the product rule, we have
\[ (ty)' = t y' + t' y= t y' + y.\]
Thus, we have
\[ (ty)' = t^2,\]
\[\rsa \quad ty = \int (ty)' \, dt = \int t^2 \, dt = \frac{t^3}{3} + C,\]
so \[ y = \frac{t^2}{3} + \frac{C}{t}.\]

\

That was lucky! What if we had
\[ y' + \frac{3}{t} y = t\]
instead? This is still not separable. I will magically multiply by $t^3$ to get
\[ t^3 y' + 3t^2 y = t^4.\]
By reverse product rule on the left-hand side, we have
\[ (t^3 y)' = t^4.\]
Now we integrate to get
\[ t^3 y = \int t^4 \, dt = \frac{t^5}{5} +C,\]
so \[y = \frac{t^2}{5} + \frac{C}{t^3}.\]

\

This is the idea we will use: multiply our equation through by something to turn it into an equation where the left-hand side comes from the product rule! But how do we come up with the magic multiplier?
\end{ex}

%\begin{comment}
\Sept{8}
\begin{idea}
Given a linear first order ODE of the form
\[ y' + p(t) y = q(t),\]
multiply by an \emph{integrating factor}\index{integrating factor} $\mu(t)$ so the left-hand side collapses via the product rule:
\[ \begin{array}{rcccl}
 &\mu(t) y' &+& \mu(t) p(t) y &= \mu(t) q(t)\\
 ( ?(t) y)' = &?(t) y' &+& ?'(t) y & \end{array}.\]
The mystery function $?(t)$ has to be the same as our integrating factor $\mu$, and we also have to have
\[ \mu' = \mu p(t).\]
This is separable now: we solve
\[ \frac{\mu'}{\mu} = p(t)\]
by integrating
\[ \ln |\mu| = \int p(t) \, dt,\]
and isolating $\mu$
\[ \mu = \pm e^{\int p(t) \, dt}.\]
Let's take the positive one:
Set $\mu = e^{\int p(t) \, dt}$.
\end{idea}

\begin{defn} Given a linear first order ODE of the form
\[ y' + p(t) y = q(t),\]
we call the function
\[ \mu = e^{\int p(t) \, dt}\]
the \emph{integrating factor}\index{integrating factor} of the equation. For the integrating factor, we can take just one antiderivative (i.e., ignore the constant of integration), since this is just something we're using to get a solution and not a solution.
\end{defn}

\begin{slogan}
For the linear first order ODE
\[ y' + p(t) y = q(t),\]
multiply by the integrating factor
\[ \mu = e^{\int p(t) \, dt},\]
realize the left-hand side as $(\mu y)'$,
and integrate.
\end{slogan}



Then we multiply by the integrating factor, realize the left-hand side as a result of the product rule, and integrate to solve.

\begin{ex} Let's solve the ODE that arose in our model of counterfeit currency from Aug 25. We found the equation
\[C'(t) = 1-\frac{2C}{10+t}\]
which we can write as
\[ C' + \frac{2}{10+t} C = 1.\]
The integrating factor is $\mu = e^{\int \frac{2}{10+t} \, dt}$.
We should simplify this. Set $u=10+t$, so $du = dt$, then \[\int \frac{2}{10+t} \, dt = \int \frac{2}{u} \, du = 2 \ln|u| = \ln((10+t)^2) \]
so 
\[ \mu = e^ {\ln((10+t)^2)} = (10+t)^2 .\]

Now we multiply by this integrating factor:
\[ (10+t)^2 C' + (10+t)^2\frac{2}{10+t} C = (10+t)^2\]
\[ \rsa (10+t)^2 C' + 2 (10+t) C = (10+t)^2.\]
Now we recognize the left-hand side as coming from the product rule:
\[ \big((10+t)^2 C \big)' = (10+t)^2 C' + (10+t)^2\frac{2}{10+t} C,\]
so we have
\[ \big((10+t)^2 C \big)' =(10+t)^2.\]
Now we integrate:
\[ (10+t)^2 C = \int (10+t)^2 \ dt.\]
Use the sub $u=10+t$, $du=dt$ to get
\[ \int u^2 \ du = \frac{u^3}{3} + k = \frac{(10+t)^3}{3} + k.\]
We used $k$ for the constant of integration since the name $C$ is taken!
Thus,
\[ (10+t)^2 C = \frac{(10+t)^3}{3} + k\]
\[\rsa C = \frac{10+t}{3} + \frac{k}{ (10+t)^2}.\]

We also recall our initial condition $C(0)=10$ and plug it in to get
\[ 10 = C(0) =  \frac{10+0}{3} + \frac{k}{ (10+0)^2} = \frac{10}{3} + \frac{k}{100}\]
and solve to get $k = \frac{2000}{3}$.
Thus,
\[ C(t) =  \frac{10+t}{3} + \frac{2000}{3 (10+t)^2}.\]
We can now graph this in a calculator:
\begin{center}\includegraphics[scale=.5]{gr1}\end{center}
and based on the formula, we know that for $t\gg0$, the second term goes to zero, and the first term gets larger and larger. We conclude that the number of counterfeits will continue to grow in the long run!
\end{ex}

\begin{ex}
Let's solve
\[ x y' = (x+3) y = x^2 e^{-x}.\]
We need to put it in the correct form first, so divide by $x$:
\[ y' + (1+\frac{3}{x}) y = x e^{-x}.\]
In the earlier notation, $p(x) = (1+\frac{3}{x})$. The integrating factor is
\[ \mu(x)=e^{\int (1+\frac{3}{x}) \, dx} = e^{ x + 3 \ln x} = e^x  e^{\ln x^3} = e^x  x^3 = x^3 e^x.\]
Multiply by $\mu(x)$:
\[ x^3 e^x y' + (1+\frac{3}{x}) x^3 e^x = (x^3 e^x) (x e^{-x})\]
and realize LHS as coming from product rule
\[ (x^3 e^x y)' = x^4.\]
Now we integrate:
\[ x^3 e^x  y = \frac{x^5}{5} + C\]
\[ y = \frac{x^2}{5} e^{-x} + \frac{C}{x^3} e^{-x}.\]
\end{ex}

\subsection*{Discussion Questions} Find the general solution of the differential equation
\[ y' = x+ y.\]


\begin{framed}
Rearrange as $y' - y = x$. Then the integrating factor is $e^{\int -1 \, dx} = e^{-x}$. Multiply through and do the product rule backwards to get
\[ (e^{-x} y)' =e^{-x} y - e^{-x} y' = x e^{-x}.\]
We now integrate both sides. On the right, we can use integration by parts with $u=x$, $dv= e^{-x} \, dx$, $du= dx$, $v= -e^{-x}$. We get (leaving aside the constant of integration)
\begin{align*} \int x e^{-x} \, dx& = - x e^{-x} - \int (-e^{-x}) \, dx \\&= -xe^{-x} + \int e^{-x} \, dx \\&= -xe^{-x}  - e^{-x} \\&= -(x+1) e^{-x}\end{align*}
so \[ e^{-x} y = - (x+1) e^{-x} + C.\]
Then multiply through to get
\[ y = -(x+1) + C e^x.\]
\end{framed}


\Sept{13}

Let's do one more example of solving a first-order linear equation with integrating factors.

\begin{ex} Let's find the general solution to
\[ x^2 y' - y = 5.\]
First, we put it in the form from which we can read off the integrating factor:
\[ y' - \frac{1}{x^2} y = \frac{5}{x^2}.\]
Now, the integrating factor is
\[ \mu(t) = e^{\int -1/x^2 \, dx} = e^{1/x}.\]
Multiply through to get
\[ e^{1/x} y' - e^{1/x}{x^2} y = \frac{ 5 e^{1/x}}{x^2}.\]
We realize the left-hand side as $(e^{1/x} y)'$ (and we double-check it using the product rule and the chain rule):
\[ (e^{1/x} y)' = \frac{ 5 e^{1/x}}{x^2}.\]
Thus
\[ e^{1/x} y = \int \frac{ 5 e^{1/x}}{x^2} \, dx = -5 \int e^{u} \, du = -5 e^{1/x} + C.\]
using the $u$-substitution $u=e^{1/x}$, $du= -e^{1/x}/x^2 \, dx$.
Finally, we get
\[ y = -5 + C e^{-1/x}\]
as the general solution.
\end{ex}


\subsection*{Euler's Method (\S2.6)}

We now have great methods to solve certain first order ODEs, namely separable and linear ones. But this doesn't encompass all of them. There is a way to solve any IVP for first order ODE of the form
\[\begin{cases} \frac{dy}{dt} = f(t,y) \\ y(t_0) = y_0\end{cases},\]
at least approximately.  The idea is that 
\[\frac{dy}{dt}\approx \frac{\Delta y}{\Delta t} = \frac{\text{small change in $y$}}{\text{small change in $t$}},\]
which we can rewrite as \[\Delta y \cong \frac{dy}{dt} \, \Delta t.\]
So, to approximate our solution, we start at our initial value $y(t_0) = y_0$, keep adding small amounts $\Delta t$ to $t$, and each time we add
\[ \frac{dy}{dt} \, \Delta t = f(t,y) \, \Delta t \] to our $y$-value. This is the idea behind \emph{Euler's method}.\index{Euler's method}

More concretely, we fix a \emph{step size}\index{step size} $h$, which plays the role of our small change in $t$ that we called $\Delta t$. This should be a small positive number. (Though how small is a good choice can be difficult to pin down.) 

We start with the values $t_0$ and $y_0$ from the initial condition, and make a list a $t$-values $t_0,t_1,t_2,t_3,\dots$ given by the rule 
\[ t_n = t_0 + n h.\]
For the corresponding $y$-values, we go from one to the next by the rule
\[ y_{n+1}  = y_n + h f(t_n, y_n).\]

\begin{ex}
Take the IVP 
\[ \begin{cases} y' = x + y^2 \\
y(0)=0\end{cases}.\]
Let's use Euler's method with step size $1$ to approximate a solution.
We start with $x_0 = 0$ and $y_0 = 0$.
Then
\[ x_1 = 1, \quad y_1 = 0 + ( 0 + 0^2) 1 = 0\]
\[ x_2 = 2, \quad y_2 = 0 + ( 1 + 0^2) 1 = 1\dots\]
\[ x_3 = 3, \quad y_3 = 1 + ( 2 + 1^2 ) 1 = 4\]
\[ x_4 = 4, \quad y_4 = 4 + ( 3 + 4^2 )1 = 23\dots\]
Let's also try step size $h=.5$.
\[x_1 = .5 , \quad y_1 = 0+ (0+0^2) .5 = 0\]
\[x_2 = 1, \quad y_2 = 0+ \big(.5 +0^2\big) .5 = .25\]
\[x_3 = 1.5 , \quad y_3 = .25 + \big(1 +(.25)^2\big) .5 = .78125 \]
\[x_4 = 2, \quad y_4 = .78125 + \big(1.5 +(.78125)^2\big) .5 \approx 1.836425 \]

Note that the different step sizes gave different answers for $y(2)$. In general, smaller step sizes give better approximations, but take longer to compute.
\end{ex}

\subsection*{Discussion Questions}
Use Euler's method with step size $h=0.5$ to approximate a solution to 
\[\begin{cases} y' = -ty^2 \\ y(0)=1\end{cases}\]
up to $t=2$.
\begin{framed}
\[ t_0 = 0, \quad y_0=1.\]
\[ t_1 = .5, \quad y_1 = 1 + (- 0 \cdot 1^2) .5 = 1.\]
\[ t_2 = 1, \quad y_2 = 1 + (- .5 \cdot 1^2) .5 = .75\]
\[ t_3 = 1.5 , \quad y_3 = .75 + (- 1 \cdot .75^2) .5 = .46875\]
\[ t_4 = 2 , \quad y_4 = .46875 + (- 1.5 \cdot .46875^2) .5 \approx .30395\]
\end{framed}


\subsection*{Linear models (\S3.1)}

We now want to apply our ability to solve many first-order ODEs arising from real world situations, like the ones we saw in the first couple weeks.

\begin{ex} Newton's law of cooling\index{Newton's law of cooling} says that the rate at which an object cools/heats up is proportional to the difference between its temperature and the temperature of its surroundings.  First, let's state Newton's law of cooling as a general model with a differential equation.

Take $T$ to be the temperature of the heating or cooling object. We are thinking of this as changing in time, so let $t$ denote time, and think of $T$ as a function of $t$. Also, the temperature of the surroundings plays a role, so take $T_0$ to the be ambient temperature. Then the rule is
\[ \frac{dT}{dt} = k (T-T_0)\]
where $k$ is some constant of proportionality.

\Sept{15}

Let's now apply it to a specific situation. Say we place a cake in a $400^{\circ}$F oven. At first, the cake is 
 $70^{\circ}$F and after 10 minutes it is  $100^{\circ}$F. How long will it take for the cake to reach  $150^{\circ}$F?
 
Based on our story, $T_0=400$. We find the general solution of our differential equation
\[ \frac{dT}{dt} = k (T-400).\]
This is separable and linear, so we can solve it two different ways. Let's use an integrating factor.
\[T' - kT = -400 k\]
\[ \mu = e^{\int -k \, dt} = e^{-kt}\]
\[ \rsa e^{-kt} T' - k e^{-kt} T = -400k e^{-kt}\]
\[ \rsa (e^{-kt} T) ' = -400k e^{-kt}\]
\[ \rsa e^{-kt} T = \int -400k e^{-kt} \, dt = -400k \int e^{-kt} \, dt = \frac{-400k}{-k} e^{-kt} +C =400 e^{-kt} +C\]
\[ \rsa T = 400 + C e^{kt}.\]
We now have to find $C$ and $k$ for a particular function of $T$. Plug in $T(0)=70$ to get
\[ 70 = T(0) = 400 + C e^{0} = 400 + C\]
\[\rsa C= 70-400 = -330,\]
so
\[ T= 400 -330 e^{kt}.\]
Then, plug in $T(10)=75$ to get
\[ 100 = 400 - 330 e^{10 k}\]
\[\rsa -300 = -330 e^{10 k}\]
\[ \rsa \frac{10}{11} = e^{10k}\]
\[ \rsa 10k = \ln(\frac{10}{11})\]
\[ \rsa k = \ln(\frac{10}{11})/10\]
so
\[ T = 400 - 330 e^{t (\ln\frac{10}{11}) /10}.\]
Now we can set $T(t) = 150$ and solve
\[ 150 = 400 - 330 e^{t (\ln\frac{10}{11}) /10}\]
\[ \rsa -250 = -330 e^{t (\ln \frac{10}{11}) /10}\]
\[ \rsa e^{t (\ln \frac{10}{11}) /10} = 25/33\]
\[ \rsa t (\ln \frac{10}{11}) /10 = \ln(25/33)\]
\[ \rsa t = 10 \ln(\frac{25}{33}) / \ln(\frac{10}{11}) \approx 29.\]
\end{ex}

\begin{ex} We can also come up with explicit solutions for the mixing models\index{mixing model} of the type we considered earlier. Say that we have a tank of water with 300 gallons of fresh water right now. Water starts flowing out at a rate of 3 gallons per minute, and water with 5 grams of salt per gallon flows in at a rate of 6 gallons per minute. Let's find the amount of salt in the tank as a function of time.

Let $S$ be the amount of salt in the tank in grams and $t$ be time in minutes. First we note that the tank has $300 + 3t$ gallons of water after $t$ minutes. The rate of salt coming in is $5 \times 6 = 30$ grams per minute. The rate of salt going out is $3\times \frac{S}{300 + 3t} = \frac{3}{300 + 3t} S$. The differential equation modeling the situation is
\[ S' = 30 - \frac{3}{300 + 3t} S.\]
We also have the initial condition $S(0)=0$.

Our ODE is linear first-order.
\[ S' +  \frac{3}{300 + 3t} S = 30.\]
The integrating factor is
\[ \mu = e^{\int \frac{3}{300+ 3t} \, dt} = e^{\int du / u} = e^{\ln u} = u = 300+3t\]
with the $u$-sub $u=300+3t$, $du = 3 \, dt$.
\[ (300+3t) S' + 3 S = 30(300+3t)\]
\[ \rsa \big( (300+3t) S \big)' = 30(300+3t)\]
\[\rsa  (300 + 3t) S = \int 9000 + 90t \, dt = 9000 t + 45 t^2 + C\]
\[\rsa S = \frac{9000 t + 45 t^2 + C}{300 + 3t}.\]
Now we plug in the initial condition $S(0)=0$:
\[ 0 = S(0) = \frac{C}{300},\]
so $C=0$. Thus, we have
\[  S = \frac{9000 t + 45 t^2}{300 + 3t}.\]
\end{ex}

\subsection*{Logistic models (\S3.2)}

We explore an important type nonlinear first-order ODEs that commonly show up in mathematical models. One place it arises is in population growth.

\begin{ex} We discussed earlier a model of population growth wherein the rate of growth of a population of proportional to the population itself. This led to the model
\[ \frac{dP}{dt} = k P\]
where $P$ is the population considered as a function of time $t$, and $k$ is some constant of proportionality. The general solution to this is of the form
\[ P(t) = C e^{kt}.\]
This grows larger and larger and larger! A model such as this will not describe the long-term growth effectively if there is some constraint on the size of the population.

Suppose we consider a population, let's say of squirrels\index{squirrels} in the city of Lincoln. There is only so much food to go around so there should be a maximum capacity for the population; let's say that there's food enough for at most $100000$ squirrels; let's call this the \emph{total capacity}\index{total capacity}. Then $100000-P$ is the amount of room for growth in the squirrel population; let's call this the \emph{remaining capacity}\index{remaining capacity}. A \emph{logistic growth model} for the squirrel population supposes that the rate of growth of the population is \emph{jointly proportional}\index{jointly proportional} to the population $P$ and the remaining capacity $100000-P$, meaning it is proportional to the product $P (100000-P)$. That is, the logistic model says
\[ \frac{dP}{dt} = k  P (100000-P).\]
The constant $k$ we take here should be positive.
\end{ex}
%\begin{comment}
%\newpage

\Sept{20}

 \begin{ex}
Let's use our techniques from \S2.1 to analyze this equation without solving it. This is an autonomous equation, so the behavior (increasing vs decreasing vs constant) depends only on the value of $P$ and not on $t$. The right-hand side is positive when $0<P<100000$, negative when $P<0$ or $P>100000$, and constant for $P=0$ or $P=100000$. Thus, the population grows when it is positive and below capacity, decreases when above capacity, and stays constant if zero or at capacity.
\end{ex}

\begin{defn}
A \emph{logistic model}\index{logistic model} is a model that supposes that the rate of growth of some quantity $P$ is jointly proportional to $P$ and $P_c - P$ for some constant $P_c$.

A \emph{logistic equation}\index{logistic equation} is a differential equation of the form
\[ \frac{dP}{dt} = k P (P_{c} - P)\]
for some constants $k$ and $P_c$. The constant $P_c$ is called the \emph{total capacity}\index{total capacity} or \emph{carrying capacity}\index{carrying capacity}.
\end{defn}

Every logistic model can be expressed as a logistic equation.

Let's see another example.

\begin{ex} A simple model for the spread of a rumor throughout a population assumes that the rate at which the rumor spreads is jointly proportional to the number of people informed and the number of people not informed. Suppose the rumor spreads among a population of $4000$ people.
\end{ex}

\subsection*{Discussion Questions:}
\begin{enumerate}
\item Find an ODE modeling the number of people informed $I$ based the information above. (You may have an unknown constant of proportionality $k$.)
\item Based on the story, should your constant $k$ be positive or negative?
\item Based on your model (and not just the story), determine whether $I$ is increasing, decreasing, or constant, based on the number of people who know at the start.
\item Suppose that 10 people know at the start. Without solving the equation, try to sketch a graph of the solution to the IVP (even without knowing $k$!).
\end{enumerate}
\begin{framed}
We should have the equation \[ \frac{dI}{dt} = k I (4000-I).\]
Since this is presumably increasing for values of $I$ between $0$ and $4000$, then $k$ should be positive.
Now, the function $k I (4000-I)$ is zero when $I=0$ or $I=4000$, and is positive when $0<I<4000$, so we have equilibrium solutions for $I=0,4000$ and increasing solutions for $0<I<4000$.
\begin{center}\includegraphics[scale=.5]{sf9}\end{center}
\end{framed}


The general logistic equation is separable, and we can find a general solution to it. Take
\[ \frac{dP}{dt} = k P (P_{c} - P)\]
and separate to get
\[\frac{dP}{P(P_c - P)} = k \, dt.\]
To integrate the left-hand side, we recall the trick of \emph{partial fractions}\index{partial fractions}:
we write
\[ \frac{1}{P(P_c - P)} = \frac{a}{P} + \frac{b}{P_c - P}\] for constants $a,b$ and solve:
\[ 1 = (P_c - P)a + P b = P_c a + P (b-a) \]
\[ \rsa a = 1/P_c, \ b-a = 0 ,\ b=1/P_c, \ \text{so}\]
\begin{align*} \int \frac{dP}{P(P_c - P)} &= \frac{1}{P_c} \int \frac{dP}{P} + \frac{1}{P_c} \int \frac{dP}{P_c - P} \\&= \frac{1}{P_c} \ln|P| -  \frac{1}{P_c} \ln|P_c - P| +C 
\\&= \frac{1}{P_c} (\ln|P| - \ln|P_c - P|) +C = \frac{1}{P_c} \ln \left| \frac{P}{P_c - P} \right| +C.\end{align*}
Then \[\frac{1}{P_c} \ln \left| \frac{P}{P_c - P} \right|  = kt +C\]
\[ \ln \left| \frac{P}{P_c - P} \right| = k P_c t + C\]
\[ \left| \frac{P}{P_c - P} \right| = e^{k P_c t + C} =  e^C e^{k P_c t }\]
\[ \frac{P}{P_c - P}  =   \pm e^C e^{k P_c t } \]
Since $\pm e^C$ is just a constant in any case, let's reuse the name $C$ for that other constant. Then
\[ \frac{P}{P_c - P}  = C e^{k P_c t } \]
for some new constant $C'$.
Rearranging and solving gives
\[ P = (P_c - P) C e^{k P_c t } = P_c C e^{k P_c t }  - P  C e^{k P_c t } \]
\[ \rsa P + P C e^{k P_c t }  = P_c C e^{k P_c t } \]
\[ \rsa P (1 +C e^{k P_c t } ) = P_c C e^{k P_c t } \]
\[ \rsa P = P_c \frac{C e^{k P_c t }}{1+ C e^{k P_c t }}.\]

In particular, a \emph{logistic function}\index{logistic function} can be written in the explicit form
\[ f(t) = a \frac{ b e^{ct}}{1+ b e^{ct}}\]
for some constants $a,b,c$.

In this class, you don't need to know how to solve a logistic equation or this general formula for a logistic function, just how to set one up and analyze it at we did in Sections 2.1 and 2.6.

\subsection*{Higher-order differential equations (\S4.1)}

For higher order differential equations, we will focus especially on linear equations.

\begin{defn} An ODE that can be written in the form
\[ a_n(x) y^{(n)} + a_{n-1}(x) y^{(n-1)} + \cdots + a_1(x) y' + a_0(x) y = g(x)\]
where $y^{(r)} = \frac{d^n y}{dx^r}$ is an \emph{n-th order linear equation}. If $g(x)=0$, we say that the equation is \emph{homogeneous}\index{homogeneous}; otherwise, it is \emph{nonhomogeneous}\index{nonhomogeneous}.
\end{defn}

With a first-order equation, to get a particular solution, we specified an initial condition of one value.
For a higher-order ODE, we typically need more initial conditions (or boundary conditions).

\begin{ex} Consider the differential equation
\[ y''' = 5.\]
To find the general solution, we can just integrate three times:
\[ y'' = \int 5 \, dt = 5t+ c_1\]
\[ y' = \int 5t + c_1 \, dt = \frac{5}{2} t^2 + c_1 t + c_2 \]
\[ y = \int \frac{5}{2} t^2 + c_1 t + c_2 \, dt = \frac{5}{6} t^3 + \frac{c_1}{2}  t^2 + c_2 t + c_3.\]
To get to a particular solution, we need to know more than one value of the function: we need three pieces of information of some sort to determine the three $c$'s.

One natural possibility is to specify the values at three different points. (This is an example of what we will call a \emph{boundary condition}\index{boundary condition} soon.) Another possibility is to specify the values of $y$, of $y'$, and of $y''$ at the same point. (This is what we will call an \emph{initial condition}\index{initial condition} in this setting.)

For example, given the IVP
\[ \begin{cases}
y^{(3)} = 5 \\
y(0)=1\\
y'(0)=-2\\
y''(0)=5\end{cases}\]
we solve
\[ 1 = y(0) = \frac{5}{6} \cdot 0^3 + \frac{c_1}{2}  \cdot0^2 + c_2 \cdot 0 + c_3 = c_3\]
\[ -2 = y'(0) = \frac{5}{2}\cdot  0^2 + c_1 \cdot 0 + c_2 = c_2\]
\[ 5 = y''(0) = 5 \cdot 0+ c_1 = c_1\]
so we get a unique solution
\[ y(t)= \frac{5}{6} t^3 + \frac{5}{2}  t^2 -2  t + 1.\]
\end{ex}

\begin{ex}
Suppose that we know that the solution IVP
\[ \begin{cases}
y^{(3)} + y' = 0 \\
y(\pi) = 0 \\
y'(\pi) = 2 \\
y''(\pi) = -1
\end{cases}\]

is of the form
\[ y(x) = c_1 + c_2 \sin(x) + c_3 \cos(x).\]
Let's find a particular solution using the initial conditions.
\[ 0 = y(\pi) = c_1 + c_2 \sin(\pi) + c_3 \cos(\pi) = c_1 - c_3\]
so $c_1=c_3$.
\[ 2 = y'(\pi) = c_2 \cos(\pi) - c_3 \sin(\pi) = -c_2\]
so $c_2=-2$.
\[ -1 = y''(\pi) = -c_2 \sin(\pi) - c_3 \cos(\pi) = c_3\]
so $c_3=-1$. So, our solution must be
\[ y(x) = -1 - 2 \cos(x) - \sin(x).\]
\end{ex}

\begin{comment}

\Sept{22}

A \emph{boundary value problem}\index{boundary value problem} poses conditions at different points to get a particular solution. For example, a system of equations like
\[\begin{cases} y'' + y = 0 \\ y(a) = c \\ y(b)=d\end{cases}\] is a boundary value problem.
We will be focusing on initial value conditions, like
\[\begin{cases} y'' + y = 0 \\ y(a) = c \\ y'(a)=d\end{cases}\] 
rather than boundary value conditions in this course.

The great news is that for a linear ODE, there exist unique solutions to IVPs in the same sense we discussed for first-order equations with the Picard-Lindel\"of Theorem.

\begin{thm}[Existence and uniqueness theorem for linear ODEs]
Given a linear ODE
\[ a_n(x) y^{(n)} + a_{n-1}(x) y^{(n-1)} + \cdots + a_1(x) y' + a_0(x) y = g(x)\]
where $g(x), a_0(x), \dots, a_n(x)$ are continuous and $a_n(x)\neq 0$ for all $x$, then there exists a unique solution
\[ \begin{cases} 
a_n(x) y^{(n)} + a_{n-1}(x) y^{(n-1)} + \cdots + a_1(x) y' + a_0(x) y = g(x) \\
y(t_0) = y_0\\
y'(t_0) = y_1 \\
 \quad  \vdots\\
y^{(n-1)}(t_0) = y_{n-1}
\end{cases}\]
on some interval containing $t_0$.
\end{thm}

\begin{ex} Consider the ODE
\[ (x-7) y'' + 3y = x^2 \cos(x).\]
Since $x-7=0$ when $x=7$, the theorem doesn't apply yet, so we should divide through by $x-7$:
\[ y'' + \frac{3}{x-7} y = \frac{x^2 \cos(x) }{x-7}.\]
The Theorem then says that when $\frac{3}{x-7}$ and $\frac{x^2 \cos(x) }{x-7}$ are continuous, there is a unique solution near that $x$-value: this is OK as long as $x\neq 7$.
For example, with the initial condition
\[ \begin{cases} y(-1) = 3 \\ y'(-1) = -.7\end{cases} \]
starting from $x=-1$, we know that there exists a unique solution near $x=-1$. Moreover, we can go to the left forever and to the right up until $x=7$ without getting into trouble, so this IVP has a unique solution on $(-\infty , 7)$.
\end{ex}

\subsection*{Principle of superposition}

I want to introduce the Principle of Superposition in an example.

\begin{ex} Consider the linear homogeneous ODE
\[ 3y'' + 2ty' + t^7 y = 0.\]
Suppose we have two solutions $y_1(t), y_2(t)$. Then for any constants $c_1,c_2$, the function
\[ y(t) = c_1 y_1(t) + c_2 y_2(t)\] is also a solution.
Let's check it:
\begin{align*} 3 y'' + 2t y' + t^7 y &= 3 (c_1 y_1 + c_2 y_2)'' + 2t (c_1 y_1 + c_2 y_2)' + t^7 (c_1 y_1 + c_2 y_2) \\ &=3 (c_1 y_1'' + c_2 y_2'') + 2t (c_1 y_1' + c_2 y_2') + t^7 (c_1 y_1 + c_2 y_2)\\
&= c_1 (3y''_1 + 2ty'_1 + t^7 y_1) + c_2 (3y''_2 + 2ty'_2 + t^7 y_2) \\
&= c_1 (  \qquad \quad \  0 \qquad \quad \  )  \,+ \,c_2 (  \qquad \quad \  0 \qquad \quad \  ) = 0,
\end{align*}
where the last equality is because $y_1$ and $y_2$ are solutions; this means that $y$ is a solution!
\end{ex}

For about the same reason, this works for any linear homogeneous ODE: the key points were that we could ``pull out the sum and constants'' form the differential equation, which is a consequence of having a linear equation, and that a sum of constants times zero is zero, which is why we needed a homogeneous equation.  Namely, we have:

\index{Principle of superposition}
\begin{thm}[Principle of superposition for homogeneous ODEs] For any linear homogeneous ODE
\[ a_n(x) y^{(n)} +  \cdots + a_1(x) y' +  a_0(x) y = 0,\]
 given any solutions $y_1,y_2,\dots,y_t$, and any constants $c_1,c_2, \dots,c_t$, the function $y=c_1 y_1 + \cdots + c_t y_t$ is also a solution to the same equation.
\end{thm}

This is only true for linear homogeneous equations, so be sure to only apply it in that setting. We give the recipe that appears above a name.

\begin{defn} If $y_1,y_2,\dots,y_n$ are functions, we say that a function of the form $y=c_1 y_1 + \cdots + c_t y_t$ for some constants $c_1,c_2, \dots,c_t$ is a \emph{linear combination}\index{linear combination} or \emph{superposition}\index{superposition} of the functions $y_1,y_2,\dots,y_t$.\end{defn}

Let's return to our example and see what happens if the equation is nonhomogeneous instead.
\begin{ex} Consider the linear nonhomogeneous ODEs
\[ 3y'' + 2ty' + t^7 y = \sin(x).\]
and
\[ 3y'' + 2ty' + t^7 y = \cos(x).\]
They are linear and have the same left-hand side ($y$ and its derivatives part), but different right-hand sides (doesn't depend on $y$ part).
Suppose we have a solution $y_1(t)$ to the first (sine) ODE, and a solution $y_2(t)$ to the second (cosine) ODE. Let's consider a superposition \[ y(t) = c_1 y_1(t) + c_2 y_2(t)\] 
of our two functions and plug it in to the left-hand side:
\begin{align*} 3 y'' + 2t y' + t^7 y &= 3 (c_1 y_1 + c_2 y_2)'' + 2t (c_1 y_1 + c_2 y_2)' + t^7 (c_1 y_1 + c_2 y_2) \\ &=3 (c_1 y_1'' + c_2 y_2'') + 2t (c_1 y_1' + c_2 y_2') + t^7 (c_1 y_1 + c_2 y_2)\\
&= c_1 (3y''_1 + 2ty'_1 + t^7 y_1) + c_2 (3y''_2 + 2ty'_2 + t^7 y_2) \\
&= c_1 (  \qquad \ \sin(x) \ \qquad   )  \,+ \,c_2 (  \qquad \   \cos(x) \ \qquad   ) \\
&= c_1 \sin(x) + c_2 \cos(x).
\end{align*}
\end{ex}
This means that the superposition $y$ is a solution to a different ODE with the same left-hand side but a new right-hand side:
\[ 3y'' + 2ty' + t^7 y = c_1 \sin(x) + c_2 \cos(x).\]

Again, for about the same reason, this works for any linear ODE.  Namely, we have:

\index{Principle of superposition}
\begin{thm}[Principle of superposition for nonhomogeneous ODEs] 
Given linear ODEs with the same ``left-hand sides'':
\[ a_n(x) y^{(n)} +  \cdots + a_1(x) y' +  a_0(x) y = g_i(x),\]
for $i=1,\dots,t$, solutions $y_1, \dots,y_t$ of the respective equations ($y_i$ satisfies the equation with $g_i$ on the right-hand side), and any constants $c_1,c_2, \dots,c_t$, the function $y=c_1 y_1 + \cdots + c_t y_t$ is also a solution to the equation
\[ a_n(x) y^{(n)} +  \cdots + a_1(x) y' +  a_0(x) y = g(x),\]
for $g = c_1 g_1 + \cdots + c_t g_t$.
\end{thm}

%For example, say that\dots

\subsection*{Discussion Questions}
The functions $y_1=e^x$ and $y_2=e^{2x}$ are solutions to
\[ y'' - 3y' + 2y = 0,\]
 $y_3 = xe^{x}$ is a solution to
\[ y'' - 3y' + 2y = -e^{x},\]
 $y_4 = x e^{2x}$ is a solution to
\[ y'' - 3y' + 2y = e^{2x}.\]
Consider the following functions:
\begin{multicols}{2}
\begin{enumerate}[label=(\alph*)]
\item $y= 12 e^x$
\item $y= e^x - e^{2x}$
\item $y= 12e^x - 15e^{2x}$
\item $y= - xe^{x}$
\item $y= 12e^x - xe^{x}$
\item $y= 12 x e^x + 15 e^{2x}$
\item $y= -12 x e^x + 15 e^{2x}$
\item $y= 15 e^{2x} -12 x e^x + 15 e^{2x}$
\end{enumerate}
\end{multicols}
\begin{enumerate}
\item Which of the functions are solutions to
\[ y'' - 3y' + 2y = 0\ ?\]
\item Which of the functions are solutions to
\[ y'' - 3y' + 2y = e^x\ ?\]
\item Which of the functions are solutions to
\[ y'' - 3y' + 2y = 12 e^x + 15 e^{2x}\ ?\]
\end{enumerate}



\subsection*{Linear dependence and Wronskians}




Let's consider an example.
\begin{ex} Consider the ODE
\[ y'' - y=0\]
(equivalently, $y'' = y$).
Certainly $y_1= e^x$ is a solution, since its derivative is itself.
Can we guess another? $y_2= e^{-x}$ has its negative for its derivative, and then the sign flips again with the second derivative, so this is also a solution.

By the principle of superposition, $7 e^x$ and $-15 e^x + \pi e^{-x}$ are also a solutions. Note that something like $x e^x$ is not a solution: the principle only applies to constant multipliers.

Let's recall a couple more functions:
\[ \sinh(x) = \frac{e^x - e^{-x}}{2} \quad \cosh(x) = \frac{e^x + e^{-x}}{2}\]
\index{$\sinh(x)$}\index{$\cosh(x)$}
are functions that satisfy $\sinh'(x) = \cosh(x)$ and $\cosh'(x) = \sinh(x)$,
so $y_3=\sinh(x)$ and $y_4=\cosh(x)$ are also solutions.

However, $y_3 = \frac12 y_1 - \frac12 y_2$ and $y_4 = \frac 12 y_1 + \frac12 y_2$ are already explained by $y_1$ and $y_2$ using the principle of superposition, so we don't really need $y_3$ or $y_4$ to create the other solutions. That is, using linear combinations, $\{y_1,y_2\}$ can be used to build everything that $\{y_1,y_2,y_3,y_4\}$ can. Note that we can also build everything using $\{y_3,y_4\}$.

The upshot is that $\{y_1,y_2,y_3,y_4\}$ has redundancy for forming linear combinations.
\end{ex}

We want a tool for detecting redundancy like this.

In the last example, the equation
\[ \frac12 y_1 + \frac12 y_2 = y_4\]
can be rewritten as
\[ \frac12 y_1 + \frac12 y_2 + 0 y_3 + (-1) y_4   = 0.\]

\begin{defn} We say that a set of functions $\{y_1,\dots, y_n\}$ is \emph{linearly independent}\index{linearly independent} (i.e., no redundancy) if whenever some linear combination yields the zero function
\[ c_1 y_1 + \cdots + c_n y_n = 0\]
the coefficients $c_1,\dots,c_n$ must be $0$. Otherwise $\{y_1,\dots, y_n\}$ is \emph{linearly dependent}\index{linearly dependent}.
\end{defn}

For example, 
\[ \frac12 e^x + \frac12 e^{-x} + (-1) \cosh(x) = 0\]
means that $\{e^x,e^{-x}, \cosh(x)\}$ is linearly dependent.


\begin{comment}
\end{comment}

\printindex

\end{document}













 