\documentclass{amsart}[12pt]
\usepackage{graphicx}
\usepackage{comment}
\usepackage{amscd,mathabx}
\usepackage{amssymb,setspace}
\usepackage{tikz-cd}
\usepackage{latexsym,amsfonts,amssymb,amsthm,amsmath,amscd,stmaryrd,mathrsfs,xcolor,mathtools}
\usepackage[all, knot]{xy}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\xyoption{all}
\xyoption{arc}
\usepackage{hyperref}


%\usepackage[notcite,notref]{showkeys}
 
%\CompileMatricesx
\newcommand{\edit}[1]{\marginpar{\footnotesize{#1}}}
%\newcommand{\edit}[1]{}
\newcommand{\rperf}[2]{\operatorname{RPerf}(#1 \into #2)}



\newcommand{\vectwo}[2]{\begin{bmatrix} #1 \\ #2 \end{bmatrix}}

\newcommand{\vecfour}[4]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4 \end{bmatrix}}

\newcommand{\Cat}[1]{\left<\left< \text{#1} \right>\right>}


\def\htpy{\simeq_{\mathrm{htpc}}}
\def\tor{\text{ or }}
\def\fg{finitely generated~}

\def\Ass{\operatorname{Ass}}
\def\ann{\operatorname{ann}}
\def\sign{\operatorname{sign}}
\def\htt{\mathrm{height}}

\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\can}{\mathrm{can}}

\def\ob{{\mathfrak{ob}} }
\def\BiAdd{\operatorname{BiAdd}}
\def\BiLin{\operatorname{BiLin}}

\def\Syl{\operatorname{Syl}}
\def\span{\operatorname{span}}

\def\sdp{\rtimes}
\def\cL{\mathcal L}
\def\cR{\mathcal R}



\def\ay{??}
\def\Aut{\operatorname{Aut}}
\def\End{\operatorname{End}}
\def\Mat{\operatorname{Mat}}
\def\Min{\operatorname{Min}}

\def\a{\alpha}



\def\etale{\'etale~}
\def\tW{\tilde{W}}
\def\tH{\tilde{H}}
\def\tC{\tilde{C}}
\def\tS{\tilde{S}}
\def\tX{\tilde{X}}
\def\tZ{\tilde{Z}}
\def\HBM{H^{\text{BM}}}
\def\tHBM{\tilde{H}^{\text{BM}}}
\def\Hc{H_{\text{c}}}
\def\Hs{H_{\text{sing}}}
\def\cHs{{\mathcal H}_{\text{sing}}}
\def\sing{{\text{sing}}}
\def\Hms{H^{\text{sing}}}
\def\Hm{\Hms}
\def\tHms{\tilde{H}^{\text{sing}}}
\def\Grass{\operatorname{Grass}}
\def\image{\operatorname{im}}
\def\im{\image}
\def\ker{\operatorname{ker}}
\def\coker{\operatorname{coker}}
\def\cone{\operatorname{cone}}
\newcommand{\Hom}{\mathrm{Hom}}

\newcommand{\onto}{\twoheadrightarrow}


\def\ku{ku}
\def\bbu{\bf bu}
\def\KR{K{\mathbb R}}

\def\CW{\underline{CW}}
\def\cP{\mathcal P}
\def\cE{\mathcal E}
\def\cL{\mathcal L}
\def\cJ{\mathcal J}
\def\cJmor{\cJ^\mor}
\def\ctJ{\tilde{\mathcal J}}
\def\tPhi{\tilde{\Phi}}
\def\cA{\mathcal A}
\def\cB{\mathcal B}
\def\cC{\mathcal C}
%\def\cZ{\mathcal Z}
\def\cD{\mathcal D}
\def\cF{\mathcal F}
\def\cG{\mathcal G}
\def\cO{\mathcal O}
%\def\cI{\mathcal I}
\def\cS{\mathcal S}
\def\cT{\mathcal T}
\def\cM{\mathcal M}
\def\cN{\mathcal N}
\def\cMpc{{\mathcal M}_{pc}}
\def\cMpctf{{\mathcal M}_{pctf}}
\def\L{\Lambda}

\def\sA{\mathscr A}
\def\sB{\mathscr B}
\def\sC{\mathscr C}
\def\sZ{\mathscr  Z}
\def\sD{\mathscr  D}
\def\sF{\mathscr  F}
\def\sG{\mathscr G}
\def\sO{\mathscr  O}
\def\sI{\mathscr I}
\def\sS{\mathscr S}
\def\sT{\mathscr  T}
\def\sM{\mathscr M}
\def\sN{\mathscr N}

\def\fA{\mathfrak A}

\newcommand{\va}{\underline{a}}
\newcommand{\vx}{\underline{x}}
\newcommand{\vy}{\underline{y}}

%\def\vx{\mathbf{x}}

%\newcommand{\inc}{\subseteq}
\newcommand{\id}{\mathrm{id}}


\newcommand{\Jan}[1]{\textcolor{violet}{Lecture of January #1, 2022}}
\newcommand{\Feb}[1]{\textcolor{violet}{Lecture of February #1, 2022}}
\newcommand{\Mar}[1]{\textcolor{violet}{Lecture of March #1, 2022}}
\newcommand{\Apr}[1]{\textcolor{violet}{Lecture of April #1, 2022}}
\newcommand{\May}[1]{\textcolor{violet}{Lecture of May #1, 2022}}

\def\Ext{\operatorname{Ext}}
 \def\ext{\operatorname{ext}}



\def\ov#1{{\overline{#1}}}

\def\vecthree#1#2#3{\begin{bmatrix} #1 \\ #2 \\ #3 \end{bmatrix}}

\def\tOmega{\tilde{\Omega}}
\def\tDelta{\tilde{\Delta}}
\def\tSigma{\tilde{\Sigma}}
\def\tsigma{\tilde{\sigma}}


\def\d{\delta}
\def\td{\tilde{\delta}}

\def\e{\epsilon}
\def\nsg{\unlhd}
\def\pnsg{\lhd}

\newcommand{\tensor}{\otimes}
\newcommand{\homotopic}{\simeq}
\newcommand{\homeq}{\cong}
\newcommand{\iso}{\approx}

\DeclareMathOperator{\ho}{Ho}
\DeclareMathOperator*{\colim}{colim}


\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\H}{\mathbb{H}}

\newcommand{\bP}{\mathbb{P}}
\newcommand{\bM}{\mathbb{M}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\bH}{{\mathbb{H}}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\bR}{{\mathbb{R}}}
\newcommand{\bL}{{\mathbb{L}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\bK}{\mathbb{K}}


\newcommand{\bD}{\mathbb{D}}
\newcommand{\bS}{\mathbb{S}}

\newcommand{\bN}{\mathbb{N}}


\newcommand{\bG}{\mathbb{G}}

\newcommand{\C}{\mathbb{C}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\NN}{\mathbb{N}}

\newcommand{\M}{\mathcal{M}}
\newcommand{\W}{\mathcal{W}}

\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cV}{\mathcal{V}}



\newcommand{\itilde}{\tilde{\imath}}
\newcommand{\jtilde}{\tilde{\jmath}}
\newcommand{\ihat}{\hat{\imath}}
\newcommand{\jhat}{\hat{\jmath}}

\newcommand{\fc}{{\mathfrak c}}
\newcommand{\fp}{{\mathfrak p}}
\newcommand{\p}{{\mathfrak p}}
\newcommand{\fm}{{\mathfrak m}}
\newcommand{\m}{{\mathfrak m}}
\newcommand{\fn}{{\mathfrak n}}
\newcommand{\q}{{\mathfrak q}}
\newcommand{\fq}{{\mathfrak q}}

\newcommand{\op}{\mathrm{op}}
\newcommand{\dual}{\vee}

\newcommand{\DEF}[1]{\emph{#1}\index{#1}}
\newcommand{\Def}[1]{#1 \index{#1}}


% The following causes equations to be numbered within sections
\numberwithin{equation}{section}


\theoremstyle{plain} %% This is the default, anyway
\newtheorem{thm}[equation]{Theorem}
\newtheorem{theorem}[equation]{Theorem}
\newtheorem{thmdef}[equation]{TheoremDefinition}
\newtheorem{introthm}{Theorem}
\newtheorem{introcor}[introthm]{Corollary}
\newtheorem*{introthm*}{Theorem}
\newtheorem{question}{Question}
\newtheorem{cor}[equation]{Corollary}
\newtheorem{corollary}[equation]{Corollary}
\newtheorem{por}[equation]{Porism}
\newtheorem{lem}[equation]{Lemma}
\newtheorem{lemma}[equation]{Lemma}
\newtheorem{lemminition}[equation]{Lemminition}
\newtheorem{prop}[equation]{Proposition}
\newtheorem{proposition}[equation]{Proposition}

\newtheorem{porism}[equation]{Porism}
\newtheorem{fact}[equation]{Fact}


\newtheorem{conj}[equation]{Conjecture}
\newtheorem{quest}[equation]{Question}

\theoremstyle{definition}
\newtheorem{defn}[equation]{Definition}
\newtheorem{definition}[equation]{Definition}
\newtheorem{chunk}[equation]{}
\newtheorem{ex}[equation]{Example}
\newtheorem{example}[equation]{Example}

\newtheorem{exer}[equation]{Optional Exercise}

\theoremstyle{remark}
\newtheorem{rem}[equation]{Remark}
\newtheorem{remark}[equation]{Remark}

\newtheorem{notation}[equation]{Notation}
\newtheorem{terminology}[equation]{Terminology}



\renewcommand{\sec}[1]{\section{#1}}
\newcommand{\ssec}[1]{\subsection{#1}}
\newcommand{\sssec}[1]{\subsubsection{#1}}

\newcommand{\br}[1]{\lbrace \, #1 \, \rbrace}
\newcommand{\li}{ < \infty}
\newcommand{\quis}{\simeq}
\newcommand{\xra}[1]{\xrightarrow{#1}}
\newcommand{\xla}[1]{\xleftarrow{#1}}
\newcommand{\xlra}[1]{\overset{#1}{\longleftrightarrow}}

\newcommand{\xroa}[1]{\overset{#1}{\twoheadrightarrow}}
\newcommand{\xria}[1]{\overset{#1}{\hookrightarrow}}
\newcommand{\ps}[1]{\mathbb{P}_{#1}^{\text{c}-1}}




\def\and{{ \text{ and } }}
\def\oor{{ \text{ or } }}

\def\Perm{\operatorname{Perm}}
\newcommand{\Ss}{\mathbb{S}}

\def\Op{\operatorname{Op}}
\def\res{\operatorname{res}}
\def\ind{\operatorname{ind}}

\def\sign{{\mathrm{sign}}}
\def\naive{{\mathrm{naive}}}
\def\l{\lambda}


\def\ov#1{\overline{#1}}
\def\cV{{\mathcal V}}
%%%-------------------------------------------------------------------
%%%-------------------------------------------------------------------

\newcommand{\chara}{\operatorname{char}}
\newcommand{\Kos}{\operatorname{Kos}}
\newcommand{\opp}{\operatorname{opp}}
\newcommand{\perf}{\operatorname{perf}}

\newcommand{\Fun}{\operatorname{Fun}}
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\SL}{\operatorname{SL}}
\def\o{\omega}
\def\oo{\overline{\omega}}

\def\cont{\operatorname{cont}}
\def\te{\tilde{e}}
\def\gcd{\operatorname{gcd}}

\def\stab{\operatorname{stab}}

\def\va{\underline{a}}

\def\ua{\underline{a}}
\def\ub{\underline{b}}


\newcommand{\Ob}{\mathrm{Ob}}
\newcommand{\Set}{\mathbf{Set}}
\newcommand{\Grp}{\mathbf{Grp}}
\newcommand{\Ab}{\mathbf{Ab}}
\newcommand{\Sgrp}{\mathbf{Sgrp}}
\newcommand{\Ring}{\mathbf{Ring}}
\newcommand{\Fld}{\mathbf{Fld}}
\newcommand{\cRing}{\mathbf{cRing}}
\newcommand{\Mod}[1]{#1-\mathbf{Mod}}
\newcommand{\Cx}[1]{#1-\mathbf{Comp}}
\newcommand{\vs}[1]{#1-\mathbf{vect}}
\newcommand{\Vs}[1]{#1-\mathbf{Vect}}
\newcommand{\vsp}[1]{#1-\mathbf{vect}^+}
\newcommand{\Top}{\mathbf{Top}}
\newcommand{\Setp}{\mathbf{Set}_*}
\newcommand{\Alg}[1]{#1-\mathbf{Alg}}
\newcommand{\cAlg}[1]{#1-\mathbf{cAlg}}
\newcommand{\PO}{\mathbf{PO}}
\newcommand{\Cont}{\mathrm{Cont}}
\newcommand{\MaT}[1]{\mathbf{Mat}_{#1}}
\newcommand{\Rep}[2]{\mathbf{Rep}_{#1}(#2)}
\newcommand{\Max}{\mathrm{Max}}
\newcommand{\Spec}{\mathrm{Spec}}
\newcommand{\Supp}{\mathrm{Supp}}

%%%-------------------------------------------------------------------
%%%-------------------------------------------------------------------
%%%-------------------------------------------------------------------
%%%-------------------------------------------------------------------
%%%-------------------------------------------------------------------

\makeindex
\title{Math 902 Lecture Notes, Spring 2022}


\begin{document}
\onehalfspacing

\maketitle

\tableofcontents

\Jan{19}

In this class, all rings are assumed to be commutative, with associative multiplication and containing 1.

\sec{Finiteness conditions}

\ssec{Finitely generated algebras}

We start by recalling a definition from last semester, specialized to the setting of commutative rings.

\begin{defn} [Algebra]
Given a ring $A$, an $A$-\DEF{algebra} is a ring $R$ equipped with a ring homomorphism $\phi:A\to R$. This defines an $A$-module structure on $R$ given by restriction of scalars, that is, for $a\in A$ and $r\in R$, $ar:=\phi(a)r$ that is compatible with the internal multiplication of $R$ i.e.,
\[
a(rs)=(ar)s=r(as) \text{ for all } a\in A, rs\in R. 
\]
We will call $\phi$ the \DEF{structure homomorphism} of the $A$-algebra $R$.
\end{defn}



\begin{ex}
\begin{itemize} \item If $A$ is a ring and $x_1,\dots,x_n$ are indeterminates, the inclusion map $A \hookrightarrow A[x_1,\dots,x_n]$ makes the polynomial ring into an $A$-algebra.
\item When $A\subseteq R$ the inclusion map makes $R$ an $A$-algebra. In this case the $A$-module multiplication $ar$ coincides with the internal (ring) multiplication on $R$.
\item Any ring comes with a unique structure as a $\Z$-algebra.
\end{itemize}
\end{ex}

The collection of $A$-algebras forms a category where the morphisms are ring homomorphisms $f:R\to S$ such that  the following diagram commutes
\[
\xymatrix{
 & A  \ar[dl]_{\phi} \ar[dr]^{\psi} & \\
R \ar[rr]_{f} && S
}
\]
for structural homomorphisms $\varphi:A\to R$ and $\psi:A\to S$.

\begin{defn}[Algebra generation]
Let $R$ be an $A$-algebra and let $\Lambda \subseteq R$ be a set. The $A$-\DEF{algebra generated by} a subset $\Lambda$ of $R$, denoted \Def{$A[\Lambda]$}, is the smallest (w.r.t containment) subring of $R$ containing $\Lambda$ and $\varphi(A)$.

A set of elements $\Lambda \subseteq R$ \DEF{generates} $R$ as an $A$-algebra if $R=A[\Lambda]$.
\end{defn}

Note that there are two different meanings for the notation $A[S]$ for a ring $A$ and set $S$: one calls for a polynomial ring, and the other calls for a subring of something.


This can be unpackaged more concretely in a number of equivalent ways:

\begin{lem}
\label{lem:algebragen}
The following are equivalent
\begin{enumerate}
	\item\label{fgalg-1} $\Lambda$ generates $R$ as an $A$-algebra.
	\item\label{fgalg-3} Every element in $R$ admits a polynomial expression in $\Lambda$ with coefficients in $\phi(A)$, i.e.
	\[
	R=\left\{\sum_{\mathrm{finite}} \phi(a) \lambda_1^{i_1} \cdots \lambda_n^{i_n} \mid a\in A, \lambda_j\in\Lambda, i_j\in \N\right\}.
\]
	\item\label{fgalg-4} The $A$-algebra homomorphism $\psi:A[X]\rightarrow R$, where $A[X]$ is a polynomial ring on a set of indeterminates $X$ in bijection with $\Lambda$ and $\psi(x_i)=\lambda_i$, is surjective.
\end{enumerate}
\end{lem}
\begin{proof} Let $S= \left\{\sum_{\mathrm{finite}} \phi(a) \lambda_1^{i_1} \cdots \lambda_n^{i_n} \mid a\in A, \lambda_j\in\Lambda, i_j\in \N\right\}$.
For the equivalence between (2) and (3) we note that $S$ is the image of $\psi$.
In particular, $S$ is a subring of $R$. It then follows from the definition that (1) implies (2). Conversely, any subring of $R$ containing $\phi(A)$ and $\Lambda$ certainly must contain $S$, so (2) implies~(1).
\end{proof}

\begin{ex} We may have also seen these brackets used in $\Z[\sqrt{d}]$ for some $d\in \Z$ to describe the ring 
\[ \{ a + b \sqrt{d} \ | \ a,b\in \Z\}.\]
In fact, this is a special instance of generating: the $\Z$-algebra generated by $\sqrt{d}$ in the most natural place, the algebraic closure of $\Q$, is exactly the set above. The point is that for any power $(\sqrt{2})^n$, write $n=2q+r$ with $r\in \{0,1\}$, so $(\sqrt{2})^n=2^d (\sqrt{2})^r$. Similarly, the ring $\Z[\sqrt[3]{d}]$ can be written as 
\[ \{ a + b \sqrt[3]{d} + c \sqrt[3]{d^2}  \ | \ a,b,c\in \Z\}.\]
\end{ex}


Note that the homomorphism $\psi$ in part (3) need not be injective.
\begin{itemize}
\item If the homomorphism $\psi$ is injective (so an isomorphism) we say that $A$ is a {\em free} algebra.
\item the set $\ker(\psi)$ measures how far $R$ is from being a free $A$-algebra and is called the set of {\em relations} on $\Lambda$.
\end{itemize}

\begin{defn}[Algebra-finite]
We say that $\varphi:A\to R$ is \DEF{algebra-finite}, or $R$ is a \DEF{finitely generated $A$-algebra}, if there exists a {finite} set of elements $f_1,\ldots, f_d$ that generates $R$ as an $A$-algebra. We write $R=A[f_1,\dots,f_d]$\index{$A[f_1,\dots,f_d]$} to denote this.

The term \DEF{finite-type} is also used to mean this.% A better name might be \emph{finitely generatable}, since to say that an algebra is finitely generated does not require knowing any actual finite set of generators.
\end{defn}

\begin{rem} Note that, by the lemma on generating sets, an $A$-algebra is finitely generated if and only if it is isomorphic to a quotient of a polynomial ring over $A$ in finitely many variables. The choice of an isomorphism with a quotient of a polynomial ring is equivalent to a choice of generating set.
\end{rem}

\Jan{21}



\begin{ex} Let $K$ be a field, and $B=K[x,xy,xy^2,xy^3,\dots] \subseteq C=K[x,y]$, where $x$ and $y$ are indeterminates. Let $A$ be a finitely generated subalgebra of $B$, and write $A=K[f_1,\dots,f_d]$.  Since each $f_i$ is a (finite) polynomial expression in the monomials $\{x y^i \ | \ i\in \N\}$, it involves only finitely many of these monomials. Thus, there is an $m$ such that $\{f_1,\dots,f_d\} \subset K[x,xy,\dots,xy^m]$, and hence $A \subseteq K[x,xy,\dots,xy^m]$. But, every element of $K[x,xy,\dots,xy^m]$ is a $K$-linear combination of monomials with the property that the $y$ exponent is no more than $m$ times the $x$ exponent, so this ring does not contain $xy^{m+1}$. Thus, $B$ is not a finitely generated $K$-algebra.
\end{ex}

\begin{exer} Let $A \xra{\phi} B \xra{\psi} C$ be ring homomorphisms (so $B$ is an $A$-algebra via $\phi$, $C$ is a $B$-algebra via $\psi$, and $C$ is an $A$-algebra via $\psi \circ \phi$). Then
\begin{itemize}
\item If $A\xra{\phi} B$ and $B\xra{\psi}C$ are algebra-finite, then $A\xra{\psi\phi} C$ is algebra-finite. (Take the union of the generating sets.)
\item If $A\xra{\psi\phi} C$ is algebra-finite, then $B \xra{\psi} C$  is algebra-finite. (Use the same generating set.)
\item If $A\xra{\psi\phi} C$ is algebra-finite, then $A\xra{\phi} B$ may \emph{not} be algebra-finite. (Use the previous example.) \end{itemize}

\end{exer}

\begin{rem}
Any surjective $\varphi$ is algebra-finite: the target is generated by $1$. Since any homomorphism $\phi:A\to R$ can be factored as $\phi=\psi\circ \varphi$ where $\varphi$ is the surjection $\varphi:A\to A/\ker (\varphi)$ and $\psi$ is the inclusion $\psi:A/\ker (\varphi) \hookrightarrow R$, to understand algebra-finiteness, it suffices to restrict our attention to injective homomorphisms by the last bullet point of the previous exercise.
\end{rem}


There are many basic questions about algebra generators that are surprisingly difficult. Let $R=\C[x_1,\dots,x_n]$ and $f_1,\dots,f_n\in R$. When do $f_1,\dots,f_n$ generate $R$ over $\C$? It is not too hard to show that the Jacobian determinant\index{Jacobian}
\[ \det \begin{bmatrix} \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\ \vdots & \ddots & \vdots \\
\frac{\partial f_n}{\partial x_1} & \cdots & \frac{\partial f_n}{\partial x_n} \end{bmatrix}\]
must be a nonzero constant. It is a big open question whether this is in fact a sufficient condition!




\ssec{Finitely generated modules}

We will also find it quite useful to consider a stronger finiteness property for maps. 

%Recall that if $\varphi:A\to R$ is a ring homomorphism, then $R$ acquires an $A$-module structure via $\varphi$ by $a \cdot r = \varphi(a)r$; this is a particular case of \emph{restriction of scalars}\index{restriction of scalars}. We may write ${}_{\varphi}R$ \index{${}_{\varphi}R$} for this $A$-module if we think we will have trouble remembering the map. Of course, if $\varphi$ is injective and we identify it with the inclusion $A\subseteq R$, then this $A$-action is just $a \cdot r = ar$.

\begin{defn}(Module generation)
Let $M$ be an $A$-module and let $\Gamma \subseteq M$ be a set. The $A$-\index{module generated by a set}{\em submodule} of $M$ {\em generated by} $\Gamma$, denoted $\sum_{\gamma \in \Gamma} A \gamma$\index{$\sum_{\gamma \in \Gamma} A \gamma$}, is the smallest (w.r.t containment) submodule of $M$ containing $\Gamma$.

A set of elements $\Gamma \subseteq M$ \index{generates as a module}\emph{generates} $M$ as an $A$-module if the submodule of $M$ generated by $\Gamma$ is $M$ itself, i.e. $M=\sum_{\gamma \in \Gamma} A \gamma$.
\end{defn}


This also has some equivalent realizations:

\begin{lem}
\label{lem:modulegen}
The following are equivalent:
\begin{enumerate}
	\item $\Gamma$ generates $M$ as an $A$-module.
	\item Every element of $M$ admits a linear combination expression in the elements of $\Gamma$ with coefficients in~$A$.
	\item The homomorphism $\theta:A^{\oplus Y} \to M$, where $A^{\oplus Y}$ is a free $A$-module with basis  $Y$ in bijection with $\Gamma$ via $\theta(y_i)=\gamma_i$, is surjective.
\end{enumerate}
\end{lem}

\begin{exer} Prove the previous lemma.
\end{exer}

\begin{defn}[Module-finite]
We say that a ring homomorphism $\varphi:A\to R$ is \emph{module-finite}\index{module-finite} if $R$ is a finitely-generated $A$-module, that is, there is a {\em finite} set $r_1,\ldots, r_n \in R$ so that $R=\sum_{i=1}^n  A r_i$. 
\end{defn}


As with algebra-finiteness, surjective maps are always module-finite in a trivial way. 
The notion of module-finite is much stronger than algebra-finite, since a linear combination is a very special type of polynomial expression. To be specific:

\begin{lem}[Module-finite $\Rightarrow$ algebra-finite]
\label{lem:MFimpliesAF}
If $\varphi:A\to R$ is module-finite then it is algebra-finite.
\end{lem}

The converse is not true.

\begin{ex}
	\begin{enumerate}
		\item If $K\subseteq L$ are fields, $L$ is module-finite over $K$ just means that $L$ is a finite field extension of $K$.
		\item The Gaussian integers\index{Gaussian integers} $\Z[i]$ satisfy the well-known property (or definition, depending on your source) that any element $z\in\Z[i]$ admits a unique expression $z=a+bi$ with $a,b\in \Z$. That is, $\Z[i]$ is generated as a $\Z$-module by $\{1,i\}$; moreover, they form a free module basis!
		\item If $R$ is a ring and $x$ an indeterminate, $R\subseteq R[x]$ is not module-finite. Indeed, $R[x]$ is a free $R$-module on the basis $\{1,x,x^2,x^3,\dots\}$. It is however algebra-finite.
		\item Another map that is \emph{not} module-finite is the inclusion of $K[x] \subseteq K[x,1/x]$. Note that any element of $K[x,1/x]$ can be written in the form $f(x)/x^n$ for some $f(x)\in K[x]$ and $n\in \N$. Then, any finitely generated $K[x]$-submodule $M$ of $K[x,1/x]$ is of the form $M=\sum_i \frac{f_i(x)}{x^{n_i}} \cdot K[x]$; taking $N=\max\{n_i \ | \ i\}$, we find that $M\subseteq 1/x^N \cdot K[x] \neq K[x,1/x]$.
	\end{enumerate}
\end{ex}

\begin{exer} Let $A \xra{\phi} B \xra{\psi} C$ be ring homomorphisms. Then
\begin{itemize}
\item If $A\xra{\phi} B$ and $B\xra{\psi}C$ are module-finite, then $A\xra{\psi\phi} C$ is module-finite.
\item If $A\xra{\psi\phi} C$ is module-finite, then $B \xra{\psi} C$  is module-finite.
\end{itemize}
\end{exer}

We will see that $A\xra{\psi\phi} C$ is module-finite does not imply $A\xra{\phi} B$ is module-finite soon.

\ssec{Integral extensions}

In field theory, there is a close relationship between (vector space-)finite field extensions and algebraic equations. The situation for rings is similar.

\begin{definition}[Integral element/extension] Let $\phi: A \to R$ be a ring homomorphism (for which we will denote $\phi(a)$ by $a$) and $r\in R$. 
The element $r$ is \emph{integral}\index{integral element} if there are elements $a_0,\dots,a_{n-1}\in A$ such that
	\[ r^n + a_{n-1} r^{n-1} + \cdots + a_1 r + a_0 = 0;\]
	i.e., $r$ satisfies a \emph{equation of integral dependence} over $A$.\index{equation of integral dependence} The homomorphism $\phi$ is \emph{integral} if every element of $R$ is integral over $A$.
\end{definition}



\begin{ex} Let  $A= \Z[\sqrt{2}]= \{ a +b \sqrt{2} \ | \ a,b\in \Z\}$. The element $t=\sqrt{2} \in A$ is integral over $\Z$, since $t^2-2=0$. Likewise, $s=1+\sqrt{2}$ is integral over $\Z$, as $s^2=3+2\sqrt{2}$, so $s^2-2s-1=0$. 

On the other hand, $\frac{1}{2} \in \Q$ is not integral over $\Z$: if
\[ \left(\frac{1}{2}\right)^n + a_{n-1} \left(\frac{1}{2}\right)^{n-1} + \cdots + a_0 =0\]
with $a_i\in \Z$, multiply through by $2^n$ to get $1+ 2 a_{n-1} + 2^2 a_{n-2} + \cdots + 2^n a_0=0$, which is impossible.
\end{ex}




\Jan{24}

\begin{proposition}
\label{fg-by-intl-modfin}
	Let $A\subseteq R$ be rings. 
	\begin{enumerate}
		\item If $r\in R$ is integral over $A$ then $A[r]$ is module-finite over $A$.
		\item If $r_1,\dots,r_t \in R$ are integral over $A$ then $A[r_1,\dots,r_t]$ is module-finite over $A$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}
		\item Suppose $r$ is integral over $A$, satisfying the equation $ r^n + a_{n-1} r^{n-1} + \cdots + a_1 r + a_0 = 0$. Then $A[r] = \sum_{i=0}^{n-1} A r^i$. Indeed, $s\in A[r]$ with a polynomial expression $s=p(r)=\sum c_j r^j$ of degree $m \geq n$, we can use the equation above to rewrite the leading term $a^m r^m$ as $-a_m r^{m-n}(a_{n-1} r^{n-1} + \cdots + a_1 r + a_0)$, and decrease the degree in $r$.
		\item 	Write $A_0:=A \subseteq A_1:=A[r_1] \subseteq A_2:=A[r_1,r_2] \subseteq \cdots \subseteq A_t:=A[r_1,\dots,r_t]$. Note that $r_i$ is integral over $A_{i-1}$: use the same monic equation of $r_i$ over $A$. Then, the inclusion $A \subseteq A[r_1,\dots,r_t]$ is a composition of module-finite maps, hence is module-finite.\qedhere
	\end{enumerate}	
\end{proof}

We recall that the \DEF{classical adjoint} of an $n\times n$ matrix $A$ is the $n \times n$ matrix whose $(i,j)$-entry is $(-1)^{i+j}$ times the determimant of the matrix obtained from $A$ by removing the $i$th column and the $j$th row.

\begin{lemma}[Determinantal trick]\label{determinantal trick}\index{determinantal trick}
Let $R$ be a ring, $B \in M_{n\times n}(R)$, $v\in R^{\oplus n}$, and $r\in R$.
	\begin{enumerate}
		\item $\mathrm{adj}(B) B = \det(B) I_{n\times n}$.
		\item If $B v = r v$, then $\det(r I_{n\times n} - B) v=0$.
	\end{enumerate} 
\end{lemma}



\begin{proof}
	\begin{enumerate}
		\item When $R$ is a field, this is a basic linear algebra fact. We deduce the case of a general ring from the field case.
		
		The ring $R$ is a $\ZZ$-algebra, so we can write $R$ as a quotient of some polynomial ring $\ZZ[X]$. Let $\xymatrix@C=6mm{\psi:\ZZ[X] \ar@{->>}[r] & R}$ be a surjection, $a_{ij}\in \ZZ[X]$ be such that $\psi(a_{ij})=b_{ij}$, and let $A=[a_{ij}]$. Note that
		\[\psi(\mathrm{adj}(A)_{ij})=\mathrm{adj}(B)_{ij} \quad \textrm{ and } \quad \psi((\mathrm{adj}(A) A)_{ij}) = (\mathrm{adj}(B) B)_{ij},\] 
		since $\psi$ is a homomorphism, and the entries are the same polynomial functions of the entries of the matrices $A$ and $B$, respectively. Thus, it suffices to establish 
		\[\mathrm{adj}(B) B = \det(B) I_{n\times n}\]
		in the case when $R=\ZZ[X]$, and we can do this entry by entry. Now, $R=\ZZ[X]$ is an integral domain, hence a subring of a field (its fraction field). Since both sides of the equation 
		\[\left( \mathrm{adj}(B) B \right)_{ij} = \left( \det(B) I_{n\times n}\right)_{ij}\]
		live in $R$ and are equal in the fraction field (by linear algebra) they are equal in $R$. This holds for all $i, j$, and thus 1) holds.
		
		\item We have $(r I_{n\times n} - B) v=0$, so by part 1)
	\[
\det(r I_{n\times n} - B) v=\mathrm{adj}(r I_{n\times n} - B) (r I_{n\times n} - B) v = 0.\qedhere\]
	\end{enumerate}
\end{proof}



\begin{theorem}
	Let $A\subseteq R$ be module-finite. Then $R$ is integral over $A$.
\end{theorem}
\begin{proof} Given $r\in R$, we want to show that $r$ is integral over $A$. The idea is to show that multiplication by $r$, realized as a linear transformation over $A$, satisfies the characteristic polynomial of that linear transformation.
	
	Write $R = A r_1 + \cdots + A r_t$. We may assume that $r_1=1$, perhaps by adding module generators. By assumption, we can find $a_{ij}\in A$ such that \[ r r_i = \sum_{j=1}^t a_{ij} r_j \] for each $i$. Let $C=[a_{ij}]$, and $v$ be the column vector $(r_1,\dots,r_t)$. We have $r  v = C v$, so by the determinant trick, $\det(r I_{n\times n} - C)v=0$. Since we chose one of the entries of $v$ to be $1$, we have in particular that $\det(r I_{n\times n} - C)=0$. Expanding this determinant as a polynomial in $r$, this is a monic equation with coefficients in $A$.
\end{proof}

Collecting the previous results, we now have a useful characterization of module-finite extensions:

\begin{corollary}[Characterization of module-finite extensions]\label{characterization of mod-fin alg-fin integral}
	Let $A\subseteq R$ be rings. $R$ is module-finite over $A$ if and only if $R$ is integral and algebra-finite over $A$.
\end{corollary}
\begin{proof}
	($\Rightarrow$): A generating set for $R$ as an $A$-module serves as a generating set as an $A$-algebra. The remainder of this direction comes from the previous theorem.
	($\Leftarrow$): If $R=A[r_1,\dots,r_t]$ is integral over $A$, so that each $r_i$ is integral over $A$, then $R$ is module-finite over $A$ by Proposition~\ref{fg-by-intl-modfin}.
\end{proof}


\begin{corollary}
	If $R$ is generated over $A$ by integral elements, then $R$ is integral. Thus, if $A\subseteq S$, the set of elements of $S$ that are integral over $A$ form a subring of $S$.
\end{corollary}
\begin{proof}
	Let $R=A[\Lambda]$, with $\lambda$ integral over $A$ for all $\lambda\in\Lambda$. Given $r\in R$, there is a finite subset $L\subseteq \Lambda$ such that $r\in A[L]$. By the theorem, $A[L]$ is module-finite over $A$, and $r\in A[L]$ is integral over $A$.
	
	For the latter statement, the first statement implies that
	\[ \{\text{integral elements}\} \subseteq A[\{\text{integral elements}\}] \subseteq \{\text{integral elements}\}, \] so equality holds throughout, and $\{\text{integral elements}\}$ is a ring.
\end{proof}


\begin{ex}
	\begin{enumerate}
			\item Not all integral extensions are module-finite. Let $K=\overline{K}$, and consider the ring \[R=K[x,x^{1/2},x^{1/3},x^{1/4},x^{1/5},\dots]\subseteq \overline{K(x)}.\] Clearly $R$ is generated by integral elements over $K[x]$, hence integral, but is not algebra-finite over $K[x]$.

		\item Let $x,y,z$ be indeterminates. Set $R=\C[x,y]$ to be a polynomial ring, and $S=\C[x,y,z]/(x^2+y^2+z^2)$ to be a quotient of a polynomial ring. We claim that we can realize $R$ as a subring of $S$; i.e., the $\C$-algebra homomorphism from $R$ to $S$ that sends $x$ to $x$ and $y$ to $y$ is injective. Indeed, the kernel is the set of polynomials in $x,y$ that are multiples of $z^2+x^2+y^2$, but, thinking of $\C[x,y,z]$ as $R[z]$, any nonzero multiple of $z^2+x^2+y^2$ must have $z$-degree at least $2$, so none only involve $x,y$. Thus, we have an inclusion $R\subseteq S$.	
				
		The ring $S$ is module-finite over $R$: indeed, $S$ is generated over $R$ as an algebra by one element $z$ that is integral over $R$.

%		\item Let $R=\C[u,v] \subseteq S=\C[u,v,w]/(u^2+vw)$; this is injective by a similar argument to the previous example. Note that this $S$ is isomorphic to the previous $S$ by the map $u\mapsto x, v\mapsto y+iz, w\mapsto y-iz$.
%		
%		 We claim that $S$ is \emph{not} integral and hence \emph{not} module-finite over $R$. Indeed, the minimal polynomial of $w$ over the fraction field of $R$ is $f(t)=vt+u^2$. Any equation that $w$ satisfies is a $\C(u,v)[t]$-multiple of this: write $g(t)=f(t)h(t)$ with $g(t)\in\C(u,v)[t]$ monic. By Gauss' lemma, there is some $a\in \C(u,v)$ such that $a^{-1} f(t), a h(t)\in \C[u,v][t]$. Since the leading coefficient of $h$ is $v^{-1}$, the numerator of $a$ must be a multiple of $v$ when written in lowest terms. But this contradicts that $a^{-1} f(t)\in \C[u,v][t]$.
	\end{enumerate}
\end{ex}



\Jan{26}


\begin{definition}
	If $A\subseteq R$, the \emph{integral closure of $A$ in $R$}\index{integral closure} is the set of elements of $R$ that are integral over~$A$. If $R$ is a domain, the \emph{integral closure} of $R$ is its integral closure in its fraction field.
\end{definition}


\begin{ex}
$\Z$ is integrally closed in $\Q$: this follows from essentially the same argument we used to show that $\frac{1}{2}$ is not integral over $\Q$.
\end{ex}

\begin{exer}
The integral closure of $\ZZ$ in $\Q(\sqrt{d})$ is
$
\begin{cases}
\ZZ[\sqrt{d}] & \text{ if } d\not\equiv 1 \pmod 4\\
\ZZ[\frac{1+\sqrt{d}}{2}] & \text{ if } d\equiv 1 \pmod 4.
\end{cases}
$

\end{exer}

\begin{exer} Let $A \xra{\phi} B \xra{\psi} C$ be ring homomorphisms. Then $A \xra{\phi} B$ and $B \xra{\psi} C$ are integral if and only if $A \xra{\psi\phi} C$ is integral.
\end{exer}

Here is a useful fact about integral extensions that we will use multiple times; it also gives a flavor for the power of the integrality condition on a map.

\begin{prop} Let $R$ and $S$ be domains and $R\subseteq S$ be integral. Then $R$ is a field if and only if $S$ is a field.
\end{prop}
\begin{proof}
($\Rightarrow$) Say $R=K$ is a field and let $s\in S$ be nonzero. The ring $K[s]$ is integral over $K$ and algebra-finite, hence module finite; i.e., a finite dimensional vector space. Then multiplication by $s$ on $K[s]$ is  an injective $K$-linear map, since $K[s]\subseteq S$ is a domain, and hence surjective. This means that $s$ has an inverse, and hence $S$ is a field.

($\Leftarrow$) Say $S=L$ is a field and let $r\in R$. Then $r^{-1}\in L$ and is hence integral over $R$. Take an integral equation
\[ (r^{-1})^n + a_1 (r^{-1})^{n-1} + \cdots + a_n =0\]
with $a_i\in R$, and multiply through by $r^{n-1}$ to get
\[ r^{-1} + a_1 + a_2 r + \cdots + a_n r^{n-1} = 0,\]
so $r^{-1}\in R$.
\end{proof}

\ssec{Commutative Noetherian rings and modules}

We recall that a ring $R$ is \DEF{Noetherian} if the following equivalent conditions hold:

\begin{enumerate}
\item The set of ideals of $R$ has ACC (every ascending chain has a maximal element)
\item Every nonempty collection of ideals  of $R$ has a maximal element (i.e., an ideal not contained in any other; not necessarily a maximal ideal though)
\item Every ideal of $R$ is finitely generated.
\end{enumerate}

Similarly, a module $M$ is  \DEF{Noetherian} if the following equivalent conditions hold:

\begin{enumerate}
\item The set of submodules of $M$ has ACC (every ascending chain has a maximal element)
\item Every nonempty collection of sumbodules of $M$ has a maximal element 
\item Every submodule of $M$ is finitely generated.
\end{enumerate}

When $R$ is Noetherian, a module is finitely generated if and only if it is Noetherian, and hence every submodule of a finitely generated module is finitely generated.

\begin{ex}
	\begin{enumerate}
		\item If $K$ is a field, the only ideals in $K$ are $(0)$ and $(1)=K$, so $K$ is a Noetherian ring.
		\item $\mathbb{Z}$ is a Noetherian ring. More generally, if $R$ is a PID, then $R$ is Noetherian. Indeed, every ideal is finitely generated!
		\item As a special case of the previous example, consider the ring of germs of complex analytic functions near $0$, \index{$\C\{z\}$} 
		\[\C\{z\} := \{ f(z) \in \C\llbracket z \rrbracket  \ | \ f \text{ is analytic on a neighborhood of $z=0$}\}.\]
		 This ring is a PID: every ideal is of the form $(z^n)$, since any $f\in \C\{z\}$ can be written as $z^n g(z)$ for some $g(z)\neq 0$, and any such $g(z)$ is a unit in $\C\{z\}$.
		\item A ring that is \emph{not} Noetherian is a polynomial ring in infinitely many variables over a field $k$, $R = k[x_1, x_2, \ldots]$: the ascending chain of ideals 
		\[(x_1)\subseteq (x_1,x_2) \subseteq (x_1,x_2,x_3) \subseteq \cdots\]
		does \emph{not} stabilize.
		\item The ring $R=K[x,x^{1/2},x^{1/3},x^{1/4},x^{1/5},\dots]$ is also \emph{not} Noetherian. A nice ascending chain of ideals is
		\[ (x) \subsetneqq (x^{1/2}) \subsetneqq (x^{1/3})\subsetneqq (x^{1/4}) \subsetneqq \cdots.\]
%		\item A variation on the last example: the ring of \emph{nonnegatively valued Puiseux series}\index{Puiseux series}: $R=\bigcup_{n\in \NN} \CC\llbracket z^{1/n} \rrbracket \subseteq \overline{\CC((z))}$.\footnote{In fact, the algebraic closure of the field of Laurent series $\CC((z))$ is $\bigcup_{n\in \NN} \CC(( z^{1/n} )) = R[1/t]$.}
		\item The ring of continuous real-valued functions $\mathcal{C}(\R,\R)$\index{$\mathcal{C}(\R,\R)$} is \emph{not} Noetherian: the chain of ideals 
		\[I_{n}=\{ f(x) \ | \ f|_{[-1/n,1/n]}\equiv 0 \}\]
		is increasing and proper. The same construction shows that the ring of infinitely differentiable real functions $\mathcal{C}^{\infty}(\R,\R)$\index{$\mathcal{C}^{\infty}(\R,\R)$} is not Noetherian: properness of the chain follows from, e.g., Urysohn's lemma (though it's not too hard to find functions distinguishing the ideals in the chain). Note that if we asked for analytic functions instead of infinitely-differentiable functions, every element of the chain would be the zero ideal!
	\end{enumerate}
\end{ex}

\begin{rem} If $R$ is Noetherian and $I\subseteq R$, then $R/I$ is Noetherian as well, since there is an order-preserving bijection
\[ \{ \text{ideals of } R \text{ that contain } I \} \leftrightarrow \{\text{ideals of }R/I\}. \]
\end{rem}

\begin{defn}
If $R$ is a commutative ring and $x$ is an indeterminate the set 
\[R\llbracket x \rrbracket=\left\{\sum_{i\geq 0} r_i x^i \mid r_i\in R\right\}\]
with the obvious addition and multiplication
is called the {\em power series ring} in the variable $x$ with coefficients in $R$. If $x_1,\ldots, x_d$ are distinct indeterminates the \DEF{power series ring} in all of these variables is defined inductively as 
\[R\llbracket x_1,\ldots,x_n \rrbracket=\left(R\llbracket x_1,\ldots,x_{d-1}\rrbracket \right)\llbracket x_d\rrbracket.\]
\end{defn}






We will now give a huge family of Noetherian rings.



\begin{theorem}[Hilbert's Basis Theorem]
	Let $R$ be a Noetherian ring. Then the rings $R[x_1,\dots,x_d]$ and $R\llbracket x_1,\dots,x_d\rrbracket$ are Noetherian.
\end{theorem}

\begin{proof}
	We give the proof for polynomial rings, and indicate the difference in the power series argument. By induction on $d$, we can reduce to the case $d=1$. Given $I\subseteq R[x]$, let 
	\[ J = \{ a \in R \ \mid  \ \textrm{there is some } a x^n + \text{lower order terms (wrt }x) \in I\}.\]
	So $J \subseteq R$ consists of all the leading coefficients of polynomials in $I$. We can check (exercise) that this is an ideal of $R$. By our hypothesis, $J$ is finitely generated, so let $J = (a_1,\dots,a_t)$. Pick $f_1,\dots,f_t\in R[x]$ such that the leading coefficient of $f_i$ is $a_i$, and set $N=\displaystyle\max_i \{\deg{f_i} \}$.
	
	Given any $f\in I$ of degree greater than $N$, we can cancel off the leading term of $f$ by subtracting a suitable combination of the $f_i$, so any $f \in I$ can be written as $f = g+h$ where $h\in (f_1, \ldots, f_t)$ and $g \in I$ has degree at most $N$, so $g \in I \cap (R + Rx + \cdots + R x^N)$. Note that since $I \cap (R + Rx + \cdots + R x^N)$ is a submodule of the finitely generated free $R$-module $R + Rx + \cdots + R x^N$, it is also finitely generated as an $R$-module. Given such a generating set, say $I \cap (R + Rx + \cdots + Rx^N) = (f_{t+1}, \ldots, f_s)$, we can write any such $f \in I$ as an $R[x]$-linear combination of these generators and the $f_i$'s. Therefore, $I = (f_1, \ldots, f_t, f_{t+1}, \ldots, f_s)$ is finitely generated, and $R[x]$ is a Noetherian ring.
	
	In the power series case, take $J$ to be the coefficients of \emph{lowest degree} terms.
\end{proof}

\begin{cor} If $R$ is Noetherian, then any finitely generated $R$-algebra is Noetherian as well.
\end{cor}
\begin{proof} A finitely generated $R$-algebra is a quotient ring of a polynomial ring in finitely many variables over~$R$.
\end{proof}

Note that the converse to this is false, e.g., a power series ring over a field is Noetherian, but is not a finitely generated algebra.




\Jan{28}

We now give a subtle connection between the finiteness conditions discussed. 


\begin{theorem}[Artin-Tate Lemma]
	Let $A\subseteq B \subseteq C$ be rings. Assume that
	\begin{itemize}
		\item $A$ is Noetherian,
		\item $C$ is module-finite over $B$, and
		\item $C$ is algebra-finite over $A$.
	\end{itemize}
	Then, $B$ is algebra-finite over $A$.
\end{theorem}

\begin{proof}
	Let $C=A[f_1,\dots,f_r]$ and $C=B g_1 + \cdots + B g_s$. Then, 
	\[f_i = \sum_j b_{ij} g_j \quad \text{and} \quad g_i g_j = \sum_k b_{ijk} g_k\]
	for some $b_{ij}, b_{ijk}\in B$. Let $B_0 = A[\{b_{ij}, b_{ijk}\}] \subseteq B$. Since $A$ is Noetherian, so is $B_0$.
	
	We claim that $C=B_0 \, g_1 + \cdots + B_0 g_s$. Given an element $c\in C$, write $c$ as a polynomial expression in $f_1, \ldots, f_r$, and since the $f_i$ are linear combinations of the $g_i$, we can rewrite $c\in A[\{b_{ij}\}][g_1,\dots,g_s]$. Then using the equations for $g_i g_j$ we can write $c$ in the form required.
	
	Now, since $B_0$ is Noetherian, $C$ is a finitely generated $B_0$-module, and $B\subseteq C$, then $B$ is a finitely generated $B_0$-module, too. In particular, $B_0 \subseteq B$ is algebra-finite. We conclude that $A  \subseteq B$ is algebra-finite, as required.
\end{proof}



\ssec{Application: Finite generation of rings of invariants}

Historically, commutative algebra has roots in classical questions of algebraic and geometric flavors, including the following natural question:

\begin{question}
	Given a (finite) set of symmetries, consider the collection of polynomial functions that are fixed by all of those symmetries. Can we describe all the fixed polynomials in terms of finitely many of them?
\end{question}


To make this precise, let $G$ be a group acting on a ring $R$, or just as well, a group of automorphisms of $R$. The main case we have in mind is when $R=K[x_1,\dots,x_d]$ is a polynomial ring and $K$ is a field. We are interested in the set of elements that are \emph{invariant}\index{invariant}\index{$R^G$} under the action,
\[ R^G : = \{ r \in R \ | \ g(r) = r \ \text{for all} \ g\in G\}. \]
Note that $R^G$ is a subring of $R$. Indeed, given $r,s\in R^G$, then
\[r-s=g \cdot r-g \cdot s =g \cdot (r-s) \quad \text{and}\quad r s = (g \cdot r) (g\cdot s) = g \cdot (rs) \qquad \text{for all} \ g\in G,\]
since each $g$ is a homomorphism. Note also that if $G=\langle g_1,\dots,g_t\rangle$, then $r\in R^G$ if and only if $g_i(r)=r$ for $i=1,\dots,t$. The question above can now be rephrased as follows:

\begin{question}
	Given a finite group $G$ acting on $R=K[x_1,\dots,x_d]$, is $R^G$ a finitely generated $K$-algebra?
\end{question}

Observe that, in this setting, $R^G$ is a $K$-subalgebra of $R$, which is a finitely generated $K$-algebra, but this does not guarantee a priori that $R^G$ is a finitely generated $K$-algebra.

\begin{example}[Negative variables]\label{rootofunityinvariants}
	Let $G=\{e,g\}$ act on $R=K[x]$ by negating the variable: $g \cdot x = -x$ for all $i$, so $g \cdot f(x) = f(-x)$. Suppose that the characteristic of $K$ is not 2, so $-1\neq 1$. 
	Write $f= a_n x^n + a_{n-1} x^{n-1} + \cdots + a_0$.  We have $g \cdot x^i=(-x)^i = (-1)^i x^i$, so
	\[ g\cdot f = (-1)^n a_n x^n+ (-1)^{n-1} a_{n-1} x^{n-1} +  \cdots  + a_0, \]
	which differs from $f$ unless for each odd $i$, $a_i=0$. That is,
	\[ R^G = \{ f \in R \ | \ \text{every term of $f$ has even degree}\}.\]
	Any such $f$ is a polynomial in $x^2$, so we have
	\[ R^G = K[x^2].\]
		 \end{example}
		 
		 
		 \begin{exer} Generalize the last example as follows: let $K$ be a filed with a primitive $d$th root of unity $\zeta$, and let $G= \langle g \rangle \cong C_d$ act on $K[x_1,\dots,x_n]$ via $g\cdot x_i = \zeta x_i$ for all $i$. Then
		 \[ R^G = \{ f \in R \ | \ \text{every term of $f$ has degree a multiple of $d$}\} = K[\{ \text{monomials of degree d}\}].\]
		 \end{exer}		 
		

\begin{ex}[Standard representation of the symmetric group]
\label{ex:symmetric}
	Let $S_n$\index{$S_n$} be the symmetric group on $n$ letters acting on $R=K[x_1,\dots,x_n]$ via $\sigma(x_i)=x_{\sigma(i)}$.
	
	For example, if $n=3$, then $f=x_1^2+x_2^2+x_3^2$ is invariant, while $g=x_1^2+x_1x_2+x_2^2+x_3^2$ is not, since swapping 1 with 3 gives a different polynomial.
	
	You may recall the Fundamental Theorem of Symmetric Polynomials says that every element of $R^{S_n}$ can be written as polynomial expression in the elementary symmetric polynomials 	
		\begin{eqnarray*}
	e_1 =&x_1+\dots +x_n\\
	e_2 =&\sum x_i x_j\\
	\vdots \\
	e_n =&x_1x_2\cdots x_n.
	\end{eqnarray*}
	E.g, $f$ above is $e_1^2-2 e_2$. (Moreover, any symmetric polynomial can be written like so in a \emph{unique} way, so $R^{S_n}$ is a free $K$-algebra.) So even though we have infinitely many invariant polynomials, we can understand them in terms of only finitely many of them, which are {\em fundamental} invariants.
\end{ex}

%\begin{example}[Roots of unity]\label{rootofunityinvariants}
%	Let $G=\{e,g\}$ act on $R=K[x_1,\dots,x_d]$ by negating the variables: $g \cdot x_i = -x_i$ for all $i$, so $g \cdot f(\underline{x}) = f(-\underline{x})$. Suppose that the characteristic of $K$ is not 2, so $-1\neq 1$. Given a general $f$, we can write it as a sum of its \emph{homogeneous} pieces: that is,
%	\[ f = f_r + f_{r-1} +  \cdots + f_1 + f_0, \]
%	where each $f_i$ is a sum of monomials of degree $i$. We have $g(f_i)=(-1)^i f_i$, so
%	\[ g(f) = (-1)^r f_r + (-1)^{r-1}f_{r-1} +  \cdots - f_1 + f_0, \]
%	which differs from $f$ unless every homogeneous piece of $f$ has even degree. That is,
%	\[ R^G = \{ f \in R \ | \ \text{every term of $f$ has even degree}\}.\]
%	Any polynomial of even degree can be written as a $K$-linear combination of products of monomials of degree two. This means that $R^G=K[\{x_i x_j \ | \ 1 \leq i \leq j \leq d\}] \subseteq K[x_1,\dots,x_n]$.
%	
%	This computation readily generalizes to the case of a field $K$ that contains $t$-th roots of unity, and a cyclic group $G=\langle g \rangle$ of order $t$ acting on $R$ by the rule $g(x_i)=\zeta_t \cdot x_i$ for all $i$. In this case, we have
%	\[ R^G = \{ f \in R \ | \ \text{every term of $f$ has degree a multiple of $t$}\} = K[ \{x_{i_1} \cdots x_{i_t} \ | \ 1 \leq i_1 \leq  \cdots \leq i_t \leq d\}].\]
%	This ring is called the \emph{$t$-th Veronese ring}\index{Veronese ring}. \end{example}





\begin{proposition}
Let $K$ be a field, $R$ be a finitely-generated $K$-algebra, and $G$ a finite group of automorphisms of $R$ that fix $K$. Then $R^G \subseteq R$ is module-finite.
\end{proposition}

\begin{proof} 
Since integral implies module-finite, we will show that $R$ is algebra-finite and integral over $R^G$.

First, since $R$ is generated by a finite set as a $K$-algebra, and $K\subseteq R^G$, it is generated by the same finite set as an $R^G$-algebra as well. Extend the action of $G$ on $R$ to $R[t]$ with $G$ fixing $t$. Now, for $r\in R$, consider the polynomial $F_r(t)=\prod_{g\in G} (t-g(r)) \in R[t]$. Then $G$ fixes $F_r(t)$, since for each $h \in G$,
\[h(F_r(t)) = h \prod_{g\in G} (t-g \cdot r)) = \prod_{g\in G} (h \cdot t-hg \cdot r) = F_r(t)\]
Thus, $F_r(t)\in (R[t])^{G}$. Notice that $(R[t])^G = R^G[t]$, since 
\[ g \cdot (a_nt^n + \cdots + a_0) = a_n t^n + \cdots + a_0 \implies (g \cdot a_n)t^n + \cdots + (g \cdot a_0) = a_n t^n + \cdots + a_0.\]

Therefore, $F_r(t) \in R^G[t]$. The leading term (with respect to $t$) of $F_r(t)$ is $t^{|G|}$, so $F_r(t)$ is monic, and $r$ is integral over $R^G$. Therefore, $R$ is integral over $R^G$.
\end{proof}

\begin{theorem}[Noether's finiteness theorem for invariants of finite groups]
Let $K$ be a field, $R$ be a polynomial ring over $K$, and $G$ be a finite group acting $K$-linearly on $R$. Then $R^G$ is a finitely generated $K$-algebra.
\end{theorem}

\begin{proof}
Observe that $K \subseteq R^G \subseteq R$, that $K$ is Noetherian, $K\subseteq R$ is algebra-finite, and $R^G\subseteq R$ is module-finite. Thus, by the Artin-Tate Lemma, we are done!
\end{proof}

\Jan{31}

\section{Graded rings} 

\ssec{Basics of graded rings}

When we think of a polynomial ring $R$, we often think of $R$ with its graded structure, in terms of degrees of elements. Other rings we have seen also have a graded structure, and this structure is actually very powerful.


\begin{definition}
An \emph{$\N$-graded ring}\index{graded ring} is a ring $R$ equipped with a direct sum decomposition as additive groups
		\[R=\bigoplus_{a \geqslant 0} R_a,\]
	such that $R_a R_b \subseteq R_{a+b}$ for every $a,b \in \mathbb{N}$, meaning that for any $r\in R_a$ and $s\in R_b$, we have $rs\in R_{a+b}$. 
	
	We say $R$ is a \DEF{positively graded $A$-algebra} if $R$ is $\N$-graded with $R_0=A$.
	
	More generally, for a semigroup $T$, a {\em $T$-graded}\index{$T$-graded} ring is a ring $R$ with a direct sum decomposition of $R$ as an additive group indexed by $T$:
	\[R=\bigoplus_{a\in T} R_a\]
	satisfying $R_a R_b \subseteq R_{a+b}$. We will assume for convenience that any grading semigroup is cancellative.

	An element that lies in one of the summands $R_a$ is said to be {\em homogeneous}\index{homogeneous element} of {\em degree}\index{degree of a homogeneous element} $a$; we write $|r|$\index{$\mid r \mid$} or $\deg(r)$\index{$\deg(r)$} to denote the degree of a homogeneous element $r$.
\end{definition}


By definition, an element in a graded ring is uniquely a sum of homogeneous elements, which we call its {\em homogeneous components}\index{homogeneous components} \index{graded components} or {\em graded components}; we may write \Def{$[f]_d$} for the $d$th homogeneous component of $f$.  One nice thing about graded rings is that many properties can usually be sufficiently checked on homogeneous elements, and these are often easier to deal with.

\begin{lem} Let $R$ be a $T$-graded ring. 
\begin{enumerate}
\item $1$ is homogeneous of degree $0\in T$ (the identity of $T$).
\item $R_0$ is a subring of $R$.
\item Each $R_a$ is a $R_0$-module.
\end{enumerate}
\end{lem}
\begin{proof}
\begin{enumerate}
\item Write $1=\sum_a r_a$ with $r_a$ homogeneous of degree $a$. Then $r_0 = r_0 (\sum_a r_a) = \sum_a r_0 r_a$ implies $r_0 r_a = 0$ for $a\neq 0$. Similarly, taking the $R_a$ component of $r_a = r_a (\sum_b r_b)$ yields $r_a = r_a r_0$ (here is where we use the cancellative assumption). Thus $r_a =0$ for $a\neq 0$, so $1\in R_0$.
\item $R_0$ is a subgroup under addition, and $r,s\in R_0$ implies $rs\in R_0$. We also just showed $1\in R_0$.
\item $R_a$ is a subgroup under addition, and $r\in R_0$, $s\in R_a$ implies $rs\in R_a$.
\end{enumerate}
\end{proof}

\begin{remark}
Note that whenever $R$ is a graded ring, the multiplicative identity $1$ must be a homogeneous element whose degree is the identity in $T$. In particular, if $R$ is $\NN$ or $\ZZ$-graded, then $1 \in R_0$ and $R_0$ is a subring of $R$.
\end{remark}


\begin{example} Let $K$ be a field, and  $R=K[x_1,\dots,x_n]$ be a polynomial ring.
	\begin{enumerate}
	
	%	\item Any ring $R$ is trivially an $\NN$-graded ring, by setting $R_0 = R$ and $R_n = 0$ for $n \neq 0$.
		
		\item There is an $\NN$-grading on $R$ called the \DEF{standard grading} where 
		\[ R_d = K \cdot \{ x_1^{\alpha_1}\cdots x_n^{\alpha_n} \ | \ \sum_i \alpha_i =d\}.\]
		 Of course, this is the notion of degree familiar from grade school. So $x_1^2+x_2x_3$ is homogeneous in the standard grading, while $x_1^2+x_2$ is not.
		
		\item We can give different $\NN$-gradings on $R$ by fixing some tuple $(\beta_1,\dots,\beta_n)\in \NN^n$ and letting $x_i$ be a homogeneous element of degree $\beta_i$; we call this a grading with \emph{weights}\index{weights} $(\beta_1,\dots,\beta_n)$. Concretely,
		\[ R_d = K \cdot \{ x_1^{\alpha_1}\cdots x_n^{\alpha_n} \ | \ \sum_i \beta_i \alpha_i =d\}.\]

		
		For example, in $K[x_1,x_2]$, $x_1^2+x_2^3$ is not homogeneous in the standard grading, but it is homogeneous of degree $6$ under the $\mathbb{N}$-grading with weights $(3,2)$.
	
		\item A polynomial ring $R = K[x_1, \ldots, x_n]$ also admits a natural $\NN^n$-grading, with 
		\[ R_{(d_1,\dots,d_n)}= {K \cdot x_1^{d_1}\cdots x_n^{d_n}}.\]
		 This is called the \emph{fine grading}\index{fine grading}.
			
	%		\item Let $\Gamma \subseteq \mathbb{N}^n$ be a subsemigroup of $\mathbb{N}^n$. Then 
	%		\[\bigoplus_{\gamma \in \Gamma} K \cdot \vx ^ {\gamma} \subseteq K[\vx] = K[x_1, \ldots, x_n]\]
	%		is an $\mathbb{N}^n$-graded subring of $K[x_1,\dots,x_n]$. Conversely, every $\NN^n$-graded subring of $K[x_1,\dots,x_n]$ is of this form.
				\end{enumerate}	
\end{example}

%\begin{remark}
%	You may have seen the term \emph{homogeneous polynomial} used to refer to a polynomial $f(x_1, \ldots, x_n) \in K[x_1, \ldots, x_n]$ that satisfies 
%	\[f(\lambda x_1, \ldots, \lambda x_n) = \lambda^d f(x_1, \ldots, x_n)\]
%	for some $d$. This is equivalent to saying that all the terms in $f$ have the same total degree, or that $f$ is homogeneous with respect to the standard grading.
%	
%	Similarly, a polynomial is \emph{quasi-homogeneous}, \index{quasi-homogeneous polynomial} or \emph{weighted homogeneous}, if there exist integers $w_1, \ldots, w_n$ such that the sum $w = a_1 w_1 + \cdots + a_n w_n$ is the same for all monomials $x_1^{a_1} \cdots x_n^{a_n}$ appearing in $f$. So $f$ satisfies
%	\[f(\lambda^{w_1} x_1, \ldots, \lambda^{w_n} x_n) = \lambda^{w} f(x_1, \ldots, x_n),\]
%	and $f(x_1^{w_1}, \ldots, x_n^{w_n})$ is homogeneous (in the previous sense, so with respect to the standard grading). 
%	This condition is equivalent to asking that $f$ be homogeneous with respect to some weighted grading on $K[x_1, \ldots, x_n]$.
%\end{remark}



\begin{definition}
	An ideal $I$ in a graded ring $R$ is called \emph{homogeneous}\index{homogeneous ideal} if it can be generated by homogeneous elements.
\end{definition}


\begin{lem} Let $I$ be an ideal in a graded ring $R$.
The following are equivalent:
	
	\begin{enumerate}
	\item $I$ is homogeneous.
	\item  For any element $f\in R$ we have $f\in I$ if and only if every homogeneous component of $f$ lies in $I$. 
	\item $I = \bigoplus_{a \in T} I_a$, where $I_a = I \cap R_a$.
	\end{enumerate}
	\end{lem}
	\begin{proof}
	(1) $\Rightarrow$ (2):  If $I$ is homogeneous and $f\in I$, write $f$ as a combination of the (homogeneous) generators of $I$, say $f_1, \ldots, f_n$:
\[f = r_1 f_1 + \cdots + r_n f_n.\]
Write each $r_i$ as a sum of its components, say $r_i = [r_i]_{d_{i,1}} + \cdots + [r_i]_{d_{i,m_i}} $. Then, after substituting and collecting, 
\[ f= \sum_{d} ( [r_1]_{d-|f_1|} f_1 + \cdots +   [r_n]_{d-|f_n|} f_n)\]
expresses $f$ as a sum of homogeneous elements of different degrees, so 
\[ f_d =  [r_1]_{d-|f_1|} f_1 + \cdots +   [r_n]_{d-|f_n|} f_n \in I.\]

(2) $\Rightarrow$ (1): Any element of $I$ is a sum of its homogeneous components. Thus, in this case, the set of homogeneous elements in $I$ is a generating set for $I$.

(2) $\Rightarrow$ (3): As above, $I$ is generated by the collection of additive subgroups $\{I_a\}$ in this case; the sum is direct as there is no nontrivial $\Z$-linear combination of elements of different degrees.

(3) $\Rightarrow$ (2): Clear.
\end{proof}
	


\begin{example}
Given an $\NN$-graded ring $R$, then $R_+=\bigoplus_{d>0} R_d$ is a homogeneous ideal.
\end{example}


We now observe the following:

\begin{lemma}
	Let $R$ be an $T$-graded ring, and $I$ be a homogeneous ideal. Then $R/I$ has a natural $T$-graded structure induced by the $T$-graded structure on $R$.
\end{lemma}

\begin{proof}
	The ideal $I$ decomposes as the direct sum of its graded components, so we can write
	\[R/I = \frac{\oplus R_a}{\oplus I_a} \cong \oplus \frac{R_a}{I_a}. \qedhere\]
\end{proof}



\begin{example}
	\begin{enumerate}
		
		\item The ideal $I = (w^2x+wyz+z^3,x^2+3xy+5xz+7yz+11z^2)$ in $R=K[w,x,y,z]$ is homogeneous with respect to the standard grading on $R$, and thus the ring $R/I$ admits an $\NN$-grading with $|w|=|x|=|y|=|z|=1$.
		
		\item In contrast, the ring $R=k[x,y,z]/(x^2+y^3+z^5)$ does not admit a grading with $|x|=|y|=|z|=1$, but does admit a grading with $|x|=15,|y|=10,|z|=6$.
	\end{enumerate}
\end{example}

\begin{definition}
Let $R$ be a $T$-graded ring. A graded $R$-module\index{graded module} is an $R$-module with a direct sum decomposition as additive groups indexed by $T$:
	\[M=\bigoplus_{a\in T} M_a \textrm{ such that } R_a M_b \subseteq M_{a+b}\] for all $a,b\in T$.
	\end{definition}
	
	The notions of homogeneous element of a module and degree of a homogeneous element of a module take the obvious meanings. A notable abuse of notation: we will often talk about $\ZZ$-graded modules over $\NN$-graded rings, and likewise.
	
	We can also talk about graded homomorphisms.
	
\begin{definition}
Let $R$ and $S$ be $T$-graded rings with the same grading monoid $T$. A ring homomorphism $\phi:R\to S$ is {\em graded} or {\em degree-preserving}\index{graded ring homomorphism} \index{degree preserving homomorphism} if $\phi(R_a) \subseteq S_{a}$ for all $a \in T$.
\end{definition}

Note that our definition of ring homomorphism requires $1_R \mapsto 1_S$, and thus it does not make sense to talk about graded ring homomorphisms that shift degrees. But we can have graded module homomorphisms of any degree.

\begin{definition}	
Let $M$ and $N$ be $\ZZ$-graded modules over the $\NN$-graded ring $R$. A homomorphism of $R$-modules $\varphi:R\to S$ is {\em graded} \index{graded homomorphism} if $\varphi(M_a) \subseteq N_{a+d}$ for all $a \in \ZZ$ and some fixed $d \in \mathbb{Z}$, called the {\em degree}\index{degree of a graded module homomorphism} of $\varphi$. A graded homomorphism of degree $0$ is also called {\em degree-preserving}\index{degree preserving homomorphism}.
\end{definition}


\begin{example}\label{example shift}
%\begin{enumerate}
%\item Consider the ring map $K[x,y,z]\to K[s,t]$ given by $x\mapsto s^2, y\mapsto st, z\mapsto t^2$. If $K[s,t]$ has the fine grading, meaning $|s|=(1,0)$ and $|t|=(0,1)$, then the given map is degree preserving if and only if $k[x,y,z]$ is graded by 
%\[|x|=(2,0), |y|=(1,1), |z|=(0,2).\]

%\item 

Let $K$ be a field, and let $R=K[x_1,\dots,x_n]$ be a polynomial ring with the standard grading. Given $c\in K=R_0$, the homomorphism of $R$-modules $R\to R$ given by $f\mapsto cf$ is degree preserving. However, if instead we take $g\in K=R_d$ for some $d>0$, then the map 
\[\xymatrix@R=1mm{R \ar[r] & R \\
f \ar@{|->}[r] & gf}\]
is not degree preserving, although it is a graded map of degree $d$. We can make this a degree-preserving map if we shift the grading on $R$ by defining $R(-d)$ \index{$R(d)$}to be the $R$-module $R$ but with the $\ZZ$-grading given by $R(-d)_t=R_{t-d}$. With this grading, the component of degree $d$ of $R(-d)$ is $R(-d)_d=R_0=K$. Now the map 
\[\xymatrix@R=1mm{R(-d) \ar[r] & R \\
f \ar@{|->}[r] & gf}\]
is degree preserving.
%\end{enumerate}
\end{example}

\Feb{2}


We observed earlier an important relationship between algebra-finiteness and Noetherianity that followed from the Hilbert basis theorem: if $R$ is Noetherian, then any algebra-finite extension of $R$ is also Noetherian. There isn't a converse to this in general: there are lots of algebras over fields $K$ that are Noetherian but not algebra-finite over $K$. However, for graded rings, this converse relation holds.



\begin{proposition}
	Let $R$ be an $\NN$-graded ring, and consider homogeneous elements $f_1,\dots,f_n \in R$ of positive degree. Then $f_1,\dots,f_n$ generate the ideal $R_+ := \bigoplus_{d>0} R_d$ if and only if $f_1,\dots,f_n$ generate $R$ as an $R_0$-algebra.
	
	Therefore, an $\NN$-graded ring $R$ is Noetherian if and only if $R_0$ is Noetherian and $R$ is algebra-finite over~$R_0$.
\end{proposition}
\begin{proof}
	If $R=R_0[f_1,\dots,f_n]$, then any element $r\in R_+$ can be written as a polynomial expression $r=P(f_1,\dots,f_n)$ for some $P\in R_0[\underline{x}]$ with no constant term. Each monomial of $P$ is a multiple of some $x_i$, and thus $r\in (f_1,\dots,f_n)$.
	
	To show that $R_+= (f_1,\dots,f_n)$ implies $R=R_0[f_1,\dots,f_n]$, it suffices to show that any homogeneous element $r\in R$ can be written as a polynomial expression in the $f$'s with coefficients in $R_0$. We induce on the degree of $r$, with degree 0 as a trivial base case. For $r$ homogeneous of positive degree, we must have $r\in R_+$, so by assumption we can write $r= a_1 f_1 + \dots + a_n f_n$; moreover, since $r$ and $f_1, \ldots, f_n$ are all homogeneous, we can choose each coefficient $a_i$ to be homogeneous of degree $|r|-|f_i|$. By the induction hypothesis, each $a_i$ is a polynomial expression in the $f$'s, so we are done.
	
	For the final statement, if $R_0$ is Noetherian and $R$ algebra-finite over $R_0$, then $R$ is Noetherian by the Hilbert Basis Theorem. If $R$ is Noetherian, then $R_0 \cong R/R_+$ is Noetherian. Moreover, $R$ is algebra-finite over $R_0$ since $R_+$ is generated as an ideal by finitely many homogeneous elements by Noetherianity, so  by the first statement, we get a finite algebra generating set for $R$ over $R_0$.
\end{proof}



%There are many interesting examples of $\NN$-graded algebras with $R_0 = K$; in that case, $R_+$ is the largest homogeneous ideal in $R$. In fact, $R_0$ is the only maximal ideal of $R$ that is also homogeneous, so we can call it \emph{the} {\bf homogeneous maximal ideal}; it is sometimes also called the {\bf irrelevant maximal ideal} of $R$. This ideal plays a very important role --- in many ways, $R$ and $R_+$ behave similarly to a local ring $R$ and its unique maximal ideal. We will discuss this further when we learn about local rings.





\ssec{Application: Finite generation rings of invariants}

If $R$ is a graded ring, and $G$ is a group acting on $R$ by degree-preserving automorphisms, then $R^G$ is a graded subring of $R$, meaning $R^G$ is graded with respect to the same grading monoid.

Using this perspective, we can now give a different proof of the finite generation of invariant rings that works under different hypotheses. The proof we will discuss now is essentially Hilbert's proof. To do that, we need another notion that is very useful in commutative algebra.

\begin{definition} 
Let $S$ be an $R$-algebra corresponding to the ring homomorphism $\phi:R \to S$. We say that $R$ is a {\em direct summand}\index{direct summand} of $S$ if the map $\phi$ admits a left inverse as a map of $R$-modules.
\end{definition}

Since the condition forces $\phi$ to be injective, we can assume it is an inclusion map (after renaming elements). Note that given any $R$-linear map $\pi: S \to R$, if $\pi(1)=1$ then $\pi$ is a splitting: indeed, $\pi(R)=\pi(r \cdot 1) = r \pi(1)=r$ for all $r \in R$.


Being a direct summand is really nice, since many good properties of $S$ pass onto its direct summands.

\begin{defn} Let $\phi:R\to S$ be a ring homomorphism.
\begin{itemize}
\item Given an ideal $J$ in $S$, the preimage of $J$ under $\phi$ is the \DEF{contraction} of $J$, denoted \Def{$\phi^{-1}(J)$} or \Def{$J \cap R$}, even if $\phi$ is not an inclusion map.
\item Given an ideal $I$ in $R$, the \DEF{expansion} of $I$ in $S$ is the ideal of $S$ generated by $\phi(I)$; we naturally denote this by \Def{$IS$}.
\end{itemize}
\end{defn}


\begin{lemma}\label{direct summand ideals contract}
Let $R$ be a direct summand of $S$. Then, for any ideal $I \subseteq R$, we have $IS \cap R=I$.
\end{lemma}

\begin{proof}
	Let $\pi$ be the corresponding splitting. Clearly, $I \subseteq IS \cap R$. Conversely, if $r \in IS \cap R$, we can write $r = s_1 f_1 + \cdots + s_t f_t$ for some $f_i \in I$, $s_i \in S$. Applying $\pi$, we have
	\[r = \pi(r) = \pi \left( \sum_{i=1}^t s_i f_i \right) = \sum_{i=1}^t \pi\left( s_i f_i \right) = \sum_{i=1}^t \pi \left( s_i \right) f_i \in I.\qedhere\]
\end{proof}

\begin{proposition}\label{direct summand noetherian}
	Let $R$ be a direct summand of $S$. If $S$ is Noetherian, then so is $R$.
\end{proposition}

\begin{proof}
	Let 
	\[I_1\subseteq I_2 \subseteq I_3 \subseteq \cdots\] 
	be a chain of ideals in $R$. The chain of ideals in $S$
	\[I_1 S \subseteq I_2 S \subseteq I_3 S \subseteq \cdots\] 
	stabilizes, so there exist $J$, $N$ such that $I_n R = J$ for $n \geqslant N$. Contracting to $R$, we get that $I_n = I_n S \cap R = J \cap R$ for $n\geqslant N$, so the original chain also stabilizes.
\end{proof}


\begin{proposition}
Let $K$ be a field, and $R$ be a polynomial ring over $K$. Let $G$ be a finite group acting by degree preserving $K$-algebra automorphisms on $R$. Assume that the characteristic of $K$ does not divide~$|G|$. Then $R^G$ is a direct summand of~$R$.
\end{proposition}

\begin{proof}
	We consider the map $\rho: R \to R^G$ given by 
	\[\rho(r)=\frac{1}{|G|} \sum_{g\in G} g\cdot r.\] 
	First, note that the image of this map lies in $R^G$, since acting by $g$ just permutes the elements in the sum, so the sum itself remains the same. We claim that this map $\rho$ is a splitting for the inclusion $R^G \subseteq R$. To see that, let $s\in R^G$ and $r\in R$. We have 
	\[
	\rho(sr)=\frac{1}{|G|} \sum_{g\in G} g\cdot (sr) =\frac{1}{|G|} \sum_{g\in G} (g\cdot s)(g\cdot r) =\frac{1}{|G|} \sum_{g\in G} s(g\cdot r) = s \frac{1}{|G|} \sum_{g\in G} (g\cdot r) = s \rho(r),\]
	so $\rho$ is $R^G$-linear, and for $s\in R^G$, 
	\[\rho(s)=\frac{1}{|G|} \sum_{g\in G} g\cdot s=s. \qedhere\]
\end{proof}


\begin{theorem}[Hilbert's finiteness theorem for invariants]
Let $K$ be a field, and $R$ be a polynomial ring over $K$. Let $G$ be a group acting by degree preserving $K$-algebra automorphisms on $R$. Assume that $G$ is finite and  $|G|$ does not divide the characteristic of $K$, or more generally, that $R^G$ is a direct summand of $R$. Then $R^G$ is a finitely generated $K$-algebra.
\end{theorem}

\begin{proof}
	Since $G$ acts by degree preserving $K$-algebra automorphisms, $R^G$ is an $\NN$-graded subring of $R$ with $R_0=K$. Since $R^G$ is a direct summand of $R$, $R^G$ is Noetherian by Proposition \ref{direct summand noetherian}. By our characterization of Noetherian graded rings, $R^G$ is finitely generated over $R_0=K$.
\end{proof}

\begin{rem}
 One important thing about this proof is that it applies to many infinite groups. In particular, for any \emph{linearly reductive group}\index{linearly reductive group}, including $\mathrm{GL}_n(\CC)$, $\mathrm{SL}_n(\CC)$, and $(\CC^{\times})^n$, we can construct a splitting map $\rho$.
\end{rem}

\Feb{4}

\sec{Affine varieties}



\ssec{Definition and examples of affine varieties}

Our next goal is to study solution sets of polynomial equations. Such solutions sets have a fancy name.

\begin{defn} Let $K$ be a field. We define \DEF{affine $n$-space} over $K$, denoted \Def{$\A^n_K$}, to be the set of $n$-tuples over $K$:
\[ \A^n_K = \{ (a_1,\dots,a_n) \ | \ a_i\in K\}.\]
\end{defn}

Observe that any $f\in K[x_1,\dots,x_n]$ can be considered as a function on $\A^n_K$, where $f(a_1,\dots,a_n)$ is result of specializing $x_i$ to $a_i$ for each $i$.

\begin{defn} For any subset $S\subseteq K[x_1,\dots,x_n]$, we set \[\cZ(S):= \{(a_1,\dots,a_n) \in \A^n_K \ | \ f(a_1,\dots,a_n)=0 \ \text{for all} \ f\in S\}.\]\index{$\cZ(I)$} We call $\cZ(S)$ the \DEF{zero set} of $S$. A \DEF{subvariety} of $\A^n_K$ is a set of the form $\cZ(S)$. An \DEF{affine variety}, or just a \DEF{variety}, is a subvariety of $\A^n_K$ for some $n$.
\end{defn}

\begin{rem} Note that if $L \supseteq K$ is a larger field, any polynomial $f\in K[x_1,\dots,x_n]$ is also an element of $L[x_1,\dots,x_n]$, and we can evaluate it at any point in $\A^n_L$. Thus, we may write \Def{$\cZ_K(S)$} or $\cZ_L(S)$ the distinguish between the zero sets over different fields.
\end{rem}

\begin{ex}
\begin{enumerate}
%\item
%For any field, we have
%$\cZ(0) = \A^n_k$ and  $\cZ(1) = \emptyset$. 

\item For $K = \mathbb{R}$ and $n = 2$, $\mathcal{Z}(y^2 - x^2(x+1))$ is a ``nodal curve'' in $\A^2_\mathbb{R}$, the real plane. Note that we've written $x$ for $x_1$ and $y$ for $x_2$ here.
\item
For $K = \mathbb{R}$ and $n = 3$, $\mathcal{Z}(z - x^2 - y^2)$ is a paraboloid in $\A^3_\mathbb{R}$, real three space. 
\item For $K = \mathbb{R}$ and $n = 3$, $\mathcal{Z}(z - x^2 - y^2, 3x - 2y + 7z - 7)$ is a circle in $\A^3_\mathbb{R}$.
\item For $K = \mathbb{R}$ and $n=3$, $\cZ(xy,xz)$ is a line and a plane that cross transversely.
 
 \item Over an arbitrary field $K$, a linear subspace of $\A^n_K = K^n$ is a subvariety: such a subset is defined by some linear equations.
 

 
 \item For $K = \mathbb{R}$, $\mathcal{Z}_\mathbb{R}(x^2 + y^2 + 1) = \emptyset$. Note that $\mathcal{Z}_\mathbb{C}(x^2 + y^2 +1 ) \neq \emptyset$, since it contains $(i,0)$.
 
   \item For $K = \mathbb{R}$, $\mathcal{Z}_\mathbb{R}(x^2 + y^2) = \{(0,0)\}$. On the other hand, $\mathcal{Z}_\mathbb{C}(x^2 + y^2)$ is a union of two ``lines'' in $\C^2$ (or two planes, in the ``real'' sense), given by the equations $x+iy=0$ and $x-iy=0$.



\item The subset $\A^2_K \setminus \{(0,0)\}$ is not an algebraic subset of $\A^2_K$ if $K$ is infinite. Why?


\item The graph of the sine function is not an algebraic subset of $\A^2_\mathbb{R}$. Why not?

\item For $K = \mathbb{R}$ or $\C$, the set
\[ X= \{ (t,t^2,t^3) \ | \ t\in K\} \] is an algebraic variety, though it isn't clear from this description. In fact, $X=\mathcal{Z}(y-x^2, z-x^3)$. To see the containment ``$\subseteq$'', for $(t,t^2,t^3)\in X$, we have $t^2- t^2=0$ and $t^3 - t ^3=0$. For the containment ``$\supseteq$'', let $(a,b,c)\in  \mathcal{Z}(y-x^2,  z-x^3)$, so $b=a^2$ and $c=a^3$. Setting $t=a$, we get that $(a,b,c)=(t,t^2,t^3)\in X$. The same argument works over $\C$. 

\item For $K = \mathbb{R}$ or $\C$, the set
\[ X= \{ (t^3,t^4,t^5) \ | \ t\in \R\} \] is an algebraic variety, though again it needs justification. Consider $Y=\cZ(y^3-x^4,z^3-x^5)$; clearly $X\subseteq Y$. Over $\R$, for $(a,b,c)\in Y$, take $t=\sqrt[3]{a}$; then $a=t^3$, $b^3=a^4$ means $b=\sqrt[3]{a}^4$, so $b=t^4$, and similarly $c=t^5$, so $X=Y$. We were using uniqueness of cube roots in this argument though, so we need to reconsider over $\C$. Indeed, if $\omega$ is a cube root of unity, then $(1,1,\omega)\in Y\smallsetminus X$, so we need to do better. Let's try $Z=\cZ(y^3-x^4,z^3-x^5,z^4-y^5)$. Again, $X\subseteq Z$. Say that $(a,b,c)\in \A^3_{\C}$ are in $Z$, and let $s$ be a cube root of $a$. Then $b^3=a^4 = (s^4)^3$ implies that $b=\omega s^4$ for some cube root of unity $\omega'$ (maybe $1$, maybe not). Similarly $c^3=a^4= (s^5)^3$ implies that $c=\omega'' s^5$ for some cube root of unity $\omega''$ (maybe $1$, maybe $\omega'$, maybe not). So at least $(a,b,c)=(s^3,\omega' s^4, \omega'' s^5)$. Let $t=\omega' s$. Then $(s^3,\omega' s^4, \omega'' s^5) = (t^3,t^4, \omega s^5)$, where $\omega= (\omega')^2 \omega''$ is again some cube root of unity. The equation $b^5=c^4$ shows that $t^20 = \omega^5 t^20$. If $t\neq 0$, this shows $\omega=1$, so $(a,b,c)=(t^3,t^4,t^5)$; if $t=0$, then $(a,b,c) = (0,0,0) = (0^3,0^4,0^5)$. Thus, $X=Z$.

\item For any field $K$ and elements $a_1, \dots, a_d \in K$, we have
\[\mathcal{Z}(x_1 - a_1, \dots, x_d -a_d) = \{(a_1, \dots, a_d)\}.\]
So, all one element subsets of $\A^d_K$ are algebraic subsets. 

\item Here is an example from linear algebra. Fix a field $K$ and consider the set of pairs $(A,v)$ of $2\times 2$ matrices and $2\times 1$ vectors over $K$. We can again identify this with $\A^6_K$; let's call our variables $x_{11}, x_{12}, x_{21}, x_{22}, y_1, y_2$, where we are thinking of $A= \begin{bmatrix} x_{11} & x_{12} \\ x_{21}& x_{22}\end{bmatrix}$ and $v= \begin{bmatrix} y_1 \\ y_2\end{bmatrix}$. The set $X$ of pairs $(A,v)$ such that $Av=0$ is a subvariety of $\A^6_K$:
\[ X = \cZ( x_{11} y_1 + x_{12} y_2, x_{21} y_1 + x_{22} y_2 ).\]


\item Let's take another linear algebra example. We can identify the set of $2 \times 3$ matrices over a field $K$ with~$\A^6_K$. To make this line up a little more naturally, let's label our variables as $x_{11}, x_{12}, x_{13}, x_{21}, x_{22}, x_{23}$. I claim that the set $X$ of matrices of rank $<2$ is a subvariety of $\A^{6}_K$. To see this, we need to find equations. For a $2\times 3$ matrix $A$ to have rank $<2$, it is necessary and sufficient that each $2\times 2$ submatrix have rank $<2$, which is equivalent to each of the $2\times 2$ minors (subdeterminants) of the matrix to be zero. Thus, 
\[ X = \cZ( x_{11} x_{22} - x_{12} x_{21} , x_{11} x_{23} - x_{13} x_{21} , x_{12} x_{23} - x_{13} x_{22} ).\]

\end{enumerate}
\end{ex}

 
 \begin{prop}
  Let $K$ be a field and $R=K[x_1, \dots,x_n]$. Let $S, S_{\lambda}, T \subseteq R$ be arbitrary subsets, and $I, I_\lambda, J\subseteq R$ be ideals.
  \begin{enumerate}
  \item[(0)] $\cZ(1) = \varnothing$ and $\cZ(0) = \A^n_K$.
  \item If $S\subseteq T$, then $\cZ(S) \supseteq \cZ(T)$.
  \item If $I= (S)$ is the ideal generated by $S$, then $\cZ(S) = \cZ(I)$.
  \item $\displaystyle \cZ(\bigcup_{\lambda \in \Lambda} S_\lambda)=\bigcap_{\lambda \in \Lambda} \cZ(S_\lambda)$.
  \item[(3')] $\displaystyle \cZ(\sum_{\lambda \in \Lambda} I_\lambda)=\bigcap_{\lambda \in \Lambda} \cZ(I_\lambda)$.
  \item $\displaystyle \cZ(\{fg \ | \ f\in S,  g\in T\}) = \cZ(S) \cup \cZ(T)$.

  \item[(4')]  $\displaystyle \cZ(I \cap J)=\cZ(IJ) = \cZ(I) \cup \cZ(J)$.
\end{enumerate}
\end{prop}
\begin{proof}
(0) is clear, since $1$ is never equal to zero and $0$ is always zero. (1) is also clear, since imposing more equations cannot enlarge the solution set.

For (2), we have $\cZ(I) \subseteq \cZ(S)$ by (1). On the other hand, if $f_1,\dots,f_m\in S$ and $r_1,\dots,r_m\in R$, and $(a_1,\dots,a_n)\in \cZ(S)$, then $f_i(a_1,\dots,a_n)=0$ for all $i$, so \[(\sum_i r_i f_i)(a_1,\dots,a_n) = \sum_i r_i(a_1,\dots,a_n) f_i(a_1,\dots,a_n) = 0,\] so $(a_1,\dots,a_n)\in \cZ(\sum_i r_i f_i)$. Thus, $(a_1,\dots,a_n)\in \cZ(I)$. That is, $\cZ(S) \subseteq \cZ(I)$. Similarly\dots

(3) is clear: for a point to satisfy be a solution to all of the equations in each set $S_\lambda$, it is equivalent to be a solution of each set of equations $S_\lambda$. For (3'), using (2) and (3), since $\sum_{\lambda \in \Lambda} I_\lambda$ is the ideal generated by $\bigcup_{\lambda\in\Lambda} I_\lambda$, we have
\[ \cZ(\sum_{\lambda \in \Lambda} I_\lambda) =  \cZ(\bigcup_{\lambda \in \Lambda} I_\lambda) = \bigcap_{\lambda \in \Lambda} \cZ(I_\lambda).\]

For (4), it is clear that \[\cZ(S) \cup \cZ(T) \subseteq \cZ(\{fg \ | \ f\in S,  g\in T\}),\] since $f(a_1,\dots,a_n)=0$ for all $f\in S$ implies $f(a_1,\dots,a_n) g(a_1,\dots,a_n)=0$ for all $f\in S$ and all $g\in T$. On the other hand, if $(a_1,\dots,a_n)\notin \cZ(S) \cup \cZ(T)$, then there is some $f\in S$ and some $g\in T$ with $f(a_1,\dots,a_n) \neq 0$ and $g(a_1,\dots,a_n)\neq 0$, so $f(a_1,\dots,a_n) g(a_1,\dots,a_n)\neq 0$.

For (4'), since $IJ \subseteq I \cap J \subseteq I$ and $I \cap J \subseteq J$), by (1) we get
\[ \cZ(I) \cup \cZ(J) \subseteq \cZ(I \cap J) \subseteq  \cZ(IJ).\] On the other hand, by (2) and (4) we get
\[ \cZ(IJ) \subseteq \cZ( \{ fg \ | \ f\in I , g\in J\}) = \cZ(I) \cup \cZ(J),\]
so the equalities hold throughout.
\end{proof}

\Feb{7}

\begin{rem}
A basic corollary of (2) above and the Hilbert basis theorem says that every system of polynomial equations is equivalent to a finite one! Indeed, for any set $S$, $\cZ(S) = \cZ(I)$ for $I=(S)$, and since $K[x_1,\dots,x_n]$ is Noetherian, $S=(f_1,\dots,f_m)$ for some $m$, so $\cZ(S) = \cZ(f_1,\dots,f_m)$.
\end{rem}


\begin{defn} Let $K$ be a field, and $X\subseteq \A^n_K$ be a subset. We define
\[\cI(X):= \{ f\in K[x_1,\dots,x_n] \ | \ f(a_1,\dots,a_n)=0 \ \textrm{for all} \ (a_1,\dots,a_n)\in X\}\]
\end{defn}

One evident relation between the two notions: for a subset $X\subseteq \A^n_K$ and a subset $S \subseteq K[x_1,\dots,x_n]$, we have 
\[ X \subseteq \cZ(S) \Longleftrightarrow \text{each $s\in S$ vanishes at each $x\in X$} \Longleftrightarrow S \subseteq \cI(X).\]

\begin{definition}
	The {\it radical}\index{radical of an ideal}\index{$\sqrt{I}$} of an ideal $I$ in a ring $R$ is the ideal
	\[\sqrt{I} := \{f\in R \ | \ f^n\in I \textrm{ for some } n\}.\] 
	An ideal is a {\it radical ideal}\index{radical ideal} if $I=\sqrt{I}$.
\end{definition}
 
 To see that $\sqrt{I}$ is an ideal, note that if $f^m, g^n \in I$, then 
 \[ \begin{aligned} (f+g)^{m+n-1} &= \sum_{i=0}^{m+n-1} \binom{m+n-1}{i} f^i g^{m+n-1-i} \\
 &= f^m \left(f^{n-1} + \binom{m+n-1}{1} f^{n-2}g + \cdots + \binom{m+n-1}{n-1} g^{n-1}\right) \\
 &+ g^n \left(\binom{m+n-1}{n} f^{m-1} + \binom{m+n-1}{n+1} f^{m-2} g + \cdots + g^{m-1} \right) \in I,
  \end{aligned}\]
 and $(rf)^m=r^m f^m \in I$.
 
Note that $I\subset R$ is radical if and only if $R/I$ has a nonzero nilpotent elements; i.e., $R/I$ is \DEF{reduced}.


\begin{prop} Let $K$ be a field, and $X,X_\lambda,Y$ be subsets of $\A^n_K$.
\begin{enumerate}
\item[(0)] $\cI(\varnothing) = R$ and, if $K$ is infinite, $\cI(\A^n_K) =  0$.
\item If $X \subseteq Y$, then $\cI(X) \supseteq \cI(Y)$.
\item $\cI(X)$ is a radical ideal.
%\item $\cI( \bigcup_{\lambda\in \Lambda} X_\lambda) = \bigcap_{\lambda\in \Lambda} \cI(X_\lambda)$.
\end{enumerate}
\end{prop}
\begin{proof}
For (0), it is clear that $\cI(\varnothing) = R$. Assume $K$ is infinite. We show by induction on $n$ that a nonzero polynomial in  $K[x_1,\dots,x_n]$ is nonzero at some point in $\A^n_K$. The case $n=1$ is standard: a polynomial in $K[x]$ of degree $d$ can have at most $d$ roots. Now, let $f(x_1,\dots,x_n)\in K[x_1,\dots,x_n]$ be a nonzero polynomial. If $f$ is a nonzero constant, it is nonzero at any point. Otherwise, we can assume that $f$ nontrivally involves some variable, say $x_n$. Write
\[f(x_1,\dots,x_n) = f_d(x_1,\dots,x_{n-1}) x_n^d + \cdots + f_0(x_1,\dots,x_{n-1}).\]
If $f$ is identically zero, then for every $(a_1,\dots,a_{n-1})\in \A^{n-1}_K$, 
\[f_d(a_1,\dots,a_{n-1}) x_n^d + \cdots + f_0(a_1,\dots,a_{n-1}) \]
is a polynomial in one variable that is identically zero, so is the zero polynomial, so each $f_i(a_1,\dots,a_{n-1})$ is identically zero. By the induction hypothesis, these are the zero polynomial, so $f(x_1,\dots,x_n)$ is the zero polynomial, as required.

(1) is clear.

For (2), note that $f,g\in \cI(X)$ and $r\in R$ implies $X\subseteq \cZ(f,g)$ implies $X \subseteq \cZ(rf+g)$ implies $rf+g \in \cI(X)$, so $\cI(X)$ is an ideal. If $f^t\in \cI(X)$, then $f(a_1,\dots,a_n)^t=0$ for all $(a_1,\dots,a_n)\in X$, so $f(a_1,\dots,a_n)=0$ for all $(a_1,\dots,a_n)\in X$, and $f\in \cI(X)$. \qedhere

%(3) is straightforward.
\end{proof}

Determining $\cI(X)$ can be very difficult; there was already some work involved in settling $\cI(\A^n_K)$! We will explore the relationship between the associations $\cZ$ and $\cI$ more soon. 

%Here are a few cautionary examples:

%\begin{enumerate}
%\item $\cZ(\cI( \mathrm{graph \ of} \ \sin(x))) = \A^2_{\R}$.
%\item $\cI(\cZ( x^2+y^2)) = (x,y)$ over $\R$, but $\cI(\cZ(x^2+y^2)) = (x^2+y^2)$ over $\C$. We also have $\cI(\cZ(x^2+y^2)) = (x+y)$ over $\F_2$!
%\end{enumerate}
%\end{ex}



\ssec{Morphisms of varieties and coordinate rings}

The natural condition for a reasonable map between two varieties is that it should also be made from polynomials.

\begin{defn} \label{def26}
Suppose $X$ is a subvariety of $\A^m_K$ and $Y$ is a subvariety of $\A^n_K$. A {\em morphism of varieties}\index{morphism of varieties} or  {\em algebraic map}\index{algebraic map} or {\em regular map}\index{regular map} from $X$ to $Y$ is a function $\phi: X \to Y$ defined coordinatewise by polynomials $g_1, \dots, g_n\in K[x_1, \dots, x_m]$, that is 
$$
\phi(a_1, \dots, a_m) = (g_1(a_1, \dots, a_m), \dots, g_n(a_1, \dots, a_m)) \text{ for all }\va\in X.
$$
Not every choice of $g_1, \dots, g_n$ will give such a morphism, because the tuple $ (g_1(\va), \dots, g_n(\va))$ has to satisfy the equations of $Y$. Furthermore, different choices of $g_1, \dots, g_n$ may yield the same morphism.

A morphism of varieties $\phi: X \to Y$ is an \emph{isomorphism}\index{isomorphism of varieties} if there is some $\phi: Y \to X$ such that $\phi\circ \psi = \id_Y$ and $\psi \circ \phi = \id_X$.  
\end{defn}




\begin{ex}
 \begin{enumerate} 
 \item Let $X = \cZ(xy -1) \subseteq \A^2_K$ (i.e., $X$ is a hyperbola) 
and define $\phi: X \to \A^1_K$ by $\phi(a,b) = a$. Then $G$ is an algebraic map (indeed, it's given by a linear polynomial) and its image is $\A^1_K\setminus \{0\}$, which is {\em not} an algebraic subset of $\A^1_K$. So,  the set-theoretic  image of a morphism of varieties  need
  not be a variety.
 \item \label{ex:cuspidal} Take an infinite field, and 
let $Y$ be the classical cuspidal curve\index{cuspidal curve}:
$$
Y = \cZ(y^2 - x^3) \subseteq \A^2_K.
$$
\begin{center}
% \includegraphics[width = 2in, height = 2in]{cusp} 
 \end{center}
Define
$$
\phi: \A^1_K \to Y \quad \phi(t) = (t^2, t^3).
$$

$\phi$ is an algebraic map from $\A^1_K$ to $Y$
since the component functions are polynomial functions of $t$ and $(t^3)^2 - (t^2)^3 = 0$ for all $t$.

Note that $G$ is a bijection of sets. However, it is not an isomorphism. Indeed, if it were, we would have some map $\psi$ such that $\psi\circ \phi = \mathrm{id}_{\A^1_K}$. This $\psi$ would be given by a polynomial $h$ in two variables such that $h(t^2,t^3) = t$. It is easy to see that no such $h$ exists.

\item Consider $\A^6_K$ as the space of $2 \times 3$ matrices over $K$ with coordinates $x_{11},\dots,x_{23}$, and consider $\A^5_K$ as the space of pairs of $2 \times 1$ and $1\times 3$ matrices over $K$ with coordinates $y_1,y_2, z_1,z_2,z_3$. The map of matrix multiplication from $\A^5_K$ to $\A^6_K$ is a regular map:
\[ (y_1,y_2,z_1,z_2,z_3)  \mapsto \begin{bmatrix} y_1 z_1 & y_1 z_2 & y_1 z_3 \\ y_2 z_1 & y_2 z_2 & y_2 z_3 \end{bmatrix}.\]
\end{enumerate}
\end{ex}

\begin{defn} For an algebraic subset $X$ of $\A^n_K$, the {\em coordinate (function) ring}\index{coordinate ring} or the {\em ring of regular functions} of $X$ is the $K$-algebra
$$
K[X] := K[x_1, \dots, x_n]/\cI(X).
$$
Recall that $\cI(X)$ is a radical ideal, and so $K[X]$ is necessarily a reduced, finitely generated $K$-algebra. 
An algebra $A$ is {\em reduced}\index{reduced} if $a^n=0$ implies $a=0$ in $A$.

We call an {\em affine $K$-algebra}\index{affine algebra}  any ring of the form 
\[
K[x_1,\ldots, x_n]/I \text{ for some ideal } I\subseteq K[x_1,\ldots, x_n].
\]
\end{defn}

\begin{rem} Let $Y = \A^1_K$ and let $X$ be any algebraic subset of $\A^n_K$ for some $n$.
Then an algebraic map $\phi:X\to \A^1_K$ is determined by a polynomial $f\in K[x_1,\ldots, x_n]$. Two such polynomials $f, g$ give the same map $G$ if they agree on $X$, that is if $f-g\in \cI(X)$.
 So, we have a bijection of sets
$$
K[X] \cong \{ \text{algebraic morphisms from $X$ to $\A^1_K$} \}.
$$
In this way, $K[X]$ is
analogous to the ring
\[
\cC_\R(T) := \{\text{the collection of continuous real valued functions on $T$}\}.\]
\end{rem}

\begin{defn} Let $K$ be a field. Let $X\subseteq \A^m_K$ and $Y\subseteq \A^n_K$ be affine varieties. Let $\phi:X\to Y$ be a morphism given by $(g_1(x),\dots,g_n(x))$, with $g_i\in K[x_1,\dots,x_m]$. We define
\[ \xymatrix@R=.5em{ K[Y] \ar[r]^{\phi^*} & K[X] \\ f(y_1,\dots,y_n) \ar@{|->}[r] & f(g_1(x),\dots,g_n(x))}\]
Alternatively, thinking of $f\in K[Y]$ as a regular map from $Y \to A^1_K$, we have 
\[\xymatrix@R=.5em{ K[Y] \ar[r]^{\phi^*} & K[X] \\ Y \xra{f} \A^1_K \ar@{|~>}[r] & X \xra{f \phi} \A^1_K \ar@{=}[d]\\  & X\xra{\phi} Y \xra{f} \A^1_K}\]
We may call this the \DEF{homomorphism induced by} $\phi$ or the \DEF{pullback} of $\phi$.
\end{defn}

\begin{exer} Show that the rule $\phi^*$ is a well-defined ring homomorphism, and that the map $\phi \mapsto \phi^*$ is well-defined.
\end{exer}

\begin{exer} For any field $K$, there is a contravariant functor from affine varieties over $K$ to affine $K$-algebras that
\begin{itemize}
\item on objects, maps a variety $X$ to its coordinate ring $K[X]$,
\item on morphisms, maps a morphism of varieties $X\xra{\phi} Y$ to its pullback $K[Y] \xra{\phi^*} K[X]$.
\end{itemize}
\end{exer}



\begin{prop}
Let $X\subseteq \A^m_K$ and $Y\subseteq \A^n_K$ be affine varieties, and $\phi: X \to Y$ be a morphism. Then $\ker(\phi^*) = \cI(\im \phi) K[Y]$.
\end{prop}

%\begin{proof} First, we focus on the case $Y=\A^n_K$. A polynomial $f\in K[y_1,\dots,y_n]$ is in $\ker(\phi^*)$ if and only if $\phi^*(f)$ is the zero element in $K[X]$, which happens if and only if $f\circ \phi(a_1,\dots,a_m)$ is zero for each element $(a_1\dots,a_m)\in X$, but this just means $f$ vanishes on $\im (\phi)$.

%In general, write 
%\[ X \xra{\phi} Y  \stackrel{i}{\subseteq} \A^n_K \qquad  K[X] \xleftarrow{\phi^*} K[Y] \stackrel{i^*}{\twoheadleftarrow} K[y_1,\dots,y_n] \]
%and note
%\[ \ker(\phi^*) = \ker( (i\phi)^* ) K[Y] = \cI( \im(i\phi) ) K[Y] = \cI(\im(\phi) ) K[Y].\qedhere\]
%\end{proof}
The proof is left as an exercise.

\Feb{9}

\ssec{The Zariski topology and irreducible varieties}

\begin{defn} Let $K$ be a field. The collection of subvarieties $X\subseteq \A^n_K$ is the collection of closed subsets in a topology on $\A^n_K$:
\begin{itemize}
\item $\varnothing = \cZ(1)$ and $\A^n_K = \cZ(0)$ are subvarieties,
\item unions of two subvarieties are subvarieties (products of the equations), and
\item arbitrary intersections of subvarieties are subvarieties (union of the equation sets).
\end{itemize}
This is called the \DEF{Zariski topology} on $\A^n_K$. Any subvariety of $\A^n_K$ obtains a \emph{Zariski topology} as the subspace topology from $\A^n_K$.
\end{defn}

This topology is not very similar to the Euclidean topology on a manifold; it is much coarser.

\begin{ex} Let $K$ be an infinite field. The closed subsets in the Zariski topology on $\A^1_K$ are just the finite subsets, along with the whole space. Note that this topology is not Hausdorff; quite on the contrary, any two nonempty open sets have infinite intersection!
\end{ex}

Here is a nice use of the topological structure.

\begin{prop} Let $X\subseteq \A^n_K$ be a subset. Then $\cZ(\cI(X)) = \overline{X}$, the closure of $X$ in the Zariski topology.
\end{prop}
\begin{proof} Clearly $X \subseteq \cZ(\cI(X))$ and $\cZ(\cI(X))$ is closed, so $\overline{X} \subseteq \cZ(\cI(X))$. 
On the other hand, $\displaystyle \overline{X} = \bigcap_{\substack{W \supseteq X \\ W \ \mathrm{closed} }} W$.  For $W\supseteq X$ closed, write $W=\cZ(J)$; then $J\subseteq \cI(W)$ and $W \supseteq X$ implies $\cI(W) \subseteq \cI(X)$, so $J\subseteq \cI(X)$, hence $\cZ(\cI(X)) \subseteq \cZ(J) = W$. It follows that $\cZ(\cI(X)) \subseteq \overline{X}$ as well.
\end{proof}


\begin{rem} Note as a consequence that the function
\[ \{ \text{subvarieties of} \ \A^n_K\} \xra{\cI} \{ \text{ideals of} \ K[x_1,\dots,x_n] \} \]
is injective, since $\cZ$ serves as a left inverse.
\end{rem}


Recall that a topological space is connected if it cannot be written as the disjoint union of two closed subsets. Here is a much stronger  notion of a similar flavor.

\begin{defn} A topological space is \emph{irreducible}\index{irreducible space} if it cannot be written as a union of two proper closed subsets.
\end{defn}

This is much stronger than connected, since there is no disjointness condition on the sets.

\begin{exer}
\begin{enumerate}
\item If $Y\subseteq X$ is irreducible, then so is $\overline{Y} \subseteq X$.
\item If $X$ is an irreducible topological space, and $f:X\to Y$ is continuous, then $f(X)$ is irreducible.
\item Any nested union $\bigcup_{\lambda\in \Lambda} X_\lambda$ (for a totally ordered set $\Lambda$ and $X_\mu \subseteq X_\nu$ for $\mu\leq \nu$) of irreducible spaces is irreducible.
\end{enumerate}
\end{exer}

\begin{exer}
A topological space is Hausdorff if and only if every irreducible subset is a point.
\end{exer}



\begin{prop} Let $K$ be an infinite field. Affine space $\A^n_K$ is irreducible. 
\end{prop}
\begin{proof} Say that $\A^n_K = \cZ(I) \cup \cZ(J)$ for some ideals $I,J$. We need to show either $\cZ(I) =\A^n_K$ or $\cZ(J) = \A^n_K$. Note that $\A^n_K = \cZ(IJ)$. We must have $IJ=0$: if $f\in IJ\smallsetminus 0$, then $\cZ(IJ)\subseteq \cZ(f) \subsetneqq \A^n_K$ since $\cI(\A^n_K) = 0$. If $I$ and $J$ are both nonzero, take $f\in I\smallsetminus 0$, and $g\in J \smallsetminus 0$; we get $fg\in IJ \smallsetminus 0$, which is a contradiction. Thus, without loss of generality, $I=0$, so $\cZ(I) = \A^n_K$.
\end{proof}

\begin{ex} Affine space over a finite field is reducible: points are subvarieties, so finite unions of points are, and hence \[\A^n_K = \{(0,\dots,0)\} \cup \A^n_K \smallsetminus \{(0,\dots,0)\}\] is a decomposition into proper subvarieties.
\end{ex}

\begin{ex} The variety $\cZ_\R(xy,xz)$ is reducible: it is $\cZ_{\R}(x) \cup \cZ_{\R}(y,z)$, the union of a line and a plane, which are varieties.
\end{ex}

\begin{ex} Let $K$ be an infinite field. Think of $\A^6_K$ as the set of pairs of $2\times 2$ matrices $A$ (with coordinates $x_{ij}$) and $2\times 1$ vectors $v$ (with coordinates $y_1,y_2$), and let $X=\cZ(x_{11} y_1 + x_{12} y_2, x_{21} y_1 + y_{22} y_2)$ be the variety of pairs such that $Av=0$. If $Av=0$ then either $v=0$, or else $v$ is a nonzero vector in the kernel of $A$, so $\det(A)=0$. Thus, $ X= X_1 \cup X_2$, where \[ X_1 = \cZ(x_{11} y_1 + x_{12} y_2, x_{21} y_1 + y_{22} y_2,  y_1, y_2) = \cZ(y_1, y_2)\]
\[ X_2= \cZ(x_{11} y_1 + x_{12} y_2, x_{21} y_1 + y_{22} y_2, x_{11} x_{22} - x_{12} x_{21}) ,\]
so $X$ is reducible.
\end{ex}


\Feb{11}

\begin{ex} Let $K$ be an infinite field. Think of $\A^6_K$ as the set of $2\times 3$ matrices (with coordinates $x_{ij}$), and let $X$ be the variety of matrices of rank at most $1$. Any matrix $A\in X$ of rank at most one can be written as $A= B C$ for some $2\times 1$ matrix $B$ and some $1\times 3$ matrix $C$, and conversely any such product has rank at most $1$. It follows that $X$ is the image of the morphism \[ \xymatrix@R=1em{ \A^5 \ar[r] & \A^6 \\ (y_1,y_2,z_1,z_2,z_3) \ar@{|->}[r] & {\begin{pmatrix} y_1 z_1 & y_1 z_2 & y_1 z_3 \\ y_2 z_1 & y_2 z_2 & y_2 z_3\end{pmatrix}} } \]
and hence is irreducible.
\end{ex}




\begin{defn} Let $X$ be a topological space. We say that $X$ is a \DEF{Noetherian} topological space if the poset of open sets under containment has ACC, or equivalently that the poset of closed subsets has DCC.
\end{defn}

\begin{lem} Any affine variety $X$ is a Noetherian topological space with the Zariski topology.
\end{lem}
\begin{proof} It suffices to deal with $\A^n_K$, since subspaces of Noetherian spaces are Noetherian. If there was an infinite descending chain of closed subvarieties of $\A^n_K$, applying $\cI$, we would obtain an infinite ascending chain of ideals in $K[x_1,\dots,x_n]$, which contradicts Hilbert's Basis Theorem.
\end{proof}


\begin{defn} Let $X$ be a topological space. A maximal irreducible subspace of $X$ is called an \DEF{irreducible component} of $X$.
\end{defn}

\begin{rem} An irreducible component of a space is closed, since the closure of an irreducible subset is closed.
\end{rem}

\begin{prop}  Let $X$ be a topological space.
\begin{enumerate}
\item $X$ is the union of its irreducible components. 
\item If $X=X_1\cup \cdots \cup X_n$ with each $X_i$ irreducible, and suppose that $X_i \not\subseteq \bigcup_{j\neq i} X_j$; i.e., the union $X=X_1\cup \cdots \cup  X_n$ is \DEF{irredundant}. Then $\{X_1,\dots,X_n\}$ is the collection of irreducible components of~$X$.
\item If $X$ is Noetherian, then $X$ has finitely many irreducible components. Hence, if $X$ is Noetherian, it can be written as an irredundant finite union of irreducible components in a unique way.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}
\item It suffices to show that any point is in an irreducible component. Let $x\in X$, and consider the collection of irreducible subsets of $X$ that contain $x$. This is nonempty, since $\{x\}$ is in the collection.  By the exercise above, the union of any chain under inclusion is again irreducible, so Zorn's lemma applies. Such a subset must be a maximal irreducible subset, since any larger subset also contains~$x$.
\item Let $Y$ be an irreducible component of $X$. Then $Y= (X_1 \cap Y) \cup \cdots \cup  (X_n \cap Y)$ implies that $X_i \cap Y = Y$, so $Y\subseteq X_i$ for some~$i$. By maximality, we must have $Y=X_i$. This shows that every irreducible component is on the list.

Conversely, for some $X_i$, take $Y\supseteq X_i$ to be an irreducible component: we can do this by the same Zorn's Lemma argument as in the previous part. By what we just showed, $Y=X_j$ for some~$j$. By irredundancy, we must have $i=j$, so $X_i$ is an irreducible component.

\item Consider the collection of closed subsets of $X$ that are not finite unions of irreducibles. If this collection is nonempty (in particular, if $X$ is not a finite union of irreducibles), it has a minimal element by DCC; call it $Z$. In particular, $Z$ is reducible, so write $Z=Z'\cup Z''$ with $Z', Z''$ closed proper subsets of $Z$. Since they are smaller than $Z$, they are finite unions of irreducibles. Putting them together expresses $Z$ as a finite union of irreducibles. \qedhere
\end{enumerate}
\end{proof}




\ssec{Prime and maximal ideals}

\begin{thm} Let $K$ be a field, and $X\subseteq \A^n_K$ be an affine variety.
\begin{enumerate}
\item $X$ is irreducible if and only if $\cI(X)$ is a prime ideal.
\item $X$ is a point if and only if $\cI(X)$ is a maximal ideal.
\end{enumerate}
\end{thm}

\begin{proof} 
\begin{enumerate}
\item First we show that if $\cI(X)$ is not prime, then $X$ is reducible. Suppose that $f,g\notin \cI(X)$ and $fg\in \cI(X)$. Since $f\notin \cI(X)$, $f$ does not vanish at some point of $X$, so $X\not\subseteq \cZ(f)$. Thus,
\[ \cZ(\cI(X) + (f)) = \cZ(\cI(X)) \cap \cZ(f) = X \cap \cZ(f) \subsetneqq X,\]
and likewise $\cZ(\cI(X) + (g)) \subsetneqq X$. But
\[ X \supseteq \cZ(\cI(X) + (f)) \cup \cZ(\cI(X) + (g)) = \cZ( (\cI(X) +(f)) (\cI(X) +(g)) ) = \cZ( \cI(X)^2 +(f,g)\cI(X) +(fg)) \supseteq \cZ(\cI(X)) = X, \]
so $\cZ(\cI(X) + (f)) \cup \cZ(\cI(X) + (g)) = X$. This shows that $X$ is reducible.

Now, we show that if $X$ is reducible, then $\cI(X)$ is not prime. Write $X= Y\cup Z$ with $Y,Z$ closed and $Y,Z\subsetneqq X$. We must that $\cI(X) \subsetneqq \cI(Y),\cI(Z)$, and $\cI(Y)\neq \cI(Z)$, since $Y\neq Z$. Take $f\in \cI(Y) \smallsetminus \cI(Z)$ and $g\in \cI(Z) \smallsetminus \cI(Y)$. Then $fg\in \cI(Y) \cap \cI(Z)$, so \[\cZ(fg) \supseteq \cZ(\cI(Y) \cap \cI(Z)) = Y\cup Z = X.\]
Thus, $fg\in \cI(X)$. This shows that $\cI(X)$ is not prime.

\item First, take $X=\{(a_1\dots,a_n)\}$. We have $x_i-a_i \in \cI(X)$ for all $i$, so $\fm:=(x_1-a_1,\dots,x_n-a_n) \subseteq \cI(X)$. The ideal $\fm$ is maximal, since the quotient $K[x_1,\dots,x_n]/\fm \cong K$ is a field. Since the only larger ideal is the full ring itself, and $1\notin \cI(X)$, we must have $\cI(X)=\fm$ is maximal.

On the other hand, if $X \supsetneqq \{(a_1\dots,a_n)\}$, then $\cI(X) \subsetneqq \cI(\{(a_1\dots,a_n)\})$, so $\cI(X)$ is not maximal. 
\end{enumerate}
\qedhere
\end{proof}




\begin{cor} Let $K$ be a field.
\begin{enumerate}
\item The maps $\cZ$ and $\cI$ induce a bijection \[ \{ \text{maximal ideals $\fm$ of $R=K[x_1,\dots,x_n]$ such that $R/\fm\cong K$} \} \leftrightarrow \A^n_K\]
\item For any affine variety $X$, there is a bijection
\[ \{ \text{maximal ideals $\fm$ of $K[X]$ such that $K[X]/\fm\cong K$} \} \leftrightarrow X\]
\end{enumerate}
\end{cor}




 \Feb{14}


 
 
\begin{proof}
For (1), we need to see that $\xra{\cZ}$ and $\xleftarrow{\cI}$ restrict to maps to/from the prescribed source and target. For $\cZ$, let $\fm$ be a maximal ideal with residue field $K$, and consider $\pi: R \to R/\fm \cong K$. We then have that $\pi(x_i) = a_i$ for some $a_i\in K$, so $(x_1-a_1,\dots,x_n-a_n) \subseteq \ker(\pi)=\fm$, and this ideal is maximal, so equality holds. Then $\cZ (\fm) = \{ (a_1,\dots,a_n)\}$, so $\cZ$ gives a well-defined map from left to right. On the other hand, from the last theorem, we see that for any point, $\cI$ yields an ideal of this form so $\cI$ restricts to a well-defined map here. We know that $\cZ(\cI(x))=x$ for a point $x$ since a point is closed, and for an ideal $\fm$ as above, $\cI(\cZ(\fm))$ is a maximal ideal containing $\fm$, so must equal $\fm$. 


For (2), we note that there is a bijection between maximal ideals of $K[X]$ and maximal ideals of $K[x_1,\dots,x_n]$ that contain $\cI(X)$; moreover $\cI(X) \subseteq \fm$ if and only if $\cZ(\fm) \in \cZ(\cI(X))=X$. Thus, the bijection from (1) induces a bijection between maximal ideals of $K[X]$ and points of $X$.
\end{proof}


To recap, over an any field $K$, the maps $\xleftarrow{\cZ}$ and $\xrightarrow{\cI}$ yield order-reversing maps between the collections below and satisfy $\cZ \circ \cI = \mathrm{id}$ in each case, so they induce bijections between the RHS and a subset of the LHS (the image of $\cI$):
\[ \xymatrix@R=.7em@C=4em{ \text{\underline{in $K[x_1,\dots,x_n]$}} &  \text{\underline{in $\A^n_K$}}  \\
\{\text{radical ideals}\} \ar@<-.5ex>[r]_-{\cI} & \ar@<-.5ex>[l]_-{\cZ} \{\text{varieties} \} \\
\{\text{prime ideals}\} \ar@<-.5ex>[r]_-{\cI} & \ar@<-.5ex>[l]_-{\cZ}  \{\text{irred vars} \} \\
\{\text{maximal ideals}\} \ar@<-.5ex>[r]_-{\cI} & \ar@<-.5ex>[l]_-{\cZ}  \{\text{points} \}. }\]
 Likewise, for any variety $X$, we have order-reversing maps that induce bijections between the RHS and a subset of the LHS:
\[ \xymatrix@R=.7em@C=4em{ \text{\underline{in $K[X]$}} &  \text{\underline{in $X$}}  \\
\{\text{radical ideals}\} \ar@<-.5ex>[r] & \ar@<-.5ex>[l] \{\text{subvarieties} \} \\
\{\text{prime ideals}\} \ar@<-.5ex>[r] & \ar@<-.5ex>[l]  \{\text{irred subvars} \} \\
\{\text{maximal ideals}\} \ar@<-.5ex>[r] & \ar@<-.5ex>[l]  \{\text{points} \}. }\]
In both cases, we identified the image of the last $\leftarrow$ as maximal ideals whose residue field was no bigger than the ground field.

 
 \begin{ex} \begin{enumerate} \item The radical ideal $(0) \subseteq \F_p[x]$ is not in the image of $\cI$ (i.e., is left of the the bijection above) over $K=\F_p$. Indeed, $\cI(\cZ(0)) = \cI(\A^1_{\F_p}) = (x^p-x)$.
 \item The prime ideal $(x^2+y^2+z^2) \subseteq \R[x,y,z]$ is not in the image of $\cI$ over $K=\R$: $\cI(\cZ(x^2+y^2+z^2))= \cI(\{(0,0,0\}) = (x,y,z)$.
 \item The maximal ideal $(x^2+1) \subseteq \R[x]$ is not in the image of $\cI$ over $K=\R$: $\cI(\cZ(x^2+1))=\cI(\varnothing) = (1)$.
 \end{enumerate}\end{ex}
 


\sec{The Nullstellensatz and the prime spectrum}


\ssec{Review of transcendence bases}

\begin{definition} Let $K\subseteq L$ be an extension of fields. A \emph{transcendence basis}\index{transcendence basis} for $L$ over $K$ is a maximal algebraically independent subset of $L$.
	\end{definition}

\begin{rem}
\label{rem:trbasis}
\begin{enumerate}
\item Every field extension has a transcendence basis. This is given by Zorn's Lemma once we see that a union of an increasing chain of algebraically independent sets is algebraically independent. Indeed  if there were a nontrivial relation on some elements in the union, there would be a nontrivial relation on finitely many, and so a relation in one of the members in the chain.
\item Every set of field generators for $L/K$ contains a transcendence basis. This is also given by Zorn's lemma considering algebraically independent subsets of the given generating set.
\item Observe that $\{x_\lambda\}_{\lambda\in \Lambda}$ is a transcendence basis for $L$ over $K$, if an only if there is a factorization
\[ K \subseteq K(\{x_\lambda\}_{\lambda\in \Lambda}) \subseteq L\]
where the first inclusion is \emph{purely transcendental}\index{purely transcendantal}, or isomorphic to a field of rational functions, and the second inclusion is algebraic (integral). If the latter were not algebraic, there would be an element of $L$ transcendental over $K(\{x_\lambda\}_{\lambda\in \Lambda})$, and we could use that element to get a larger algebraically independent subset, contradicting the definition of transcendence basis. Conversely, if $K \subseteq K(\{x_\lambda\}_{\lambda\in \Lambda}) \subseteq L$ with the first inclusion purely transcendental and the second algebraic, $\{x_\lambda\}_{\lambda\in \Lambda}$ is a transcendence basis.
\end{enumerate}
\end{rem}


\begin{lem} Let $\{x_1,\dots,x_m\}$ and $\{y_1,\dots,y_n\}$ be two transcendence bases for $L$ over $K$. Then, there is some $i$ such that $\{x_i,y_2,\dots,y_n\}$ is a transcendence basis.
\end{lem}
\begin{proof} Since $L$ is algebraic over $K(y_1,\dots,y_n)$, for each $i$ there is some $p_i(t)\in K(y_1,\dots,y_n)[t]$ such that $p_i(x_i)=0$. We can clear denominators to assume without loss of generality that $p_i(x_i)\in K[y_1,\dots,y_n][t]$. 

We claim that there is some $i$ such that $p_i(t) \notin K[y_2,\dots,y_n][t]$. If not, so $p_i(t) \in K[y_2,\dots,y_n][t]$ for all $i$, note that each $x_i$ is algebraic over $K(y_2,\dots,y_n)$.  Thus, $K(x_1,\dots,x_m)$ is algebraic over $K(y_2,\dots,y_n)$, and since $L$ is algebraic over $K(x_1,\dots,x_m)$, $y$ is algebraic over $K(y_2,\dots,y_n)$, which contradicts that $\{y_1,\dots,y_n\}$ is a transcendence basis. This shows the claim.

Now, we claim that for such $i$, $\{x_i,y_2,\dots,y_n\}$ is a transcendence basis. Thinking of the equation $p_i(x_i)=0$ as a polynomial expression in $K[x_i,y_2,\dots,y_n][y_1]$, $y_1$ is algebraic over $K(x_i,y_2,\dots,y_n)$, hence $K(y_1,\dots,y_n)$ is algebraic over $K(x_i,y_2,\dots,y_n)$, and $L$ as well.

If $\{x_i,y_2,\dots,y_n\}$ were algebraically dependent, take a polynomial equation $p(x_i,y_2,\dots,y_n)=0$. Note that this equation must involve $x_i$, since $y_2,\dots,y_n$ are algebraically independent. We would then have $K(x_i,y_2,\dots,y_n)$ is algebraic over $K(y_2,\dots,y_n)$. But since  $y_1$ is algebraic over $K(x_i,y_2,\dots,y_n)$, we would have that $K(y_1,\dots,y_n)$ is algebraic over $K(y_2,\dots,y_n)$, which would contradict that $y_1,\dots,y_n$ is a transcendence basis.
\end{proof}

\begin{prop} If $\{x_1,\dots,x_m\}$ and $\{y_1,\dots,y_n\}$ are two transcendence bases for $L$ over $K$, then $m=n$.
\end{prop} 
\begin{proof} Say that $m\leq n$.  If the intersection has $s<m$ elements, then without loss of generality $y_1\notin \{x_1,\dots,x_m\}$. Then, for some $i$,  $\{x_i, y_2\dots,y_n\}$ is a transcendence basis, and $\{x_1,\dots,x_m\} \cap \{x_i, y_2\dots,y_n\}$ has $s+1$ elements. Replacing $\{y_1,\dots,y_n\}$ with  $\{x_i, y_2\dots,y_n\}$ and repeating this process, we obtain a transcendence basis with $n$ elements such that $\{x_1,\dots,x_m\} \subseteq \{y_1,\dots,y_n\}$. But we must then have that these two transcendence bases are equal, so $m=n$.
\end{proof}


\ssec{Nullstellensatz}

\begin{thm}[Zariski's Lemma]
\label{lem:Zariski}
 Let $K\subseteq L$ be fields. If $L$ is a finitely generated $K$-algebra, then $L$ is a finite dimensional $K$-vector space. In particular, if $K$ is algebraically closed then $L=K$.
\end{thm}
\begin{proof}
	Let $L=K[h_1,\dots,h_d]$. Since in particular $h_1,\dots,h_d$ generate $L$ as a field over $K$, we can choose a transcendence basis for $L/K$ from among the $h$'s, and after reordering, we may assume that $h_1,\dots,h_c=x_1,\dots,x_c$ form a transcendence basis, and $h_{c+1},\dots,h_d$ are algebraic over $K'=K(x_1,\dots,x_c)$. Then $L$ is integral and algebra-finite over $K'$, hence module-finite. Thus, if $c=0$, we are done. Suppose that $c\neq 0$; we will obtain a contradiction to complete the proof.

 We can apply the Artin-Tate Lemma to $K\subseteq K' \subseteq L$ to see that $K'$ is algebra-finite over $K$. In particular, there are $f_i, g_i$ in the polynomial ring $K[x_1,\dots,x_c]$ such that $K'=K[\frac{f_1}{g_1},\dots,\frac{f_m}{g_m}]$. This implies that any element of $K'$ can be written as a fraction with denominator $(g_1\cdots g_m)^n$ for some $n$.  The element $\frac{1}{g_1\cdots g_m +1}\in K'$ cannot be written this way; if so, we would have 
	\[  \frac{v}{(g_1\cdots g_m)^n} = \frac{1}{g_1\cdots g_c +1},\]
	for some $v$ with $g_1\cdots g_m \nmid v$ (since the polynomial ring is a UFD). But, the equation $g_1\cdots g_m v + v = (g_1\cdots g_m)^n$ contradicts this.
	
Now if $K$ is algebraically closed and $\ell \in L$, since $L/K$ is finite then $\ell$ is algebraic over $K$,  thus $\ell\in K$.
\end{proof}

\Feb{16}


\begin{thm}[Hilbert's Nullstellensatz (Weak Form)]
Let $K$ be an algebraically closed field and  $J$ be an ideal of $K[x_1, \dots x_n]$. We have 
\[\cZ(J) =\emptyset \text{ if and only if } J = K[x_1, \dots, x_n].\]
\end{thm}

\begin{rem} One direction is clear. The nontrivial direction, in its most basic form, says the following: Suppose we are given a system of polynomial equations
\[
\begin{aligned}
f_1(x_1, \dots, x_n) & = 0 \\
f_2(x_1, \dots, x_n) & = 0 \\
\vdots \qquad &  = \, \vdots \\
f_m(x_1, \dots, x_n) & = 0 \\
\end{aligned}
\]
in $n$ variables with coefficients in some algebraically closed field $K$.  If the system has no solutions over $K$, then for some polynomials $g_1,\dots, g_m$ we have $\sum_i g_i f_i = 1$. One can think of $g_1,\dots,g_m$ as forming a ``certificate'' that there is no solution.
\end{rem}



\begin{proof} If $J = K[x_1, \dots, x_n]$, then $Z(J) = \emptyset$ since $1 = 0$ has no solutions.


We show that if $J \subset K[x_1, \dots, x_n]$ is a proper ideal, then $Z(J) \ne \emptyset$. Since $J$ is proper, it is contained in some maximal ideal $\fm$. By Zariski's Lemma, $K[x_1,\dots,x_n]/\fm\cong K$,  so we have $\cZ(\fm) \neq \varnothing$.
\end{proof}



 To attack the Strong Form of the Nullstellensatz, we will need an observation on inequations. 
 
 \begin{remark}[Rabinowitz's trick]
 \label{rk:Rabinowitz}
 We write $\vx=(x_1,\dots,x_n)$ and $\va=(a_1,\dots,a_n)$. Observe that, if $f(\vx)$ is a polynomial, $f(\va)\neq 0$ if and only if there is a solution $y=b\in K$ to $yf(\va)-1=0$. In particular, a system of polynomial equations and inequations
\begin{equation*}
f_1(\vx)=0, \dots, f_m(\vx)=0, g_1(\vx)\neq0,\dots, g_n(\vx)\neq 0
\end{equation*}
has a solution $\vx=\va$ if and only if the system
\begin{equation*}
 f_1(\vx)=0, \dots, f_m(\vx)=0, y_1 g_1(\vx)-1=0,\dots, y_n g_n(\vx)-1 = 0
\end{equation*}
has a solution $(\vx,\vy)=(\va,\underline{b})$. In fact, this is equivalent to a system in one extra variable:
\begin{equation*}
f_1(\vx)=0, \dots, f_m(\vx)=0, y g_1(\vx)\cdots g_n(\vx)-1 = 0.
\end{equation*}
\end{remark}

\begin{thm}[Hilbert's Nullstellensatz (Strong Form)] Let $K$ be an algebraically closed field and 
let $J$ be an ideal in the polynomial ring $R=K[x_1, \dots, x_n]$. Then, for $f\in R$, 
$\cZ(f) \supseteq \cZ(J)$ if and only if $f\in \sqrt{J}$.

In particular, $\cI(\cZ(J)) = \sqrt{J}$.
\end{thm}

%\begin{rem} The Strong Form implies the Weak Form: If $Z(J)$ is empty, then $1 \in I(Z(J))$ and hence $1^n \in J$ by the Strong Form, which gives that $J = (1)$.  
%\end{rem}

\begin{proof}
The equations in $\sqrt{J}$ vanish on $\cZ(J)$, so $\sqrt{J}\subseteq \cI(\cZ(J))$.
	
	For the converse, suppose that $f(\vx)$ vanishes on $\cZ(J)$. Write $J=(g_1,\dots,g_m)$. Considering the system 
\[
g_1(\vx)=0, \dots, g_m(\vx)=0, f(\vx)\neq 0
\]
we see that it has no solution since $f(\vx)=0$ is a consequence of the first $m$ equations. By the remark above, 
this implies that $\cZ(JS+(yf-1))=\varnothing$, where $JS+(yf-1)$ is an ideal in the polynomial ring ${S=K[x_1,\ldots,x_n,y]}$. By the Weak Nullstellensatz, we see that $1\in J S+(yf-1)$. Write $J=(g_1(\vx),\dots,g_m(\vx))$, and
	\[1 = r_0(\vx,y) (1-yf(\vx))+r_1(\vx,y) g_1(\vx) + \cdots + r_m(\vx,y) g_m(\vx).  \]
	We can apply an evaluation map $S\to \mathrm{Frac}(R)$ sending $y \mapsto 1/f$ to get
	\[1 = r_1(\vx,1/f) g_1(\vx) + \cdots + r_m(\vx,1/f) g_m(\vx).  \]
	 Since each $r_i$ is polynomial, there is a largest negative power of $f$ occurring; say that $f^n$ serves as a common denominator. We can clear denominators multiplying by $f^n$ to obtain (on the LHS) $f^n$ as a polynomial combination of the $g$'s (on the RHS).
\end{proof}



%\begin{ex} Recall that
%\[ X:= \{ (t^3,t^4,t^5) \ | \ t\in \C \} = \cZ(y^3-x^4,z^3-x^5,z^4-y^5)\}.\]
%Let $I=(y^3-x^4,z^3-x^5,z^4-y^5)$ and $J=(x^3-yz,y^2-xz,z^2-x^2y)$.
%We claim that $\cI(X) = J$. By the Nullstellensatz, $\cI(X) = \sqrt{I}$, so it suffices to show that $\sqrt{I}=J$. We will show that $I \subseteq J$, $J \subseteq \sqrt{I}$, and that $J$ is prime; it will follow that 
%\[ I \subseteq J (=\sqrt{J}) \subseteq \sqrt{I} \subseteq \sqrt{J} (=J),\]
%and thus the conclusion.
%
%To see that $I \subseteq J$, we check that every generator of $I$ is congruent to $0$ modulo $J$:
%\[ y^3-x^4 = y (y^2) - x (x^3) \equiv y(xz) - x(yz) =0, \quad \mod J\]
%and similarly with the other two.
%
%To see that $J \subseteq \sqrt{I}$, we check that every generator of $J$ has a power that is congruent to $0$ modulo $I$:
%note that 
%\[ x^9 yz \equiv (x^4)(x^5)yz \equiv y^4 z^4 \equiv y^9 \equiv x^12 \equiv x^3 y^3 z^3 \quad \mod I\]
%and
%\[ x^6 y^2 z^2 \equiv x^2 y^5 z^2 \equiv x^2 z^6 \equiv x^{12}  \quad \mod I\]
%so
%\[ (x^3-yz)^4 = x^{12} - 4 x^9 yz + 6 x^6 y^2 z^2 - 4 x^3 y^3 z^3 + y^4 z^4 \equiv x^{12} ( 1 - 4 + 6 - 4 +1) \equiv 0  \quad \mod I,\]
%and similarly with the other two.
%
%Now, we argue that $J$ is prime. We will show that the ring homomorphism
%\[ \xymatrix@R=1em{ \frac{\C[x,y,z]}{J} \ar[r] & \C[t^3,t^4,t^5] \\ (x,y,z) \ar@{|->}[r] & (t^3,t^4,t^5)}\] is an isomorphism; it clearly is surjective. Note that if we set $|x|=3,|y|=4,|z|=5, |t|=1$, this is a graded homomorphism of graded rings. Since $[ \C[t^3,t^4,t^5] ]_n$ is a $1$-dimensional vector space generated by $t^n$ for all $n\geq 3$ (and zero in degrees 1 and 2), it suffices to show that $\dim( [\frac{\C[x,y,z]}{J}]_n ) \leq 1$ for all $n\leq 3$ (and zero in degrees 1 and 2).
%
%Given any monomial in $\frac{\C[x,y,z]}{J}$ we can use the relations $y^2-xz$, $z^2-x^2y$, and $yz-x^3$ to obtain an equivalent monomial where the sum of the $y$ and $z$ exponents is smaller until we get a monomial of the form $x^a$, $x^a y$, or $x^a z$. If $n=1,2$, there is no such monomial; if $n\geq 3$, there is exactly one, namely, 
%\[ \begin{cases} x^{n/3} & \text{if} \ n\equiv 0 \mod 3 \\
% x^{(n-4)/3} y & \text{if} \ n\equiv 1 \mod 3 \\
% x^{(n-5)/3} y & \text{if} \ n\equiv 2 \mod 3 \end{cases}\]
% This shows the claim, and concludes the proof.
% \end{ex}


\begin{corollary}\label{ord-pres-bij}
	Let $K$ be an algebraically closed field. The associations $\cZ$ and $\cI$ induce order-reversing bijections
	\[ \xymatrix@R=.7em@C=4em{ \text{\underline{in $K[x_1,\dots,x_n]$}} &  \text{\underline{in $\A^n_K$}}  \\
\{\text{radical ideals}\} \ar@<-.5ex>[r]_-{\cI} & \ar@<-.5ex>[l]_-{\cZ} \{\text{varieties} \} \\
\{\text{prime ideals}\} \ar@<-.5ex>[r]_-{\cI} & \ar@<-.5ex>[l]_-{\cZ} \{\text{irred vars} \} \\
\{\text{maximal ideals}\} \ar@<-.5ex>[r]_-{\cI} & \ar@<-.5ex>[l]_-{\cZ}  \{\text{points} \}. }\]
 In particular, given ideals $I$ and $J$, we have $\mathcal{Z}(I) = \mathcal{Z}(J)$ if and only if $\sqrt{I}=\sqrt{J}$.

 Likewise, for any variety $X$ over an algebraically closed  field, we have order-reversing bijections
\[ \xymatrix@R=.7em@C=4em{ \text{\underline{in $K[X]$}} &  \text{\underline{in $X$}}  \\
\{\text{radical ideals}\} \ar@<-.5ex>[r] & \ar@<-.5ex>[l] \{\text{subvarieties} \} \\
\{\text{prime ideals}\} \ar@<-.5ex>[r] & \ar@<-.5ex>[l]  \{\text{irred subs} \} \\
\{\text{maximal ideals}\} \ar@<-.5ex>[r] & \ar@<-.5ex>[l]  \{\text{points} \}. }\]
	\end{corollary}



\begin{ex} Recall that
\[ X:= \{ (t^3,t^4,t^5) \ | \ t\in \C \} = \cZ(I), \ \text{where} \ I=(y^3-x^4,z^3-x^5,z^4-y^5).\]
By the Nullstellensatz, $\cI(X) = \sqrt{I}$. The ideal $I$ is not radical: 
note that 
\[ x^9 yz \equiv (x^4)(x^5)yz \equiv y^4 z^4 \equiv y^9 \equiv x^{12} \equiv x^3 y^3 z^3 \quad \mod I\]
and
\[ x^6 y^2 z^2 \equiv x^2 y^5 z^2 \equiv x^2 z^6 \equiv x^{12}  \quad \mod I\]
so
\[ (x^3-yz)^4 = x^{12} - 4 x^9 yz + 6 x^6 y^2 z^2 - 4 x^3 y^3 z^3 + y^4 z^4 \equiv x^{12} ( 1 - 4 + 6 - 4 +1) \equiv 0  \quad \mod I.\]
One can show that $\sqrt{I}=(x^3-yz,y^2-xz,z^2-x^2y)$.
\end{ex}


\ssec{Spectrum of a ring}

As a consequence of the Nullstellensatz, for an algebraically closed field $K$ and an algebra of the form $R=K[x_1,\dots,x_n]/I$ that is reduced, we know that $I=\cI(X)$ for some variety $X\subseteq \A^n_K$, and $R=K[X]$. We can recover $X$ (as a set) from the ring $R$ by taking the maximal ideals of $R$. Moreover, we can recover the Zariski topology on $X$: a subvariety of $X$ corresponds to a (radical) ideal of~$R$, so the closed subsets correspond to the sets of maximal ideals that contain a particular (radical) ideal of~$R$. Moreover, we can reconstruct morphisms of varieties from the maps on their coordinate rings:

\begin{exer} Let $X,Y$ be affine varieties over an algebraically closed field with $R=K[X]$ and $S=K[Y]$. Let $\phi:X\to Y$ be an algebraic morphism, and $\phi^*: S\to R$ be the induced map on coordinate rings. Then the following diagram commutes:
\[ \xymatrix@R=2mm{ \Max(R) \ar[rrrrr]\ar[dddd] &&& & & \Max(S) \ar[dddd]\\
& \fm  \ar@{|->}[rrr] &&& (\phi^*)^{-1}(\fm) & \\
\\
\\
X \ar[rrrrr]^-{{\large \phi}} &&&&& Y}\]
where the vertical maps send a maximal ideal of the form $(x_1-a_1,\dots,x_n-a_n)$ to the point $(a_1,\dots,a_n)$; this is essentially the map $\cZ$ on maximal ideals.
\end{exer}

\begin{rem}
Loosely speaking, this exercise says that $\Max(-)$ can be thought of as a contravariant functor that, on the category of reduced finitely generated algebras over algebraically closed fields, is an inverse to the coordinate ring functor up to natural isomorphism. The precise statement is that functor yields an equivalence of categories.
\end{rem}

\Feb{18}


We now use a similar idea to construct a geometric object for every ring. However, we want this to be functorial, and in general the preimage of a maximal ideal is not maximal, e.g., for the inclusion $\Z\subseteq \Q$, $(0)$ is maximal in $\Q$, but its contraction is $(0)$ in $\Z$, which is not maximal. However, the preimage of a prime ideal is prime.

\begin{lem} Let $R\to S$ be a ring homomorphism and $\fp\subset S$ be prime. Then $\fp \cap R$ is also prime.
\end{lem}

\begin{defn} Let $R$ be a ring. The \DEF{prime spectrum} of $R$, \Def{$\Spec(R)$}, is the set of prime ideals of $R$. \end{defn}

\begin{defn} For a ring $R$ and an ideal $I$, we set \index{$V(I)$}
\[ V(I) := \{ \fp \in \Spec(R) \ | \ \fp \supseteq I\}.\]
\end{defn}


\begin{proposition}
	Let $R$ be a ring, and $I_{\lambda},J$ be ideals (possibly improper).
	\begin{enumerate}
		\item[(0)] $V(R) = \varnothing$ and $V(0) = \Spec(R)$.
		\item If $I \subseteq J$, then $V(J)\subseteq V(I)$.
		\item $V(I) \cup V(J) = V(I \cap J)=V(IJ)$.
		\item $\bigcap_{\lambda} V(I_{\lambda}) =V(\sum_{\lambda} I_{\lambda})$.
		\item $V(I)=V\sqrt{I}$
	%	\item $\Spec(R)$ has a basis given by open sets of the form $D(f):=\Spec(R)\smallsetminus V(f)$.
	%	\item $\Spec(R)$ is quasicompact.
	\end{enumerate}
\end{proposition} 
\begin{proof}
We only deal with (2), as the others are straightforward.
 To see $V(I)\cup V(J)\subseteq V(I \cap J)$, just observe that if $\p \supseteq I$ or $\p \supseteq J$, then $\p \supseteq I \cap J$.
		Since $IJ\subseteq I\cap J$, we have $V(I\cap J) \subseteq V(IJ)$. To show $V(IJ)\subseteq V(I)\cup V(J)$, if $\p \not\supseteq I, J$, let $f\in I\smallsetminus \p$, and $g \in J\smallsetminus \p$. Then $fg \in IJ \smallsetminus \p$ since $\p$ is prime.
		\end{proof}


\begin{defn} It follows that $\Spec(R)$ obtains a topology by setting the closed sets to be all sets of the form $V(I)$; this is the \DEF{Zariski topology} on $\Spec(R)$.
\end{defn}

\begin{exer} Note that $\Spec(R)$ is also a poset under inclusion. Show that the poset structure of $\Spec(R)$ can be recovered from the topology as follows: 
\[ \p\subseteq \q \quad \Leftrightarrow \quad \q \in \overline{\{ \p \}}.\]
\end{exer}


\begin{ex} For any affine variety $X$ over an algebraically closed field, the spectrum of $K[X]$ consists of maximal ideals and nonmaximal primes. The maximal ideals are in bijection with the points of $X$; the other primes correspond to irreducible subvarieties of $X$. Thus, we can think of $\Spec(K[X])$ as $X$ with ``fake points'' added in for each irreducible subvariety.
\end{ex}

\begin{example} The spectrum of $\mathbb{Z}$ is, as a poset:
\[ \xymatrix@C-1pc{ &&&& & (2) &  & (3) &  & (5) & & (7) & & (11) & & \cdots &&&&& \\ 
&&&& &  & &  & &  & (0)\ar@{-}[lllllu] \ar@{-}[lllu] \ar@{-}[lu] \ar@{-}[ru] \ar@{-}[rrru] \ar@{=}[rrrrru] &&&&& &&&&& }\]
The closed sets are of the form $V((n))$, which are the whole space when $n=0$, the empty set with $n=1$, and any finite union of things in the top row.
\end{example}


\begin{definition}[Induced map on $\Spec$]
	Given a homomorphism of rings $\varphi:R\to S$, we obtain a map on spectra $\varphi^*:\Spec(S)\to\Spec(R)$\index{map on $\Spec$} given by $\varphi^*(\p)=\varphi^{-1}(\p)$.
\end{definition}




The key point is that the preimage of a prime ideal is also prime. 
We will often write $\p \cap R$ for $\varphi^{-1}(\p)$, even if the map is not necessarily an inclusion.

We observe that this is not only an order-preserving map, but also is continuous: if $U\subseteq \Spec(R)$ is open, we have $U=\Spec(R) \smallsetminus V(I)$ for some ideal $I$; then for a prime $\q$ of $S$,
\[\q\in (\varphi^*)^{-1}(U) \quad \Leftrightarrow \quad \q \cap R \not\supseteq I  \quad \Leftrightarrow \quad \q \not\supseteq IS  \quad \Leftrightarrow \quad \q \in \Spec(S) \smallsetminus V(IS).\]

\begin{lemma} Let $R$ be a ring, $I$ an ideal, and $W$ a multiplicatively closed subset. If $W\cap I=\varnothing$, then there is a prime ideal $\p$ with $\p \supseteq I$ and $\p \cap W=\varnothing$.
\end{lemma}
\begin{proof}
	Consider the family of ideals $\{ J \ | \ J \supseteq I, J \cap W=\varnothing\}$. This is nonempty, since it contains $I$, and has some maximal element $\fA$ by a basic application of Zorn's Lemma. We claim $\fA$ is prime. Suppose $f,g\notin \fA$. By maximality, $\fA+(f)$ and $\fA+(g)$ both have nonempty intersection with $W$, so there exist $r_1f+a_1$, $r_2 g+a_2 \in W$, with $a_1,a_2\in \fA$. If $fg\in \fA$, then $(r_1f+a_1)(r_2g+a_2)=r_1 r_2 fg + r_1 f a_2 + r_2 g a_1 + a_1 a_2 \in W \cap \fA$, a contradiction.
\end{proof}


\begin{proposition}[Spectrum analogue of strong Nullstellensatz]
	Let $R$ be a ring, and $I$ be an ideal. For $f\in R$,
	\[  V(I) \subseteq V(f) \Longleftrightarrow f\in \sqrt{I}.\] 
	Equivalently, $\bigcap_{\p \in V(I)} \p = \sqrt{I}$.
\end{proposition}

\Feb{21}

\begin{proof}
First to justify the equivalence of the two statements we observe: 
\[V(I) \subseteq V(f) \Leftrightarrow f\in \p \ \text{for all} \ \p\in V(I)  \Leftrightarrow f \in \bigcap_{\p \in V(I)} \p.\]
We prove the latter formulation.

$(\supseteq)$: It suffices to show that $\p \supseteq I$ implies that $\p \supseteq \sqrt{I}$. But, $f^n\in \p$ implies $f\in \p$, so this is clear.

$(\subseteq)$: If $f\notin \sqrt{I}$, consider the multiplicatively closed set $W=\{1,f,f^2,f^3,\dots\}$. We have $W\cap I=\varnothing$ by hypothesis. By the previous lemma, there is a prime $\p$ in $V(I)$ that does not intersect $W$, and hence does not contain $f$.
\end{proof}

\begin{cor} 	For two ideals $I,J$, $V(I)=V(J)$ if and only if $\sqrt{I}=\sqrt{J}$.
\end{cor}
\begin{proof} ($\Leftarrow$): Follows from $V(I)=V(\sqrt{I})$.
($\Rightarrow$): If $V(I)=V(J)$, then $f\in \sqrt{I}$ if and only if $V(f)\supseteq V(I) = V(J)$ if and only if $f\in \sqrt{J}$.
\end{proof}

We also have the following:

\begin{prop} $V(I)$ is irreducible if and only if $\sqrt{I}$ is prime.
\end{prop}
\begin{proof} Observe first that
\[ V(I+(f)) \cup V(I + (g)) = V(I^2 + (f,g)I + (fg)) = V(I^2+(f,g)I) \cap V(fg) = V(I) \cap V(fg)\]
since $I^2 \subseteq I^2+(f,g)I \subseteq I$ implies $\sqrt{I} = \sqrt{I^2} \subseteq \sqrt{I^2+(f,g)I} \subseteq \sqrt{I}$ so equality holds throughout.

Now, if $\sqrt{I}$ is not prime, take $f, g\notin\sqrt{I}$ with $fg\in \sqrt{I}$. Then $V(I+(f)), V(I+(g)) \subsetneqq V(I)$ and $V(I+(f)) \cup V(I + (g)) = V(I) \cap V(fg) = V(I)$ since $V(fg)\supseteq V(I)$. Thus $V(I)$ is reducible.

On the other hand, any closed proper subset of $V(I)$ is contained in a closed set of the form $V(I+(h))$ for some $h\notin \sqrt{I}$, so if $V(I)$ is reducible, then we can write $V(I)= V(I+(f)) \cup V(I + (g))$ for $f,g\notin\sqrt{I}$. By the computation above, we have $V(I)=V(I)\cap V(fg)$ so $V(fg) \supseteq V(I)$ and $fg\in \sqrt{I}$, so $\sqrt{I}$ is not prime.
\end{proof}

We conclude

\begin{corollary}
	Let $R$ a ring.
	The map $\xrightarrow{V}$ induces order-reversing bijections
\[	\xymatrix@R=.7em@C=4em{ \text{\underline{in $R$}} &  \text{\underline{in $\Spec(R)$}}  \\
\{\text{radical ideals}\} \ar@{<->}[r] & \ \{\text{closed subsets} \} \\
\{\text{prime ideals}\} \ar@{<->}[r]& \{\text{irred closeds} \} \\
\{\text{maximal ideals}\} \ar@{<->}[r] &  \{\text{closed points} \}. }\]
\end{corollary}




\sec{Support of modules and associated primes}

\ssec{Localization}



Our three most important classes of  examples of multiplicative sets are as follows.
\begin{example} Let $R$ be a ring.
	\begin{enumerate}
		\item For any $f\in R$, the set $W=\{1, f, f^2, f^3, \dots\}$ is a multiplicative set.
		\item If $\p\subseteq R$ is a prime ideal, the set $W=R\smallsetminus \p$ is multiplicative: this is an immediate translation of the definition.
		\item The set of \emph{nonzerodivisors}\index{nonzerodivisor} in $R$---elements that are not zerodivisors---forms a multiplicatively closed subset.
	%	\item An arbitrary intersection of multiplicatively closed subsets is multiplicatively closed. In particular, for any family of primes $\{\p _{\lambda} \}$, the set $R \smallsetminus \bigcup_{\lambda} \p _{\lambda}$ is multiplicatively closed.
	\end{enumerate}
\end{example}

\begin{definition}[Localization of a ring]
	Let $R$ be a ring, and $W$ be a multiplicative set with $0\notin W$. The \emph{localization}\index{localization of a ring} of $R$ at $W$ is the ring 
	\[ W^{-1} R := \left\{ \frac{r} {w} \ \Big| \ r\in R, w\in W \right\} / \sim \]
	where $\sim$ is the equivalence relation $\displaystyle \frac{r}{w}\sim \frac{r'}{w'}$ if $\exists u\in W : u(rw'-r'w)=0$. The operations are given by 
	\[ \frac{r}{v}+\frac{s}{w}=\frac{rw+sv}{vw} \qquad \text{and} \qquad  \frac{r}{v}\frac{s}{w}=\frac{rs}{vw}.\]
	There is a canonical ring homomorphism $R\to W^{-1}R$ that sends $r \mapsto \frac{r}{1}$.
\end{definition}

Note that we write elements in $W^{-1}R$ in the form $r/w$ even though they are equivalence classes of such expressions.

Observe that if $R$ is a domain, the equivalence relation simplifies to $rw'=r'w$, so $R \subseteq W^{-1}R \subseteq \mathrm{Frac}(R)$, and in particular $ W^{-1}R$ is a domain too.

%In the localization of $R$ at $W$, every element of $W$ becomes a unit. The following universal property says roughly that $W^{-1}R$ is the smallest $R$-algebra in which every element of $R$ is a unit.

%\begin{proposition}
%	Let $R$ be a ring, and $W$ a multiplicative set with $0\notin W$. Let $S$ be an $R$-algebra in which every element of $W$ is a unit. Then there is a unique homomorphism $\alpha$ such that the following diagram commutes:
%	\[\xymatrix{ R \ar[r]\ar[d] & W^{-1}R \ar[dl]^{\alpha} \\  S& } \]
%	where the vertical map is the structure homomorphism and the horizontal map is the canonical homomorphism.
%\end{proposition}

\begin{example}[Most important localizations] Let $R$ be a ring.
	\begin{enumerate}
		\item For $f\in R$ and $W=\{1, f, f^2, f^3, \dots\}$, we usually write $R_f$\index{$R_f$} for $W^{-1}R$.
		\item For $\p\subset R$ prime, we generally write $R_{\p}$\index{$R_{\p}$} for $(R\smallsetminus \p)^{-1} R$.
		\item When $W$ is the set of nonzerodivisors on $R$, we call $W^{-1}R$ the \emph{total ring of fractions}\index{total ring of fractions} of $R$. When $R$ is a domain, this is just the fraction field of $R$.
	\end{enumerate}
\end{example}

We state an analogous definition for modules, and for module homomorphisms.

\begin{definition}
	Let $R$ be a ring, $W$ be a multiplicative set, and $M$ an $R$-module. The \emph{localization}\index{localization of a module}\index{$W^{-1}M$} of $M$ at $W$ is the $W^{-1}R$-module
	\[ W^{-1} M := \left\{ \frac{m} {w} \ \Big| \ m\in M, w\in W \right\} / \sim \]
	where $\sim$ is the equivalence relation $\displaystyle \frac{m}{w}\sim \frac{m'}{w'}$ if $\exists u\in W : u(mw'-m'w)=0$. The operations are given by \[\frac{m}{v}+\frac{n}{w}=\frac{mw+nv}{vw} \qquad \text{and} \qquad \frac{r}{v} \frac{m}{w}=\frac{rm}{vw}.\]
	
	If $M\xrightarrow{\alpha} N$ is an $R$-module homomorphism, then there is a $W^{-1}R$-module homomorphism $W^{-1}M \xrightarrow{W^{-1}\alpha} W^{-1}N$\index{$W^{-1}\alpha$} given by the rule $W^{-1}\alpha (m/w) = \alpha(m)/w$.
\end{definition}

We will use the notations $M_f$\index{$M_f$} and $M_{\p}$\index{$M_{\p}$} analogously to $R_f$ and $R_{\p}$.

To understand localizations of rings and modules, we will want to understand better how they are built from $R$.



\begin{lemma}
	Let $M$ be an $R$-module, and $W$ a multiplicative set. The class 
	\[ \frac{m}{w}\in W^{-1}M \ \text{ is zero} \ \iff \  \exists v\in W \ : \ vm=0   \ \iff \ \ann_R(m) \cap W \neq \varnothing.\]
	Note in particular this holds for $w=1$.
\end{lemma}
\begin{proof}
	For the first equivalence, we compute: $\frac{m}{w}=\frac{0}{1}$ in $W^{-1}M$ if and only if $\exists v\in W$ such that $0=v(1m-0w)=vm$. The second equivalence just comes from the definition of the annihilator.
\end{proof}

\begin{remark}
	It follows from this lemma that if $\alpha:N\to M$ is injective, then $W^{-1}\alpha: W^{-1}N\to W^{-1}M$ is as well. Indeed, if $\alpha$ is injective, then
	\[ 0=W^{-1}\alpha(n/w)=\alpha(n)/w \ \Rightarrow \ \exists u\in W : 0=u\alpha(n)=\alpha(un) \Rightarrow \ un=0 \Rightarrow n/w=0.\]
\end{remark}





We want to collect one more lemma for later.

\begin{lemma} Let $M$ be a module, and $N_1,\dots,N_t$ be a finite collection of submodules. Let $W$ be a multiplicative set. Then,
	\[ W^{-1} (N_1 \cap \cdots \cap N_t) = W^{-1} N_1 \cap \cdots \cap W^{-1} N_t \subseteq W^{-1}M.\]
\end{lemma}
\begin{proof}
	The containment ``$\subseteq$'' is clear. An element of the RHS is of the form $\frac{n_1}{w_1}= \cdots = \frac{n_t}{w_t}$; we can find a common denominator to realize this in the LHS.
\end{proof}

Last semester in the homework we showed the following.


\begin{theorem}[Flatness of localization]
	Let $R$ be a ring, and $W$ a multiplicative system. Then
	\begin{enumerate}
		\item $W^{-1} R \otimes_R M \cong W^{-1}M$ as $W^{-1}R$-modules, and $W^{-1} R \otimes \alpha$ corresponds to $W^{-1}\alpha$ under these isomorphisms.
		\item $W^{-1}R$ is flat over $R$.
		\item $W^{-1}(-)$ is an exact functor; i.e., it sends exact sequences to exact sequences.
	\end{enumerate}
\end{theorem}
%\begin{proof}
%	\begin{enumerate}
%		\item The bilinear map $W^{-1}R \times M \to W^{-1}M$ given by $(r/w , m) \mapsto rm/w$ induces a map $\psi$ from the tensor product that is clearly surjective. For an inverse map, set $\phi(m/w) =1/w \otimes m$. To see this is well-defined, suppose $m/w=m'/w'$, so $\exists v\in W$ such that $v(mw'-m'w)=0$. Then, 
%		\[\phi(m/w) - \phi(m'/w')= 1/w \otimes m - 1/w' \otimes m'.\] We can multiply through by $vww' / vww'$ to get \[\frac{vw'}{vww'} \otimes m - \frac{vw}{vww'} \otimes m' = \frac{1}{vww'} \otimes v(mw'-m'w) = 0.\]
%		
%		 To see this is a homomorphism, we note that
%		\begin{align}\phi(\frac{m}{w}+\frac{m'}{w'})&=\phi(\frac{mw'+m'w}{ww'}) = \frac{1}{ww'} \otimes (mw'+m'w) = \frac{1}{ww'} \otimes mw' + \frac{1}{ww'} \otimes m'w \\
%		 &= \frac{w'}{ww'} \otimes m + \frac{w}{ww'} \otimes m' = \frac{1}{w} \otimes m + \frac{1}{w'} \otimes m' = \phi(\frac{m}{w}) + \phi(\frac{m'}{w'}), \end{align}
%		 and
%		 \[\phi(r \frac{m}{w}) = \frac{1}{w} \otimes rm = r(\frac{1}{w} \otimes m)=r\phi(\frac{m}{w}).\] The composition $\phi\circ \psi$ sends $r/w \otimes m \mapsto rm/w \mapsto 1/w \otimes rm = r/w \otimes m$; since it is the identity on simple tensors and additive, it is the identity.
%	
%For the claim about maps, we need to see that, for $M \xrightarrow{\alpha} N$, we have to check ${\psi_N \circ   (W^{-1}R \otimes \alpha)}= {W^{-1}\alpha \circ \psi_M}$. Indeed,
%
%\begin{align*} (\psi_N \circ (W^{-1}R \otimes \alpha)) (\frac{r}{w} \otimes m) &=\psi_N  (\frac{r}{w} \otimes \alpha(m)) = \frac{r \alpha(m)}{w} \\
%&=\frac{\alpha(rm)}{w}=W^{-1}\alpha (\frac{rm}{w}) =  (W^{-1}\alpha \circ \psi_M)(\frac{r}{w} \otimes m).\end{align*}
%
%	
%		\item This follows from the earlier observation that $W^{-1}(-)$ preserves injective maps.
%		
%		\item This is immediate from part (2).\qedhere
%	\end{enumerate}
%\end{proof}

\begin{proposition}
	Let $W$ be multiplicatively closed in $R$.
	\begin{enumerate}
	\item[(0)] $W^{-1} I = I(W^{-1} R)$.
		\item If $I$ is an ideal, then $W^{-1} I \cap R = \{ r \in R \ | \ \exists w\in W : wr\in I\}$.
		\item If $\p$ is prime and $W \cap \p=\varnothing$, then $W^{-1}\p =\p (W^{-1}R)$ is prime.
		\item The map $\Spec(W^{-1} R) \to \Spec(R)$ is injective, with image $\{\p \in \Spec(R) \ | \ \p \cap W = \varnothing\}$.
	\end{enumerate}

\end{proposition}
\begin{proof}
	\begin{enumerate}

		\item Since $W^{-1}(R/I) \cong W^{-1} R / W^{-1} I$, we have $\ker (R \to W^{-1}(R/I)) = R \cap W^{-1} I$. The equality is then clear.
		\item First, since $W\cap \p =\varnothing$, and $\p$ is prime, we know that no element of $W$ kills $\bar{1}=1 + \p$ in $R/\p$, so $\bar{1}/1$ is nonzero in $W^{-1}(R/\p)$. Thus, $W^{-1}R / W^{-1}\p \cong W^{-1}(R/\p)$ nonzero, and a localization of a domain, hence is a domain. Thus, $W^{-1}\p$ is prime.
	
	\Feb{23}
		\item First, by part (2), the map $\p \mapsto W^{-1}\p$, for $S=\{\p \in \Spec(R) \ | \ \p \cap W = \varnothing\}$ sends primes to primes. We claim that 
	\[\xymatrix@R=1em{  \Spec(W^{-1} R) \ar@{<->}[r] & S \\
	\q  \ar@{|->}[r] &  \q \cap R \\
	W^{-1}\p=\p (W^{-1}R) \ar@{<-|}[r] & \p}\]
		is a pair of mutually inverse maps.
		
	To see this, first note that if $J$ is an ideal of $W^{-1}R$, then $J=(J\cap R) W^{-1}R$. Indeed, if $J=(a_1/w_1,\dots,a_t/w_t)$, then  $J=(a_1/1,\dots,a_t/1)$, since each generator was replaced by a unit multiple. Second, if $W\cap \p=\varnothing$, then using part (1) and the definition of prime, we have that $\p = W^{-1}\p \cap R$.\qedhere
	\end{enumerate}
\end{proof}

\begin{corollary}
Let $R$ be a ring and $\p$ be a prime ideal. The map $R\to R_{\p}$ induces a map on spectra that is injective with image
\[ \{ \q \in \Spec(R) \ | \ \q \subseteq \p \}.\]
\end{corollary}

\begin{proposition}[Hom and flat base change]
	Let $S$ be a flat $R$ algebra, and $M,N$ be two $R$-modules. Suppose that $M$ is finitely presented. Then 
	\[\xymatrix{ S\otimes_R \Hom_R(M,N) \ar[r]^{\cong} & \Hom_{S} (S\otimes_R M, S\otimes_R N) \\
	s\otimes \varphi \ar@{|->}[r] & s(S\otimes \varphi)}\]
is an isomorphism.
\end{proposition}
\begin{proof}
	When $M$ is $R$ or a finitely generated free module $R^{\oplus a}$, this is clear: both sides are isomorphic to $(S\otimes_R N)^{\oplus a}$, and it is easy to see that the map above realizes this.
	
	Now, take a presentation 
	\[R^{\oplus b} \to R^{\oplus a} \to M \to 0.\]
	 If we apply $S\otimes_R -$, we obtain another right exact sequence; if we then apply $\Hom_S(-,S\otimes_R N)$ to this presentation, we obtain a left-exact sequence 
	 \[0 \to \Hom_{S} (S\otimes_R M, S\otimes_R N) \to \Hom_{S} (S\otimes_R  R^{\oplus a}, S\otimes_R N) \to \Hom_{S} (S\otimes_R R^{\oplus b}, S\otimes_R N).  \]
	 
	Likewise, if we apply $\Hom_R(-,N)$, we obtain a left exact sequence; if we then apply $S\otimes_R -$, we obtain by flatness another left exact sequence
	\[ 0\to S\otimes_R \Hom_R(M,N) \to S\otimes_R \Hom_R(R^{\oplus a},N) \to \Hom_R(R^{\oplus b},N). \]
	
	We then have a diagram
	\[\xymatrix{ 0 \ar[r] & \Hom_{S} (S\otimes_R M, S\otimes_R N) \ar[r] & \Hom_{S} (S\otimes_R  R^{\oplus a}, S\otimes_R N) \ar[r] & \Hom_S(S\otimes_R R^{\oplus b}, S\otimes_R N) \\
		0 \ar[r] &  S\otimes_R \Hom_R(M,N) \ar[r]\ar[u] & S\otimes_R \Hom_R(R^{\oplus a},N) \ar[r]\ar[u]^-{\cong} & S \otimes_R \Hom_R(R^{\oplus b},N) \ar[u]^-{\cong},} \]
	where the vertical maps are given by the formula of the statement. We claim that the squares commute. Indeed, given $X\xrightarrow{\alpha} Y$,  
	\[\xymatrix{  \Hom_{S} (S\otimes_R Y, S\otimes_R N) \ar[rrr]^{\Hom(S\otimes \alpha, S \otimes N)} & & & \Hom_{S} (S\otimes_R  X, S\otimes_R N)  \\
		 S\otimes_R \Hom_R(Y,N) \ar[rrr]^{S \otimes \Hom(\alpha,N)} \ar[u] & & & S\otimes_R \Hom_R(X,N) \ar[u]}, \]
		 an element $s\otimes \varphi$ in the bottom left goes $\uparrow$ to $s \cdot (S\otimes \varphi)$ and then $\rightarrow$ to $s \cdot (S \otimes (\varphi \circ \alpha))$, whereas $s\otimes \varphi$ goes $\rightarrow$ to $s \otimes (\varphi\circ \alpha)$ and then $\uparrow$ to $s \cdot (S\otimes (\varphi \circ \alpha))$.
		 It then follows that there is an isomorphism in the first vertical map in the previous diagram.
\end{proof}


\begin{corollary}[Hom and localization]
	Let $R$ be a Noetherian ring, $W$ be a multiplicative set, $M$ be a finitely generated $R$-module, and $N$ an arbitrary $R$-module. Then,
	\[ \Hom_{W^{-1}R}(W^{-1}M , W^{-1}N) \cong W^{-1} \Hom_R(M,N). \]
	In particular, if $\p$ is prime,
	\[ \Hom_{R_{\p}}(M_{\p} , N_{\p}) \cong \Hom_R(M,N)_{\p}. \]
\end{corollary}

%\begin{proposition}
%	Let $M$ be an $R$-module, and $W$ a multiplicative set. Set $M_W=\{ m\in M \ | \ \exists w\in W : wm=0\}$ and $\overline{M}=M/M_W$. Then,
%	\[ W^{-1} M = \bigcup_{w\in W} \frac{1}{w} \overline{M}, \]
%	where each $\frac{1}{w} \overline{M}$ is an isomorphic copy of $\overline{M}$ as an $R$-module.
%\end{proposition}
%\begin{proof}
%	First, $M_W$ is a submodule of $M$ and consists of the elements that go to zero in the localization. We have $W^{-1}{\overline{M}} \cong W^{-1}(M/M_W) \cong \frac{W^{-1}M}{W^{-1} M_W}\cong W^{-1}M$, so we can replace $M$ by the $W$-torsionfree module $\overline{M}$. It is clear that every element of $W^{-1}M$ has the form on the RHS. The map $\overline{M} \to \frac{1}{w} \overline{M}$ sending $m \mapsto \frac{m}{w}$ is clearly $R$-linear, and is injective by the $W$-torsion free assumption.
%\end{proof}



%\begin{definition}
%	Let $\phi:R\to S$ be a ring homomorphism, and $\p\in \Spec(R)$. We call the ring
%	\[ \kappa_{\phi}(\p):= (R\smallsetminus \p)^{-1} (S/\p S) \]
%	the \emph{fiber ring}\index{fiber ring}\index{$\kappa_{\phi}(\p)$} of $\phi$ over $\p$.
%\end{definition}
%
%The point of this definition is the following.
%
%\begin{lemma} Let $\phi:R\to S$ be a ring homomorphism, and $\p\in \Spec(R)$.
%	$\Spec(\kappa_{\phi}(\p)) \cong (\phi^*)^{-1}(\p)$, the set of primes that contract to $\p$.
%\end{lemma}
%\begin{proof}
%	Consider the maps $S \to S/\p S \to (R\smallsetminus \p)^{-1} (S/\p S)$. For the first map, the map on spectra can be identified with the inclusion of $V(\p S)$ into $\Spec(S)$. For the second, it can be identified with the inclusion of the set of primes that do not intersect $R \smallsetminus \p$, i.e., those whose contraction is contained in $\p$. Put together, this is the set of primes that contract to $\p$. 
%\end{proof}

\ssec{Minimal primes and support}



\begin{definition}
	The primes that contain $I$ and are minimal with the property of containing $I$ are called the {\em minimal primes}\index{minimal prime} of $I$. That is, the minimal primes of $I$ are the minimal elements of $V(I)$. We write $\Min(I)$\index{$\Min(I)$} for this set. 
\end{definition}

%\begin{exer}\label{radical minimal primes}
%	Let $R$ be a ring, and $I$ an ideal. Every prime $\p$ that contains $I$ contains a minimal prime of $I$. Consequently,
%	$$\sqrt{I} = \bigcap_{\p\in \Min(I)} \p.$$
%\end{exer}

%\begin{proof}
%	This follows from Zorn's lemma. We just need to check that the intersection of a descending chain of prime ideals that contain $I$ is prime and contains $I$. These are both trivial.
%	The first equality in the ``consequently'' we already know; the second is basic set theory.
%\end{proof}

\begin{remark}\label{min primes of a prime}
	If $\p$ is prime, then $\Min(\p)=\{\p\}$. Also, since $V(I)=V(\sqrt{I})$, we have $\Min(I)=\Min(\sqrt{I})$.
\end{remark}



\begin{remark} As a consequence of the order-reversing correspondence between irreducible closed subsets and prime ideals, for an ideal $I$ and a prime ideal $\p$, we have that $\p\in \Min(I)$ if and only if $V(\p)$ is an irreducible component of $V(I)$.
\end{remark}

\begin{thm}
Let $R$ be a ring and $I$ be an ideal.
\begin{enumerate}
\item Every prime containing $I$ contains a minimal prime of $I$. Consequently,
	\[\sqrt{I} = \bigcap_{\p\in \Min(I)} \p.\]
\item If $I=\p_1 \cap \cdots \cap \p_n$ with each $\p_i$ prime, and $\p_i \not\supseteq \p_j$ for $i\neq j$, then $\Min(I)=\{\p_1,\dots,\p_n\}$.
\item If $R$ is Noetherian, then $\Min(I)$ is finite. Hence, if $R$ is Noetherian, $\sqrt{I}$ can be written as a finite irredundant intersection of primes in a unique way.
\end{enumerate}
\end{thm}
\begin{proof}
We can prove these directly, but we can instead deduce them for our general proposition on irreducible components of topological spaces and the remarks above. 

For (1), we recall that a topological space is the union of its irreducible components, so in particular, each point $\q \in V(I)$ is contained in a set of the form $V(\p)$ for some minimal prime $\p\in \Min(I)$, which means $\q$ contains a minimal prime.

For (2), we have $V(I) = V(\p_1) \cup \cdots \cup V(\p_n)$; if $V(\p_i)\subseteq \bigcup_{j\neq i} V(\p_j)$, then $\p_i \in V(\p_j)$ for some $j$, so $\p_i \supseteq \p_j$. Thus, our union of closed subsets is irredundant, so $\{V(\p_1),\dots,V(\p_n)\}$ must be the set of irreducible components, and the statement follows.

For (3), since $\Spec(R)$ is Noetherian, any closed set $V(I)$ has finitely many irreducible components, and the statement follows.
\end{proof}

\Feb{25}

As a special case of part (1), the nilpotent elements of a ring $R$ are exactly the elements in every minimal prime of $R$, or equivalently, in every minimal prime of the ideal $(0)$. The ideal $\sqrt{(0)}$ is called the \DEF{nilradical} of $R$. That is,

\begin{rem} If $R$ is Noetherian, then any closed set $V(I)$ is the union of finitely many sets of the form $V(\p)$ for primes $\p$.
\end{rem}


We now wish to understand modules in a similar way. 

\begin{definition}
	If $M$ is an $R$-module, the {\em support}\index{support} of $M$\index{$\Supp(M)$} is 
	$$\Supp(M):=\{ \p \in \Spec(R) \ | \ M_{\p}\neq 0\}.$$
\end{definition}

%\begin{example}
%	If $M=R/I$, then $\Supp(M)=V(I)$. Indeed, $M_{\p}$ is generated by the image of $1$, so $M_{\p}=0$ iff the image of $1$ is zero in the localization. But this happens if and only if $\exists w\notin \p: w\cdot 1=0 \text{ in } R/I \Leftrightarrow \exists w\notin \p, w\in I \Leftrightarrow \p \not\supseteq I$.
%\end{example}



\begin{proposition}\label{supp v ann}
	Given $M$ a finitely generated $R$-module over a ring $R$, 
	$$\Supp(M)=V(\ann_R(M)).$$ 
	In particular, $\Supp(R/I)=V(I)$.
\end{proposition}
\begin{proof}
	Let $M= R m_i + \cdots + R m_n$. We have 
	$$\ann_R(M)=\bigcap_{i=1}^n \ann_R(m_i),$$ 
	so 
	$$V(\ann_R(M))=\bigcup_{i=1}^n V( \ann_R(m_i)).$$ 
	Notice that we need finiteness here.
Also, we claim that 
$$\Supp(M) = \bigcup_{i=1}^n \Supp(R m_i).$$ 
To show $(\supseteq)$, notice that $(R m_i)_{\p} \subseteq M_{\p}$, so
$$\p \in \Supp(R m_i) \implies 0 \neq (R m_i)_\p \subseteq M_\p \implies \p \in \Supp(M).$$

On the other hand, the images of $m_1, \ldots, m_n$ in $M_\p$ generate $M_\p$ for each $\p$, so $\p \in \Supp(M)$ if and only if $\p \in \Supp(R m_i)$ for some $m_i$. Thus, we can reduce to the case of a cyclic module $R m$. Now $\frac{m}{1}=0$ in $M_\p$ if and only if $(R\smallsetminus \p) \cap \ann_R (m) \neq \varnothing$, which happens if and only if $ \ann_R (m)  \not\subseteq \p$.
\end{proof}

The finite generating hypothesis is necessary!

\begin{example}
	Let $K$ be a field, and $R=K[x]$. Take 
	$$M=R_x / R = \bigoplus_{i>0} K \cdot x^{-i}.$$ 
	With this $K$-vector space structure, the action is given by multiplication in the obvious way, then killing any nonnegative degree terms. 
	
	On one hand, we claim that $\Supp(M) = \{(x)\}$. Indeed, any element of $M$ is killed by a large power of $x$, so $W^{-1}M=0$ whenever $x \in W$, so $\Supp(M) \subseteq \{ (x)\}$. Since $\ann_R(x^{-1}) = (x)$, the image of $x^{-1}$ is nonzero in $M_{(x)}$, so $\Supp(M) = \{(x)\}$.
		
	On the other hand, the annihilator of the class of $x^{-n}$ is $x^n$, so 
	$$\ann_R(M) \subseteq \bigcap_{n \geqslant 1}(x^n) = 0.$$
	In particular, $V(\ann_R(M)) = \Spec(R)$.
\end{example}

\begin{example}
	Let $R=\CC[x]$, and $M= \displaystyle\bigoplus_{n\in \ZZ} R/(x-n)$.
	
	First, note that $M_\p = \displaystyle\bigoplus_{n\in \ZZ} (R/(x-n))_{\p}$, so
	$$\Supp(M)= \bigcup_{n\in \ZZ} \Supp(R/(x-n))= \bigcup_{n\in \ZZ} V((x-n))=\{(x-n) \ | \ n \in \ZZ\}.$$

	On the other hand, 
	$$\ann_R(M)=\bigcap_{n\in \ZZ} \ann_R(R/(x-n)) = \bigcap_{n\in \ZZ} (x-n) = 0.$$
	
	Note that in this example the support is not even closed. 
\end{example}



\begin{lemma}\label{nonzero element localizes}
	Let $R$ be a ring, $M$ an $R$-module, and $m\in M$. The following are equivalent:
	\begin{enumerate}
		\item $m=0$ in $M$.
		\item $\frac{m}{1}=0$ in $M_\p$ for all $\p \in \Spec(R)$.
		\item $\frac{m}{1}=0$ in $M_\p$ for all $\p \in \Max(R)$.
	\end{enumerate}
\end{lemma}

\begin{proof}
	The implications $1) \implies 2) \implies 3)$ are clear. If $m\neq 0$, its annihilator is a proper ideal, which is contained in a maximal ideal, so $V(\ann_R m)=\Supp(Rm)$ contains a maximal ideal, so $\frac{m}{1} \neq 0$ in $M_\p$ for some maximal ideal $\p$.
\end{proof}
	
	\begin{exer} If 
	$$\xymatrix{0 \ar[r] & L \ar[r] & M \ar[r] & N \ar[r] & 0}$$ 
	is exact, then $\Supp(L) \cup \Supp(N) = \Supp(M)$. 
\end{exer}

\begin{exer}
	If $M$ is a finitely generated $R$-module,
	\begin{enumerate}
		\item $M=0$.
		\item $M_\p=0$ in $M_\p$ for all $\p \in \Spec(R)$.
		\item $M_\p=0$ in $M_\p$ for all $\p \in \Max(R)$.
	\end{enumerate}
\end{exer}


\ssec{Associated primes}

\begin{definition}
	Let $R$ be a ring, and $M$ a module. We say that $\p\in \Spec(R)$ is an {\em associated prime}\index{associated prime} of $M$ if $\p = \ann_R(m)$ for some $m\in M$. Equivalently, $\p$ is associated to $M$ if there is an injective homomorphism $R/\p \longrightarrow M$. We write $\Ass_R(M)$\index{$\Ass_R(M)$} for the set of associated primes of $M$.
	
	If $I$ is an ideal, by the {\em associated primes}\index{associated primes of an ideal} of $I$ we (almost always) mean the associated primes of $R/I$. To avoid confusion, we will try to write $\Ass_R(R/I)$.
\end{definition}

\begin{lemma}
	If $\p$ is prime, $\Ass_R(R/\p)=\{ \p \}$.
\end{lemma}

\begin{proof}
	For any nonzero $\bar{r}\in R/\p$, we have $\ann_R(\bar{r}) = \{ s\in R \ | \ rs\in \p\} = \p$ by definition of prime ideal.
\end{proof}

\

Let's recall the definition of zerodivisors on $M$.

\begin{definition}
	Let $M$ be an $R$-module. An element $r \in R$ is a {\bf zerodivisor}\index{zerodivisors} on $M$ if $rm = 0$ for some $m \in M$. 
	%So the set of zerodivisors on $M$ is
	%$$\{r \in R \ | \ rm=0 \text{ for some } 0 \neq m\in M \}.$$
\end{definition}

\begin{lemma}\label{associated primes nonzero}\label{zerodivisors associated primes}
	If $R$ is Noetherian, and $M$ is an arbitrary $R$-module, then 
	\begin{enumerate}
		\item For any nonzero $m \in M$, $\ann_R(m)$ is contained in an associated prime of $M$.
		\item $\Ass(M)= \varnothing \Longleftrightarrow M=0$, and
		\item $\bigcup\limits_{\p \in \Ass(M)} \p$ is the set of zerodivisors on $M$.
	\end{enumerate}
%Additionally, if $R$ and $M$ are $\ZZ$-graded and $M\neq 0$, $M$ has an associated prime that is homogeneous.
\end{lemma}
\begin{proof}
\begin{enumerate}
\item  The set of ideals $S := \{ \ann_R(m) \ | \ m\in M, m \neq 0\}$ is nonempty, and any element in $S$ is contained in a maximal element of $S$, by Noetherianity. Let $I=\ann(m)$ be any maximal element, and let $rs\in I$, $s\notin I$. We always have $\ann(sm)\supseteq \ann(m)$, and equality holds by the maximality of $\ann(m)$ in $S$. Then $r(sm)=(rs)m=0$, so $r\in \ann(sm)=\ann(m)=I$. We conclude that $I$ is prime, and therefore it is an associated prime of $M$.

\item	Even if $R$ is not Noetherian, $M = 0$ implies $\Ass(M) = \varnothing$ by definition. So we focus on the case when $M \neq 0$.
	 If $M \neq 0$, then $M$ contains a nonzero element $m$, and $\ann(m)$ is contained in an associated prime of $M$. In particular, $\Ass(M) \neq 0$, and holds. 
	 
\item Now if $r \in \mathcal{Z}(M)$, then by definition we have $r \in \ann(m)$ for some nonzero $m \in M$. Since $\ann(m)$ is contained in some associated prime of $M$, so is $r$. On the other hand, if $\p$ is an associated prime of $M$, then by definition all elements in $\p$ are zerodivisors on $M$.\qedhere
\end{enumerate}
\end{proof}

\Feb{28}

\begin{example}
	If $R$ is not Noetherian, then there may be modules (or ideals even) with no associated primes. Let $R=\bigcup_{n\in \NN} \CC\llbracket x^{1/n} \rrbracket$ be the ring of nonnegatively-valued Puiseux series. We claim that $R/(x)$ is a cyclic module with no associated primes (i.e., the ideal $(x)$ has no associated primes). First, observe that any element of $R$ can be written as a unit times $x^{m/n}$ for some $m,n$, so any associated prime must be an annihilator of $x^{m/n}+(x)$ for some $m\leq n$. We have $\ann(x^{m/n}+(x))=(x^{1-m/n})$, which is not prime, since $(x^{1/2-m/2n})^2 \in (x^{1-m/n})$, but $x^{1/2-m/2n}$.
\end{example}

For Noetherian rings, associated primes also localize.

\begin{theorem}[Associated primes localize in Noetherian rings]
	Let $R$ be a Noetherian ring, $W$ a multiplicative set, and $M$ a module. Then $\Ass_{W^{-1}R}(W^{-1}M)=\{W^{-1}\p  \ | \ \p \in \Ass_R(M), \p \cap W = \varnothing\}$.
\end{theorem}
\begin{proof}
	($\supseteq$): Given $\p \in \Ass_R(M), \p \cap W= \varnothing$, we have that $W^{-1}\p$ is a prime (proper ideal) in $W^{-1}R$. Then $W^{-1}R /W^{-1}\p \cong W^{-1}(R/\p) \hookrightarrow W^{-1}M$ by exactness, so it is associated. 
	
	($\subseteq$): If $W^{-1}\p$ is associated to $W^{-1}M$, there is an embedding 
	\[ W^{-1}(R/\p) (\cong W^{-1}R /W^{-1}\p) \stackrel{i}{\hookrightarrow} W^{-1}M.\]
	 By the Noetherian hypothesis, since $R/\p$ is finitely generated, Hom localizes: $W^{-1} \Hom_R(R/\p,M) \cong \Hom_{W^{-1}R} (W^{-1}R /W^{-1}\p, W^{-1}M)$, so there is some $R/\p \xrightarrow{i'} M$ and $w\in W$ such that $i=w^{-1} \cdot W^{-1}i'$. Let $K=\ker(i')$. Since $W^{-1} K=\ker(W^{-1}i)=0$ by exactness, every element of $K$ is killed by something in $W$. But, $K\subseteq R/\p$, so elements of $W$ act as nonzerodivisors on $K$. Hence, $K=0$. Thus, $R/\p$ injects into $M$, so $\p\in \Ass_R(M)$.
\end{proof}

\begin{prop} Let $R$ be a Noetherian ring and $M$ be an $R$-module.
\begin{enumerate} 
\item $\Supp_R(M) = \bigcup_{\p \in \Ass_R(M)} V(\p)$
\item $\min(\Supp_R(M)) = \min(\Ass_R(M))$
\end{enumerate}
In particular, $\Min(I) = \min(\Ass_R(R/I))$.
\end{prop}
\begin{proof}
\begin{enumerate}
\item We have $\p\in \Supp_R(M)$ iff $M_{\p} \neq 0$ iff $\Ass_{R_\p}(M_\p) \neq \varnothing$ iff $\Ass_R(M) \cap \{ \q\in \Spec(R) \ | \ \q \subseteq \p\} = \varnothing$ iff $M$ contains an associated prime of $M$.
\item Let $\p\in \min(\Supp_R(M))$. Then there is some $\q\in \Ass_R(M)$ with $\q\subseteq \p$. If $\q\subsetneqq \p$, then $\q\in \Supp_R(M)$ contradicts minimality of $\p$, so $\p = \q\in \Ass_R(M)$. If $\p$ is not minimal in $\Ass_R(M)$, it is not minimal in the support, so we must have $\p\in \min(\Ass_R(M))$. On the other hand, for $\p\in \min(\Ass_R(M))$, $\p$ is in the support of $M$. If there is some $\q\in \Supp_R(M)$ with $\q\subsetneqq \p$, then there is some $\mathfrak{r}\in \Ass_R(M)$ with $\mathfrak{r}\subseteq \q$, contradicting minimality of $\p$. Thus, $\p \in \min(\Supp_R(M))$. \qedhere
\end{enumerate}\end{proof}

\begin{defn} For an ideal $I$, we say a prime $\p$ is an \DEF{embedded prime} of $I$ if $\p\in \Ass_R(R/I)\smallsetminus \Min(I)$.
\end{defn}

\begin{lemma}
	If $0\to L \to M \to N \to 0$ is exact, then $\Ass(L) \subseteq \Ass(M) \subseteq \Ass(L) \cup \Ass(N)$.
\end{lemma}
\begin{proof}
	If $R/\p \hookrightarrow L$, then composition with the inclusion $L\hookrightarrow M$ gives $R/\p \hookrightarrow M$. Let $\p\in \Ass(M)\smallsetminus \Ass(L)$, and let $\p=\ann(m)$. Now, every submodule of $Rm$ consists of $0$ and elements with annihilator $\p$, so $Rm\cap L=0$. Thus, $Rm \subseteq M$ bijects onto its image in $N$ in the map $M \to N$, so $R/\p \hookrightarrow N$.
\end{proof}

\Mar{2}


\begin{theorem}
	If $R$ is a Noetherian ring, and $M$ is a finitely generated module, then there exists a \emph{filtration}\index{filtration} of $M$
	\[ M=M_t \supsetneqq M_{t-1} \supsetneqq M_{t-2} \supsetneqq \cdots \supsetneqq  M_1 \supsetneqq M_0 = 0 \]
	such that $M_i / M_{i-1} \cong R/\p_i$ for primes $\p_i\in \Spec(R)$. Such a filtration is called a \emph{prime filtration}\index{prime filtration} of $M$.	
%	If additionally $R$ and $M$ are $\ZZ$-graded, there is a filtration as above with $M_i / M_{i-1} \cong (R/\p_i)(t_i)$ as graded modules for homogeneous primes $\p_i\in \Spec(R)$ and integers $t_i$.
\end{theorem}
\begin{proof}
	If $M\neq 0$, then $M$ has an associated prime, so there is an injection $M_1\cong R/\p_1 \hookrightarrow M$. If $M/M_1\neq 0$, it has an associated prime, so there is an $M_2 \subseteq M$ such that  $M_2/M_1 \cong R/\p_2 \hookrightarrow R/M_1$. Continuing this process, we get a strictly ascending chain of submodules of $M$ where the successive quotients are of the form $R/\p_i$. If we do not have $M_t=M$ for some $t$, then we get an infinite strictly ascending chain of submodules of $M$, which contradicts that $M$ is a Noetherian module.
\end{proof}

\begin{corollary}
	If $R$ is a Noetherian ring, and $M$ is a finitely generated module, and \[M=M_t \supsetneqq M_{t-1} \supsetneqq M_{t-2} \supsetneqq \cdots \supsetneqq  M_1 \supsetneqq M_0 = 0\] is a prime filtration of $M$ with $M_i/M_{i-1}\cong R/\p_i$ then \[\Ass_R(M)\subseteq \{ \p_1, \dots, \p_t \}.\]
	Consequently, $\Ass_R(M)$ is finite.
\end{corollary}
\begin{proof}
For each $i$, we have $\Ass(M_i) \subseteq \Ass(M_{{i-1}})\cup \Ass(M_i/M_{i-1}) = \Ass(M_{{i-1}}) \cup \{\p_i\}$ so that, inductively, $\Ass(M_i)\subseteq\{\p_1,\dots,\p_i\}$. The consequencenfollows from the previous theorem.
\end{proof}



\begin{lemma}[Prime avoidance]\index{prime avoidance} Let $R$ be a ring, $I_1,\dots,I_n,J$ be ideals, and suppose that $I_i$ is prime for $i>2$ (at most two are not prime). 
	
	If $J\not\subseteq I_i$ for all $i$, then $J\not\subseteq \bigcup_i I_i$; equivalently, if $J\subseteq \bigcup_i I_i$, then $J\subseteq I_i$ for some $i$.
	
	Moreover, if $R$ is $\NN$-graded, and all of the ideals are homogeneous, all $I_i$ are prime, and $J\not\subseteq I_i$ for all $i$, then there is a homogeneous element in $J \smallsetminus \bigcup_i I_i$.
\end{lemma}
\begin{proof} 
	We proceed by induction on $n$. If $n=1$, there is nothing to show.
	
	By induction hypothesis, we can find elements $a_i \in J \smallsetminus \bigcup_{j\neq i} I_j$ for each $i$. If some $a_i\notin I_i$, we are done, so suppose that $a_i\in I_i$ for each $i$. Consider $a= a_n + a_1 \cdots a_{n-1}$. This belongs to $J$. If $a\in I_i$ for $i<n$, then, since $a_1\cdots a_{n-1}=a_i(a_1\cdots \widehat{a_i} \cdots a_{n-1})\in I_i$, we also have $a_n\in I_i$, a contradiction. If $a\in I_n$, then, since $a_n\in I_n$, we also have $a_1\cdots a_{n-1}\in I_n$. If $n=2$, this says $a_1\in I_2$, a contradiction. If $n>2$, then $I_n$ is prime, so one of $a_1,\dots,a_{n-1}\in I_n$, a contradiction.
	
	If all $I_i$ are homogeneous and prime, we proceed as above, replacing $a_n$ and $a_1,\dots,a_{n-1}$ with suitable powers (e.g., $|a_1| + \cdots + |a_{n-1}|$ and $|a_n|$ each, respectively) so that $a_n + a_1 \cdots a_{n-1}$ is homogeneous. The primeness assumption guarantees that noncontainments in ideals is preserved.
\end{proof}

\begin{corollary}
	Let $I$ be an ideal and $M$ a finitely generated module over a Noetherian ring $R$. If $I$ consists of zerodivisors on $M$, then $Im=0$ for some $m\in M$.
\end{corollary}
\begin{proof}
	We have that $I\subseteq \bigcup_{\p \in \Ass(M)}(\p)$. By the assumptions, this is a finite set of primes. By prime avoidance, $I \subseteq \p$ for some $\p \in \Ass(M)$. That is $I\subseteq \ann_R(m)$ for some $m\in M$.
\end{proof}

\Mar{4}

\ssec{Primary decomposition}

We refine our decomposition theory once again, and introduce primary decompositions of ideals. 
\begin{definition}
	We say that an ideal is {\em primary}\index{primary ideal} if 
	$$xy\in I \implies x\in I \text{ or } y\in \sqrt{I}.$$
	We say that an ideal is {\em $\p$-primary}\index{$\p$-primary ideal}, where $\p$ is prime, if $I$ is primary and $\sqrt{I}=\p$.
\end{definition}

\begin{remark}
	Note that a primary ideal has indeed a prime radical: if $Q$ is primary, and $xy\in \sqrt{Q}$, then $x^n y^n\in Q$ for some $n$. If $y\notin \sqrt{Q}$, then we must have $x^n\in Q$, so $x\in \sqrt{Q}$. Thus, every primary ideal $Q$ is $\sqrt{Q}$-primary.
\end{remark}


\begin{example}$\,$\label{example primary ideals}
	\begin{enumerate}
		\item Any prime ideal is also primary.
		\item If $R$ is a UFD, we claim that a principal ideal is primary if and only if it is generated by a power of a prime element. Indeed, if $a=f^n$, with $f$ irreducible, then 
		$$xy\in (f^n) \Longleftrightarrow f^n | xy \Longleftrightarrow f^n | x \text{ or } f| y \Longleftrightarrow x\in (f^n) \text{ or } y\in \sqrt{(f^n)} = (f).$$ 
		Conversely, if $a$ is not a prime power, then $a=gh$, for some $g$, $h$ nonunits with no common factor, then take $gh\in (a)$ but $g\notin a$ and $h\notin \sqrt{(a)}$.
		\item As a particular case of the previous example, the nonzero primary ideals in $\mathbb{Z}$ are of the form $(p^n)$ for some prime $p$ and some $n \geqslant 1$. This example is a bit misleading, as it suggests that primary ideals are the same as powers of primes. We will soon see that it not the case.
		\item\label{example powers primary} In $R=k[x,y,z]$, the ideal $I=(y^2,yz,z^2)$ is primary. Give $R$ the grading with weights $|y|=|z|=1$, and $|x|=0$. If $g\notin \sqrt{I}=(y,z)$, then $g$ has a degree zero term. If $f\notin I$, then $f$ has a term of degree zero or one. The product $fg$ has a term of degree zero or one, so is not~in~$I$.
	\end{enumerate}
\end{example}

If the radical of an ideal is prime, that does not imply that ideal is primary.
\begin{example}\label{example radical prime but not primary}
In $R=k[x,y,z]$, the ideal $\q=(x^2,xy)$ is not primary, even though $\sqrt{\q}=(x)$ is prime. The offending product is $xy$.	
\end{example}

The definition of primary can be reinterpreted in many forms.

\begin{proposition}\label{characterization of primary}
The following are equivalent:
	\begin{enumerate}
		\item $\q$ is primary.
		\item Every zerodivisor in $R/\q$ is nilpotent on $R/\q$.
	
		\item $\sqrt{\q} = \p$ is prime and for all $r, w \in R$ with $w\notin \p$, $rw\in \q$ implies $r\in \q$.
		\item $\sqrt{\q}= \p$ is prime, and $\q R_{\p} \cap R = \q$.
	\end{enumerate}
	If $R$ is Noetherian, then these are also equivalent to:
	\begin{enumerate}
	\setcounter{enumi}{4}
		\item $\Ass(R/\q)$ is a singleton.
		\item $\q$ has exactly one minimal prime, and no embedded primes.
		\end{enumerate}
\end{proposition}
\begin{proof}
	$(1) \iff (2)$: $y$ is a zerodivisor mod $\q$ if there is some $x\notin \q$ with $xy\in \q$; the primary assumption translates to a power of $y$ is in $\q$.
	
	
	$(1) \iff (3)$: Given the observation that the radical of a primary ideal is prime, this is just a rewording of the definition.
	
	$(3) \iff (4)$: We already know this from the discussion on behavior of ideals in localizations, which says that
	$$\q R_\p \cap R = \lbrace r \in R \mid rs \in \q \textrm{ for some } s \notin \p \rbrace.$$
	
		$(2) \iff (5)$: On the one hand, (2) says that the set of zerodivisors on $R/\q $ and coincide with the elements in the nilradical of $R/\q$. These agree with the union of all the associated primes and the intersection of all the minimal primes respectively.
	$$\bigcup_{\p \in \Ass(R/\q)} \p \, = \, \{\textrm{zerodivisors on}\  (R/\q)\} \, =  \{ r \in R \mid r + \q \in \textrm{nilradical of} \ (R/\q) \} \, = \bigcap_{\p \in \Min(\q)} \p = \bigcap_{\p \in \Ass(R/\q)} \p.$$
	This holds if and only if there is only one associated prime.
	
	$(5) \iff (6)$ follows from the definitions.
\end{proof}


If the radical of an ideal is maximal, that \emph{does} imply the ideal is primary.

\begin{remark} 
Let $I$ be an ideal with $\sqrt{I}=\fm$ a maximal ideal. If $R$ is Noetherian, then $\Ass_R(R/I)$ is nonempty and contained in $\Supp(R/I)=V(I)=\{\fm\}$, so $\Ass_R(R/I) =\fm$, and hence $I$ is primary.
\end{remark}

Note that the assumption that $\fm$ is maximal was necessary here. Indeed, having a prime radical does not guarantee an ideal is primary, as we saw above Moreover, even the powers of a prime ideal may fail to be primary.

\begin{example}\label{powers of prime not primary}
	Let $R = k[x,y,z]/(xy-z^n)$, where $k$ is a field and $n \geqslant 2$ is an integer. Consider the prime ideal $P = (x,z)$ in $R$, and note that $y \notin P$. On the one hand, $xy = z^n \in P^n$, while $x \notin P^n$ and $y \notin \sqrt{P^n} = P$. Therefore, $P^n$ is not a primary ideal, even though its radical is the prime $P$.
\end{example}


The contraction of primary ideals is always primary.

\begin{remark}\label{contraction of primary ideals is primary}
	 Given any ring map $\xymatrix{R \ar[r]^-\phi & S}$, and a primary ideal $Q$ in $S$, then the contraction of $Q$ in $R$ (via $f$) $Q \cap R$ is always primary. Indeed, if $xy \in Q \cap R$, and $x \notin Q \cap R$, then $\phi(x) \notin Q$, so $\phi(y^n) = \phi(y)^n \in Q$ for some $n$. Therefore, $y^n \in Q \cap R$, and $Q \cap R$ is indeed primary.
\end{remark}

\begin{lemma}\label{lemma intersections primary}
	If $I_1,\dots,I_t$ are ideals, then 
	$$\Ass \left( R/ \bigcap_{j=1}^t I_j \right) \subseteq \bigcup_{j=i}^t \Ass(R/I_j).$$ 
	In particular, a finite intersection of $\p$-primary ideals is $\p$-primary.
\end{lemma}
\begin{proof}
	There is an inclusion $R/(I_1 \cap I_2) \subseteq R/I_1 \oplus R/I_2$. Hence, $\Ass(R/(I_1\cap I_2)) \subseteq \Ass(R/I_1) \cup \Ass(R/I_2)$; the statement for larger $t$ is an easy induction.
	
	If the $I_j$ are all $\p$-primary, then
	$$\Ass(R/(\bigcap_{j=1}^t I_j)) \subseteq \bigcup_{j=i}^t \Ass(R/I_j) = \{ \p \}.$$
	On the other hand, $\bigcap_{j=1}^t I_j \subseteq I_1 \neq R$, so $R/(\bigcap_{j=1}^t I_j) \neq 0$. Thus $\Ass(R/(\bigcap_{j=1}^t I_j))$ is nonempty, and therefore the singleton $\{ \p \}$. Then $\bigcap_{j=1}^t I_j$ is $\p$-primary by the characterization of primary in \ref{characterization of primary} (3) above.
\end{proof}

\begin{definition}[Primary decomposition]	
A {\em primary decomposition}\index{primary decomposition} of an ideal $I$ is an expression of the form 
	\[I = \q_1 \cap \cdots \cap \q_t,\] with each $\q_i$ primary. A {\em minimal primary decomposition} of an ideal $I$ is a primary decomposition as above in which $\sqrt{\q_i}\neq \sqrt{\q_j}$ for $i\neq j$, and $\q_i \not\supseteq \displaystyle\bigcap_{j\neq i} \q_j$ for all $i$.\end{definition}

\begin{remark} 
By the previous lemma, we can turn any primary decomposition into a minimal one by combining the terms with the same radical, then removing redundant terms.
\end{remark}

\Mar{7}

\begin{example}[Primary decomposition in $\mathbb{Z}$]
	Given a decomposition of $n \in \mathbb{Z}$ as a product of distinct primes, say $n = p_1^{a_1} \cdots p_k^{a_k}$, then the primary decomposition of the ideal $(n)$ is $(n) = (p_1^{a_1}) \cap \cdots \cap (p_k^{a_k})$. Note that primary is not the same is prime power in general.
\end{example}


\begin{ex} If $R$ is Noetherian and $I$ is a radical ideal, then $I=\p_1 \cap \cdots \cap \p_n$ for the minimal primes $\p_i$ of $I$. This is a minimal primary decomposition of $I$.
\end{ex}

The existence of primary decompositions was first shown by Emanuel Lasker for polynomial rings and power series rings in 1905, and then extended to what we now call Noetherian rings by Emmy Noether in 1921.  It will be useful to consider the following notion in the proof.

\begin{defn} An ideal $I$ is \emph{irreducible}\index{irreducible ideal} if there do not exist ideals $J_1,J_2\supsetneqq I$ such that $J_1 \cap J_2 = I$.
\end{defn}



\begin{theorem}[Existence of primary decompositions]
Let $R$ be a Noetherian ring.
\begin{enumerate}
\item Every irreducible ideal is primary.
\item Every ideal can be written as a finite intersection of irreducible ideals.
\end{enumerate}
Thus, every ideal of $R$ admits a primary decomposition.
\end{theorem}
\begin{proof}
\begin{enumerate}
\item To prove the contrapositive, suppose that $\q$ is not primary, and take $xy\in \q$ with $x\notin \q$, $y\notin \sqrt{\q}$. The ascending chain of ideals 
	$$(\q : y) \subseteq (\q : y^2) \subseteq (\q : y^3) \subseteq \cdots$$
	stabilizes for some $n$, since $R$ is Noetherian. This means that $y^{n+1} f\in \q \implies y^n f\in \q$. We will show that 
	$${(\q+(y^n))\cap( \q+(x)) = \q},$$ 
	proving that $\q$ is not irreducible.
	
	The containment $\q\subseteq (\q+(y^n))\cap( \q+(x))$ is clear. On the other hand, if 
	$$a \in (\q+(y^n))\cap( \q+(x)),$$ 
	we can write $a=q+by^n$ for some $q\in \q$, and 
	$$a\in \q + (x) \implies ay \in \q + (xy) = \q.$$
	So
	$$b y^{n+1} = ay - aq \in \q \implies b \in (\q : y^{n+1}) = (\q : y^n).$$
	
	By definition, this means that $by^n \in \q$, and thus $a = q+by^n \in \q$. This shows that $\q$ is not irreducible, concluding the proof. 
	
	\item  If the set of ideals that are not a finite intersection of irreducibles were nonempty, then by Noetherianity there would be an ideal maximal with the property of not being an intersection of irreducible ideals. Such a maximal element must be an intersection of two larger ideals, each of which are finite intersections of irreducibles, giving a contradiction. \qedhere
\end{enumerate}
\end{proof}

\begin{ex}
There are primary ideals that are not irreducible. For example, $(x^2,y) \cap (x,y^2) = (x^2,xy,y^2)$.
\end{ex}


Primary decompositions, even minimal ones, are not unique.


\begin{example}
	Let $R=K[x,y]$, where $K$ is a field, and $I=(x^2,xy)$. We can write
	\[ I = (x) \cap (x^2,xy,y^2) = (x) \cap (x^2,y). \]
	These are two different minimal primary decompositions of $I$. To check this, we just need to see that each of the ideals $(x^2,xy,y^2)$ and $(x^2,y)$ are primary. Observe that each has radical $\fm=(x,y)$, which is maximal, so by an earlier remark, these ideals are both primary. In fact, our ideal $I$ has infinitely many minimal primary decompositions: given any $n \geqslant 1$, 
	$$I = (x) \cap (x^2, xy, y^n)$$ 
	is a minimal primary decomposition. One thing all of these have in common is the radicals of the primary components: they are always $(x)$ and $(x,y)$.
\end{example}


In the previous example, the fact that all our minimal primary decompositions had primary components always with the same radical was not an accident. Indeed, there are some aspects of primary decompositions that are unique, and this is one of them.



\begin{theorem}[First uniqueness theorem for primary decompositions]\label{uniqueness primary decomposition associated primes}
	Suppose $I$ is an ideal in a Noetherian ring $R$. Given any minimal primary decomposition of $I$, say 
	$$I = \q_1 \cap \cdots \cap \q_t,$$ 
	we have 
	$$\{ \sqrt{\q_1},\dots,\sqrt{\q_t}\}=\Ass(R/I).$$ 
	In particular, this set is the same for all minimal primary decompositions of $I$.
\end{theorem}

\begin{proof}
	For any primary decomposition, minimal or not, we have 
	$$\Ass(R/I) \subseteq \bigcup_i \Ass(R/\q_i) = \{ \sqrt{\q_1},\dots,\sqrt{\q_t}\}$$ 
	from the lemma on intersections we proved. We just need to show that in a minimal decomposition as above, every $\p_j  := \sqrt{\q_j}$ is an associated prime.
	
	So fix $j$, and let 
	$$I_j = \displaystyle\bigcap_{i\neq j} \q_i \supseteq I.$$
	Since the decomposition is minimal, the module $I_j/I$ is nonzero, hence it has an associated prime, say $\mathfrak{a}$. Since $I_j / I \subseteq R/I$, we have $\mathfrak{a} \in \Ass_R(R/I)$ as well. Fix $x_j\in R$ such that $\mathfrak{a}$ is the annihilator of $\overline{x_j}$ in $I_j/I$. Since 
	$$\q_j x_j \subseteq \q_j \cdot \displaystyle\bigcap_{i\neq j} \q_i \subseteq \q_1 \cap \cdots \cap \q_n = I,$$ 
	we conclude that $\q_j$ is contained in the annihilator of $\overline{x_j}$, meaning $\q_j \subseteq \mathfrak{a}$. Since $\p_j$ is the unique minimal prime of $\q_j$ and $\mathfrak{a}$ is a prime containing $\q_j$, we must have $\p_j \subseteq \mathfrak{a}$. On the other hand, if $r\in \mathfrak{a}$, we have $rx_j\in I \subseteq \q_j$, and since $x_j\notin \q_j$, we must have $r\in \p_j = \sqrt{\q_j}$ by the definition of primary ideal. Thus $\mathfrak{a} \subseteq \p_j$, so $\mathfrak{a} = \p_j$. This shows that $\p_j$ is an associated prime of $R/I$.
\end{proof}

We note that if we don't assume that $R$ is Noetherian, we may or may not have a primary decomposition for a given ideal. It is true that if an ideal $I$ in a general ring has a primary decomposition, then the primes occurring are the same in any minimal decomposition. However, they are not the associated primes of $I$ in general; rather, they are the primes that occur as radicals of annihilators of elements.

\

There is also a partial uniqueness result for the actual primary ideals that occur in a minimal decomposition.

\begin{theorem}[Second uniqueness theorem for primary decompositions]\label{primary decomposition uniqueness minimal components}
	If $I$ is an ideal in a Noetherian ring $R$, then for any minimal primary decomposition of $I$, say $I = \q_1 \cap \cdots \cap \q_t$, the set of \emph{minimal components} $\{ \q_i \ | \ \sqrt{\q_i} \in \Min(R/I)\}$ is the same. Namely, $\q_i = I R_{\sqrt{\q_i}} \cap R$.
\end{theorem}

\Mar{9}

\begin{proof}
	We observe that for a  $\p$-primary ideal $\q$ and a prime $\mathfrak{a}$ 
	\[ \Ass_{R_\mathfrak{a}} (R_\mathfrak{a} / \q_\mathfrak{a}) = \begin{cases} \p_\mathfrak{a} & \text{if} \ \p \subseteq \mathfrak{a} \\ \varnothing & \text{if} \ \p \not\subseteq \mathfrak{a}\end{cases}. \]
	
	Now, since finite intersections commute with localization, then for any prime $\mathfrak{a}$,
	\[ I_{\mathfrak{a}} = (\q_1)_{\mathfrak{a}} \cap \cdots \cap (\q_t)_{\mathfrak{a}}\]
	is a primary decomposition, although not necessarily minimal. In a minimal decomposition, choose a minimal prime $\mathfrak{a}=\p_i$. Then when we localize at $\mathfrak{a}$, all the other components become the unit ideal since their radicals are not contained in $\p_i$, and thus $I_{\p_i} = (\q_i)_{\p_i}$. We can then contract to $R$ to get $I_{\p_i} \cap R = (\q_i)_{\p_i} \cap R = \q_i$, since $\q_i$ is $\p_i$-primary.
\end{proof}



\begin{cor} If $I$ has no embedded primes, then the primary decomposition of $I$ is unique.
\end{cor}


	\begin{example}
	Let  $R=\mathbb{Z}[\sqrt{-5}]$, where some elements can be written as products of irreducible elements in more than one way. For example,
	$$6 = 2 \cdot 3 = (1 + \sqrt{-5}) (1 - \sqrt{-5}).$$
	We can write $(6) = (2) \cap (3)$, since $2$ and $3$ are comaximal. Note that 
	\[	R/(2) \cong \frac{\Z[x]}{(x^2 + 5,2)} \cong \frac{\F_2[x]}{(x^2 + 1)} \cong \frac{\F_2[x]}{(x+ 1)^2}.\]
	Thus, this ideal has one minimal prime, given by $(x+1)$ on the right, which is $(2,1+\sqrt{-5})$ in $R$. This ideal is maximal, since the quotient is isomorphic to $\F_2$, so $(2)$ is $(2,1+\sqrt{-5})$-primary.
Now note that 
\[	R/(3) \cong \frac{\Z[x]}{(x^2 + 5,3)} \cong \frac{\F_3[x]}{(x^2 - 1)} \cong \frac{\F_3[x]}{(x+ 1)(x-1)}.\]
The ideals $(x-1)$, $(x+1)$ are the minimal primes of the ring on the right, so $(3,1+\sqrt{-5})$ and $(3, 1-\sqrt{-5})$ are the minimal primes of $(3)$, and intersect to $(3)$.

We conclude that \[ (6) = (2) \cap (3,1+\sqrt{-5}) \cap (3, 1-\sqrt{-5}) \]
is the unique minimal primary decomposition of $(6)$.
	\end{example}



Finally, we note that the primary decompositions of powers of ideals are especially interesting.


\begin{definition}[Symbolic power]
	If $\p$ is a prime ideal in a ring $R$, the {\em $n$th symbolic power}\index{symbolic power}\index{$\p^{(n)}$} of $\p$ is $\p^{(n)} := \p^n R_{\p} \cap R$.
\end{definition}

This admits equivalent characterizations.

\begin{proposition}
	Let $R$ be Noetherian, and $\p$ a prime ideal of $R$. 
	\begin{enumerate}
		\item $\p^{(n)}=\{ r\in R \ \mid \ rs\in \p^n \textrm{ for some }  s\notin \p \}$.
		\item $\p^{(n)}$ is the unique smallest $\p$-primary ideal containing $\p^n$.
		\item $\p^{(n)}$ is the $\p$-primary component in any minimal primary decomposition of $\p^n$.
	\end{enumerate} 
\end{proposition}

\begin{proof}
	The first characterization follows from the definition, and the fact that expanding and contraction to/from a localization is equivalent to saturating with respect to the multiplicative set.
	
	We know that $\p^{(n)}$ is $\p$-primary from one of the characterizations of primary. Any $\p$-primary ideal satisfies $\q R_{\p} \cap R = \q$, and if $\q\supseteq \p^{n}$, then $\p^{(n)} = \p^n R_{\p} \cap R \subseteq \q R_{\p} \cap R = \q$. Thus, $\p^{(n)}$ is the unique smallest $\p$-primary ideal containing $\p^n$.
	
	The last characterization follows from the second uniqueness theorem.
\end{proof}

In particular, note that $\p^n = \p^{(n)}$ if and only if $\p^n$ is primary.

\begin{example}$\,$
	\begin{enumerate}
		\item In $R=k[x,y,z]$, the prime $\p=(y,z)$ satisfies $\p^{(n)}=\p^n$ for all $n$. This follows along the same lines as above.
		\item In $R=k[x,y,z]=(xy-z^n)$, where $n \geqslant 2$, we have seen that the square of $\p=(y,z)$ is not primary, and therefore $\p^{(2)}\neq \p^2$. Indeed, $xy=z^n \in \p^2$, and $x\notin \p$, so $y\in \p^{(2)}$ but $y \notin \p^2$.
	%	\item Let $X=X_{3\times 3}$ be a $3\times 3$ matrix of indeterminates, and $k[X]$ be a polynomial ring over a field~$k$. Let $\p=I_2(X)$ be the ideal generated by $2\times 2$ minors of $X$. Write $\Delta_{\substack{i|k \\j |l}}$ for the determinant of the submatrix with rows $i,j$ and columns $k,l$. We find
%		\[\begin{aligned} x_{11} \det(X) = & \, x_{11}x_{31} \Delta_{\substack{1|2 \\2 |3}} - x_{11}x_{32} \Delta_{\substack{1|1 \\2 |3}} + x_{11}x_{33} \Delta_{\substack{1|1 \\2 |2}} \\
%		=& \, (x_{11}x_{31} \Delta_{\substack{1|2 \\2 |3}} - x_{11}x_{32} \Delta_{\substack{1|1 \\2 |3}} + x_{11}x_{33} \Delta_{\substack{1|1 \\2 |2}} ) \\
%		-&\, (x_{11}x_{31} \Delta_{\substack{1|2 \\2 |3}} - x_{12}x_{31} \Delta_{\substack{1|1 \\2 |3}} + x_{13}x_{31} \Delta_{\substack{1|1 \\2 |2}} )\\
%		=&\,  -\Delta_{\substack{1|1 \\3 |2}} \Delta_{\substack{1|1 \\2 |3}} + \Delta_{\substack{1|1 \\3 |3}} \Delta_{\substack{1|1 \\2 |2}}\in I_2(X)^2.
%		\end{aligned}\]
%		Note that in the second row, we subtracted the Laplace expansion of the determinant of the matrix with row 3 replaced by another copy of row 1. That is, we subtracted zero.
	\end{enumerate}
\end{example}

\Mar{11}

\sec{Local rings and NAK}


\begin{definition}
	A ring $R$ is called a \emph{local ring}\index{local ring} if it has exactly one maximal ideal. We often use the notation $(R,\m)$\index{$(R,\m)$} to denote $R$ and its maximal ideal, or $(R,\m,k)$\index{$(R,\m,k)$} to also specify the residue field $k=R/\m$. Some people reserve the term \emph{local ring} for a Noetherian local ring, and call what we have defined a \emph{quasilocal ring}\index{quasilocal ring}; we will not follow this convention here.\end{definition}

An easy equivalent characterization is that $R$ is local if and only if the set of nonunits of $R$ forms an ideal: this must then be the unique maximal ideal.

The following remark is an easy source of local rings.
\begin{remark}
	If $R$ is a ring and $\p$ is a prime ideal, then $(R_\p,\p R_\p)$ is a local ring. Indeed, the primes of $R_\p$ are just the expansions of primes of $R$ that are contained in $\p$. In $R$, $\p$ is uniquely maximal among primes contained in $\p$.
\end{remark}


\begin{example}
	\begin{enumerate}
		\item The ring $\ZZ/(p^n)$ is local with maximal ideal $(p)$.
		\item The ring $\Z_{(p)} = \{ \frac{a}{b} \in \Q \ | \ p\nmid b \text{ when in lowest terms}\}$ is a local ring with maximal ideal $(p)$.
		\item The ring of power series $K\llbracket \vx \rrbracket$ over a field $K$ is local. Indeed, a power series has an inverse if and only if its constant term is nonzero. The complement of this set of units is an ideal (the ideal $(\vx)$).
		\item The ring of complex power series holomorphic at the origin, $\CC\{ \vx \}$ is local. In the above setting, one proves that the series inverse of a holomorphic function at the origin is convergent on a neighborhood of $0$.
		\item A polynomial ring over a field is certainly not local; you know so many maximal ideals! A local ring we will often encounter is $K[x_1,\dots,x_d]_{(x_1,\dots,x_d)}$. We can consider this as the ring of rational functions that in lowest terms have a denominator with nonzero constant term. (We can talk about lowest terms since the polynomial ring is a UFD.)
		\item Extending the following example, we have local rings like $(K[x_1,\dots,x_d]/I)_{(x_1,\dots,x_d)}$. If $K$ is algebraically closed and $I$ is a radical ideal, then $K[x_1,\dots,x_d]/I= K[X]$ is the coordinate ring of some affine variety, and $(x_1,\dots,x_d)=\m_{\underline{0}}$ is the ideal defining the origin (as a point in $X \subseteq K^d$). Then we call $(K[x_1,\dots,x_d]/I)_{(x_1,\dots,x_d)}=K[X]_{\m_{\underline{0}}}$ the \emph{local ring of the point}\index{local ring of a point} $\underline{0} \in X$; some people write $\mathcal{O}_{X,\underline{0}}$. The radical ideals of this ring consist of radical ideals of $K[X]$ that are contained in $\m_{\underline{0}}$, which by the Nullstellensatz correspond to subvarieties of $X$ that contain $\underline{0}$.
	\end{enumerate}
\end{example}

%We want to make a quick observation about local rings: let $(R,\m,k)$ be local. Since $k$ is a quotient of $R$, the characteristic of $R$ must be a multiple of the characteristic of $k$; the kernel of the map from $\ZZ$ can only get bigger in the composition. Of course, with example 2 in mind, we must think of $0$ as a multiple of any integer for this to make sense. Now $k$ is a field, so its characteristic is $0$ or $p$ for a prime $p$. If $\Char(k)=0$, then necessarily $\Char(R)=0$. If $\Char(k)=p$, we claim that $\Char(R)$ must be either $0$ or a power of $p$. Indeed, if we write $\Char(R)=p^n \cdot m$ with $m$ coprime to $p$, note that $p\in \m$, so if $m\in \m$, we have $1\in (p,m)\subseteq \m$, which is contradiction. Since $R$ is local, this means that $m$ is a unit. But then, $p^n m=0$ implies $p^n=0$, so the characteristic must be $p^n$. We summarize and add one more observation.

%\begin{proposition}
%	Let $(R,\m,k)$ be a local ring. Then one of the following holds:\begin{enumerate}
%		\item $\Char(R)=\Char(k)=0$. We say that $R$ has \emph{equal characteristic zero}\index{equal characteristic zero}.
%		\item $\Char(R)=0$, $\Char(k)=p$ for a prime $p$. We say that $R$ has \emph{mixed characteristic $(0,p)$}\index{mixed characteristic $(0,p)$}.
%		\item $\Char(R)=\Char(k)=p$ for a prime $p$. We say that $R$ has \emph{equal characteristic $p$}\index{equal characteristic $p$}.
%		\item $\Char(R)=p^n$, $\Char(k)=p$ for a prime $p$ and an integer $n>1$.
%	\end{enumerate}
%	If $R$ is reduced, then one of the first three cases holds.
%\end{proposition}



There are a range of statements the go under the banner of Nakayama's Lemma a.k.a. NAK. 

\begin{proposition}
	Let $R$ be a ring, $I$ an ideal, and $M$ a finitely generated $R$-module. 
	If $IM = M$, then 
	\begin{itemize}
		\item there is an element $r\in 1 + I$ such that $rM=0$, and
		\item there is an element $a\in I$ such that $am=m$ for all $m\in M$.
	\end{itemize}
\end{proposition}
\begin{proof}
	Let $m_1,\dots,m_s$ be a generating set for $M$. By assumption, we have equations
	\[ m_1 = a_{11} m_1 + \cdots + a_{1s} m_s \ , \ \dots \ , \ m_s = a_{s1} m_1 + \cdots + a_{ss} m_s,\]
	with $a_{ij}\in I$. Setting $A=[a_{ij}]$ and $v=[x_i]$ we have a matrix equations $Av=v$, and hence $(\mathrm{id} - A)v=0$. By the adjoint trick, we have $\det(\mathrm{id} - A)$ kills each $m_i$, and hence $M$. Since $\det(\mathrm{id}-A)\equiv \det(\mathrm{id})  \equiv 1 \,\mathrm{mod}\, I$, this determinant is the element $r$ we seek for the first statement.
	
	For the latter statement, set $a=1-r$; this is in $I$ and satisfies $am=m-rm=m$ for all $m\in M$.
\end{proof}

%\begin{example}
%	We will use this to give a quick proof of the fact that, if $M$ is a finitely generated $R$-module, and $\varphi:M \to M$ is a surjective $R$-linear endomorphism, then $\varphi$ is an isomorphism. In this setting, $M$ is an $R[x]$-module by the rule $x m = \varphi(m)$, $x^2 m = \varphi^2(m)$, etc. The hypothesis that $\varphi$ is surjective says that $x M = M$. Then, some element of $(x)$ acts as the identity on $M$: $f(x) x$ is the identity, so $ f(\varphi)\circ \varphi $ is the identity. Thus, $\varphi$ is an isomorphism.
%\end{example}

\begin{proposition}
	Let $(R,\m,k)$ be a local ring, and $M$ be a finitely generated module. If $M=\m M$, then $M=0$.
\end{proposition}
\begin{proof}
	By the previous lemma, there exists an element $r\in 1+\m$ that annihilates $M$. Such an $r$ must be a unit, so $1$ annihilates $M$; i.e., $M=0$.
\end{proof}

\begin{proposition}
	Let $(R,\m,k)$ be a local ring, and $M$ be a finitely generated module. For $m_1,\dots,m_s\in M$,
	\[ m_1,\dots, m_s \text{ generate } M \Longleftrightarrow \overline{m_1},\dots,\overline{m_s} \text{ generate } M/\m M.\] Thus, any generating set for $M$ consists of at least $\dim_k (M/\m M)$ elements.
\end{proposition}
\begin{proof} The implication $\Rightarrow$ is clear.
	Let $N=\langle m_1,\dots, m_s \rangle \subseteq M$. We have that $M/N=0$ iff $M/N= \m(M/N)$ iff $M= \m M + N$ iff $M/\m M$ is generated by the image of $N$.
\end{proof}

\begin{definition}
	Let $(R,\m)$ be a local ring, and $M$ a finitely generated module. A set of elements $\{m_1,\dots,m_t\}$ is a \emph{minimal generating set}\index{minimal generators} of $M$ if the images of $m_1,\dots,m_t$ form a basis for the $R/\m$ vector space $M/\m M$.
\end{definition}

Observe that any generating set for $M$ contains a minimal generating set, and that every minimal generating set has the same cardinality.

%We now want to give graded analogues for the results above.

%\begin{proposition} Let $R$ be an $\NN$-graded ring, and $M$ a $\ZZ$-graded module such that $[M]_{<a}=0$ for some $a$. If $M= (R_+) M$, then $M=0$.

%In particular, if $M$ is a finitely generated $\ZZ$-graded module and $M= (R_+) M$, then $M=0$.
%\end{proposition}
%\begin{proof}
%	If $M$ is finitely-generated, then it can be generated by finitely generated homogeneous elements (the homogeneous pieces of some finite generating set); thus the first statement implies the second. 
	
%	  $M$ lives in degrees at least $a$, but $(R_+)M$ lives in degrees strictly bigger than $a$. If $M$ has a nonzero element, it has a nonzero homogeneous element, and we obtain a contradiction.
%\end{proof}



%Just as above, we obtain the following:

%\begin{proposition}
%	Let $R$ be an $\NN$-graded ring, with $R_0$ a field, and $M$ a $\ZZ$-graded module such that $[M]_{<a}=0$ for some $a$. A set of elements of $M$ generates $M$ if and only if their images in $M/(R_+)M$ spans as a vector space. Since $M$ and $(R_+)M$ are graded, $M/(R_+)M$ admits a basis of homogeneous elements.
%\end{proposition}

%In particular, if $K$ is a field, $R$ is a positively graded $K$-algebra, and $I$ is a homogeneous ideal, then $I$ has a minimal generating set by homogeneous elements, and this set is unique up to $K$-linear combinations. 

%Note that we can use NAK to prove that certain modules are finitely generated in the graded case; in the local case, we cannot.

%We want to prove one more important fact about Noetherian local rings. We prepare with a lemma.



\begin{lemma}[Radical lemma for finitely generated ideals]
	If $I \subseteq J$ are ideals, $J\subseteq \sqrt{I}$ and $J$ is finitely generated, then there is some $n$ with $J^n \subseteq I$.
	
	Thus, if $R$ is Noetherian, for every ideal $I$, there is some $n$ with $\sqrt{I}^n \subseteq I$.
\end{lemma}
\begin{proof}
	Write $J=(f_1,\dots,f_m)$. By definition, there are $a_1,\dots,a_m$ with $f_i^{a_i}\in I$. Let \\ ${n=a_1 + \cdots + a_m +1}$; by the pigeonhole principle, any product of at most $n$ $f_i$'s must lie in $I$.
	
	For the second statement, just use the fact that $\sqrt{I}$ is finitely generated.
\end{proof}


\begin{theorem}[Krull intersection theorem]
	Let $(R,\m,k)$ be a Noetherian local ring. Then $\bigcap_{n \in \NN} \m^n = 0$.
\end{theorem}
\begin{proof} Let $J=\bigcap_{n \in \NN} \m^n$. We will show that $J \subseteq \m J$, hence $J=\m J$, and thus $J=0$ by NAK.
	
	Let $\m J=\q_1 \cap  \cdots \cap \q_t$ be a primary decomposition. We claim that $J \subseteq \q_i$ for each $i$. If $\sqrt{\q_i}\neq \m$, pick $x\in \m \smallsetminus \sqrt{\q_i}$. We have $xJ \subseteq \m J \subseteq \q_i$, with $x\notin \sqrt{\q_i}$, so $J \subseteq \q_i$ by definition of primary. If instead $\sqrt{\q_i}=\m$, there is some $N$ with $\m^N\subseteq \q_i$ by the radical lemma for finitely generated ideals. We then have $J \subseteq \m^N\subseteq \q_i$, and we are done.
\end{proof}



This result extends to modules as well.

\begin{thm} Let $(R,\m,k)$ be a Noetherian local ring, and $M$ be a finitely generated $R$-module. Then $\bigcap_{n \in \NN} \m^n M = 0$.
\end{thm}
\begin{proof} Consider the Nagata idealization $R \rtimes M$, which is $R \oplus M$ additively, with multiplication $(r,m)(s,n) =(rs, rn+sm)$. This is a local ring with maximal ideal $\m \oplus M$: any element outside of this ideal can be written as $(\lambda, m )$ with $\lambda$ a unit in $R$, and \[(\lambda, m )(\lambda^{-1}, -\lambda^{-2} m) = (\lambda \lambda^{-1},  \lambda (-\lambda^{-2}) m + \lambda^{-1} m )= (1,0).\] It is a finitely generated $R$-module, so it is again Noetherian. We also have
\[ (\m \oplus M)^n = \m^n \oplus \m^{n-1} M.\]
If $m\in \bigcap_{n\in\N} \m^n M$, then $(0,m)\in\bigcap_{n\in\N} (\m \oplus M)^n =0$, so $m=0$.
\end{proof}

%\begin{thm} Let R be a Noetherian ring, M a finitely generated R-module, and I an ideal
%of R. Then $m \in \bigcap_{n\in \N} I^n M$ if and only if there is some $a\in I$ with $am=m$.
%\end{thm}
%\begin{proof}
%The ``if'' part is trivial.
%For the other direction, suppose that $I + \ann_R m$ is a proper ideal of $R$, let $\m$ be a maximal ideal of $R$ containing it. Then $u/1$ is nonzero in $M_\m$, and $I R_\m \subseteq \m R_\m$, the maximal ideal of $R_\m$. But then $m \in I^n M$ for all $n$ implies that $m/1 \in (I R_\m)^n M_\m \subseteq (\m R_\m)^n M_\m$  for all $n$, and this is a contradiction. Thus, we can choose $a\in I$ and $z \in \ann_R(m)$ such that $a+z = 1$. But then $am=am+zm=(a+z)m=1m=m$.
%\end{proof}


\sec{Dimension theory, globally}


\Mar{21}

\ssec{Definition of dimension}

We will now spend a while discussing the notion of dimension of a ring and dimension of a variety. To motivate the definition, let's first think in terms of varieties. 

We take our inspiration from the fundamental setting of dimension theory: vector spaces. The notion of basis doesn't make sense for varieties (What does it mean to span? Where is zero?), but one relevant thing we do have for both vector spaces and for varieties is subobjects.

One way to characterize the dimension of a vector space $V$ is the the largest number $d$ such that there is a proper chain of subspaces
\[ \{0\} = V_0 \subsetneqq V_1 \subsetneqq V_2 \subsetneqq \cdots \subsetneqq V_d = V.\]
We can try something similar for varieties, but for a reducible variety, this isn't a very good notion. For example, for a union of $m$ points, we can cook up a chain of $m$ proper subvarieties by adding one more point each time, but a point should be zero-dimensional by any reasonable measure. So, if we want this approach to work, we should stick to chains of irreducible subvarieties.

\begin{defn} The \emph{dimension}\index{dimension of a variety} of an affine variety $X$ is defined as
\[ \sup \{ d \ | \ \exists \ \text{a strictly decreasing chain of irreducible subvarieties of $X$:} \ \ X_d \supsetneqq X_{d-1} \supsetneqq \cdots \supsetneqq X_0\}.\]
\end{defn}

Over an algebraically closed field $K$, this information of chains of subvarieties can be translated into information about primes in the coordinate ring: namely, a strictly increasing chain of irreducible subvarieties
\[X_d \supsetneqq X_{d-1} \supsetneqq \cdots \supsetneqq X_0\]
corresponds to strictly increasing chain of prime ideals
\[\p_0 \subsetneqq \p_{1} \subsetneqq \cdots \subsetneqq \p_d\]
in the coordinate ring $K[X]$.

\begin{defn} The {\em Krull dimension}\index{Krull dimension}\index{dimension} (often just called dimension) of a commutative ring $R$, written $\dim(R)$,  is defined to be
$$
\dim(R)=\sup \{d \mid \exists \text{ a strictly increasing chain of prime ideals } \fp_0 \subsetneqq \cdots \subsetneqq \fp_d\}.
$$
We will agree that the dimension of the zero ring is $-1$, by convention. 

For a (proper) chain of primes
\[\fp_0 \subsetneqq \cdots \subsetneqq \fp_d\]
its \emph{length}\index{length of a chain of primes} is $d$, the number of (proper) containments in the chain; such a chain is \emph{saturated}\index{saturated chain of primes} if for each $i$, there is no $\q\in \Spec(R)$ with ${\p_i \subsetneqq \q \subsetneqq \p_{i+1}}$. One can equivalently define $\dim(R)$ as the supremum of the lengths of saturated chains of primes of $R$.
\end{defn}

Note in the definition that the set we are taking the sup over is a subset of $\N$, so this sup is either $\infty$ if unbounded or the maximum if bounded.



\begin{example}
	\begin{enumerate}
		\item The dimension of a field is zero.
	\item A ring is zero-dimensional if and only if every minimal prime of $R$ is maximal.
	\item The ring of integers $\ZZ$ has dimension one, since there is one minimal prime $(0)$ and every other prime is maximal. Likewise, any PID that is not a field has dimension one.
%	\item If $R$ is a UFD, $I$ is a prime of height one if and only if $I=(f)$ for a prime element $f$. 
%	
%	To see this, note that if $I=(f)$ with $f$ irreducible, and $0\subsetneqq \p \subseteq I$, then $\p$ contains some nonzero multiple of $f$, say $af^n$ with $a$ and $f$ coprime. Since $a\notin I$, $a\notin \p$, so we must have $f\in \p$, so $\p=(f)$. Thus, $I$ has height one. On the other hand, if $I$ is a prime of height one, we claim $I$ contains an irreducible element. Indeed, $I$ is nonzero, so contains some $f\neq 0$, and primeness implies one of the prime factors of $f$ is contained in $I$. Thus, any nonzero prime contains a prime ideal of the form $(f)$, so a height one prime must be of this form.
%	
	\item It follows from the definition that if $K$ is a field, then 
	\[\dim(K[x_1,\dots,x_d])\geq d,\] since there is a saturated chain of primes 
	\[(0) \subsetneqq (x_1)  \subsetneqq (x_1,x_2)  \subsetneqq \cdots  \subsetneqq (x_1,\dots,x_d).\]
	\end{enumerate}
	
The definition for the dimension of $K[x_1,\dots,x_d]$ can be equivalently stated as the supremum of the lengths of strictly increasing chains of irreducible algebraic subsets of the form 
$$
X_0 \subsetneqq \cdots \subsetneqq X_d \subseteq \A^n_k.
$$
Clearly, we may assume take $X_0$ to be a single point and $X_d = \A^n_k$ in finding this supremum.
\end{example}

\begin{rem}
We will show eventually that $\dim(K[x_1,\dots,x_d])=d$. The case $d=1$ follows from above, i.e. $\dim(K[x])=1$, since this ring is a PID.
\end{rem}

\begin{rem} The definition of dimension is most meaningful for Noetherian rings, although 
\begin{itemize}
\item
There are nonNoetherian rings of finite Krull dimension:  for a field $K$, the ring $K[x_1,x_2,\dots]/(x_1^2,x_2^2,\dots)$ is not Noetherian, as
\[ (x_1) \subsetneqq (x_1,x_2) \subsetneqq (x_1,x_2,x_3) \subsetneqq \cdots\]
is an infinite ascending chain, but its dimension is zero, since $\sqrt{(0)} = (x_1,x_2,\dots)$ is a maximal ideal, and hence $(x_1,x_2,\dots)$ is the unique minimal prime of $R$, which is also maximal.
\item
There are Noetherian rings of infinite dimension.  This was shown in a famous example due to Nagata presented below. 
\end{itemize}
\end{rem}


\begin{example}[Nagata]
\label{ex:Nagata}
	Let $R=K[x_{11},x_{21},x_{22}, x_{31}, x_{32}, x_{33},\dots]$ be a polynomial ring in infinitely many variables, which we are thinking of as arranged in an infinite triangle. $R$ is clearly infinite-dimensional and not Noetherian. Let
	\[ W=R\smallsetminus \big((x_{11}) \cup (x_{21},x_{22}) \cup (x_{31},x_{32},x_{33})  \cup \cdots \big) = \bigcap_{n\in \NN} \big(R \smallsetminus (x_{n1},\dots,x_{nn})\big)\]
	and $S=W^{-1}R$. Note that $W$ is an intersection of multiplicatively closed subsets, so this is a valid localization of $R$.
	
	For any $n$, we have a chain of primes \[(x_{n1}) \subsetneqq (x_{n1},x_{n2}) \subsetneqq \cdots \subsetneqq (x_{n1},\dots,x_{nn})\]
	in $R$. As these are all contained in the last one, none of these intersects $W$, so the expansions yield a proper chain of primes in $S$.  It follows that $\dim(S) \geq n$ for all $n\in \NN$, so $S$ is infinite-dimensional.
	
	It turns out that $S$ is Noetherian, which is not at all obvious. We skip the proof of this.
\end{example}


To aid in computing dimension we make the following related definition.

\begin{defn}
\label{def:ht}
The \emph{height}\index{height} of a prime ideal  $\p$ of a ring $R$  is the supremum of the lengths of (saturated) chains of primes in $R$ that end in $\p$, in symbols
$$
\htt(p)=\sup \{h \mid \exists \text{ a strictly increasing chain of prime ideals } \fp_0 \subsetneqq \cdots \subsetneqq \fp_h=\p\}.
$$
%Equivalently, $\htt(\p)$ is the supremum of the lengths of saturated chains of primes in $R$ that end in $\p$.

The \emph{height} of an ideal $I$ is the infimum of the heights of the primes containing $I$
\[
\htt(I)=\inf\{\htt(\p)\mid \p\in V(I)\}=\inf\{\htt(\p)\mid \p\in \Min(I)\}.
\]
\end{defn}

To get a feel for these definitions, we make a sequence of easy observations. We use the phrase {\em minimal primes of $R$} and the notation $\Min(R)$  to mean $\Min(0)$.

\begin{prop}[Properties of dimension and height]
\label{rk:dimprop}
\

\begin{enumerate}
%\item Dimension and height are isomorphism invariants.
\item A prime has height zero if and only if it is a minimal prime of $R$.
\item An ideal has height zero if and only if it is contained in a minimal prime of $R$. In particular, in a domain, every nonzero ideal has positive height.
\item $\dim(R)=\sup\{ \dim(R/\p) \ | \ \p\in \Spec(R) \}=\sup\{ \dim(R/\p) \ | \ \p\in \Min(R) \}$.
\item $\dim(R)=\sup\{ \mathrm{height}(\p) \ | \ \p\in \Spec(R) \}=
\sup\{ \mathrm{height}(\fm) \ | \ \fm\in \Max(R) \}$.
%	\item If $\p$ is prime, then $\dim(R/\p)$ is the supremum of the lengths of (saturated) chains of primes of $R$, $\p_0 \subsetneq \p_1  \subsetneq \cdots \subsetneq \p_n $, with each $\p_i \in V(\p)$.
	\item If $I$ is an ideal, then $\dim(R/I)$ is the supremum of the lengths of (saturated) chains of primes of $R$, $\p_0 \subsetneqq \p_1  \subsetneqq \cdots \subsetneqq \p_n$, with each $\p_i \in V(I)$.
	\item\label{ineq1} If $\p$ is prime, $\dim(R/\p) + \mathrm{height}(\p) \leq \dim(R)$.
	\item\label{ineq2} If $I$ is an ideal, $\dim(R/I) + \mathrm{height}(I) \leq \dim(R)$.
			\item If $W$ is a multiplicative set, then $\dim(W^{-1}R) \leq \dim(R)$.
\item If $\p$ is prime, then $\mathrm{height}(\p)=\dim(R_{\p})$.
\item If $\p\subseteq \q$ are primes, then $\dim(R_{\q}/ \p R_{\q})$ is the supremum of the lengths of (saturated) chains of primes in $R$ of the form 
	$\p=\p_0 \subsetneqq \p_1  \subsetneqq \cdots \subsetneqq \p_n=\q$.

\end{enumerate}
\end{prop}
\begin{proof}
We only discuss a few here.

For (2), if $I$ is contained in a minimal prime $\q$ of $R$, then there is some $\p\in \Min(I)$ with $\p\subseteq \q$, so $\p=\q$, and $\mathrm{height}(\p)=0$ by (1), so $\mathrm{height}(I)=0$ by definition. Conversely, if $\mathrm{height}(I)=0$, by definition, there is a minimal prime of $I$ of height $0$, so some minimal prime of $I$ is a minimal prime of $R$, so $I$ is contained in a minimal prime of $R$.

For (6), it suffices to show that if $\dim(R/\p)\geq a$ and $\mathrm{height}(\p) \geq b$ then $\dim(R) \geq a+b$. By definition, $\mathrm{height}(\p) \geq b$ means that there is a chain of primes 
\[ \q_0 \subsetneqq \q_1 \subsetneqq \cdots \subsetneqq \q_b = \p.\] By (5), $\dim(R/\p)\geq a$ means that there is a chain of primes 
\[ \mathfrak{a}_0 \subsetneqq \mathfrak{a}_1 \subsetneqq \cdots \subsetneqq \mathfrak{a}_a\]
with $\mathfrak{a}_0 \supseteq \p$. We can assume without loss of generality that $\mathfrak{a}_0=\p$, since if not, we can add it to the bottom of the chain. Putting these chains together, we get a chain of length $a+b$ in $\Spec(R)$, so $\dim(R) \geq a+b$.

For (7), let $\dim(R/I)\geq a$ and $\mathrm{height}(I) \geq b$. The inequality $\mathrm{height}(I) \geq b$ means that for every minimal prime $\p$ of $I$, $\mathrm{height}(\p) \geq b$. The inequality $\dim(R/I) \geq a$ implies that there exists a minimal prime of $\p$ of $I$ such that $\dim(R/\p) \geq a$. For such a minimal prime as in the latter statement, using (5), we get the desired conclusion.

(8)--(10) are left for you.
\end{proof}


\begin{rem} We know that in Noetherian rings, there can be arbitrarily long chains of primes: the dimension can be infinite as in Nagata's example. On the other hand, any ascending proper chain of primes is finite, as a consequence of the definition. Does this imply that every prime has finite height? It does not follow: 

A priori, there could be an infinite descending chain of primes, which would then give any of the primes in the chain infinite height. (This seems strange in conjunction with the fact that in any ring, any prime contains a minimal prime, but does not contradict this.) 

Another possible problem is there being two primes $\p \subset \q$ with for each $n\in \N$, a chain of primes of length $n$ from $\p$ to $\q$.

However, we will show later that the height of any ideal in a Noetherian ring is finite, though only a while from now.
\end{rem}



\Mar{23}

\begin{exer} Let $R$ be a UFD. Then a nonzero ideal has height $1$ if and only if it is principal.
\end{exer}

%\begin{lem} Let $R$ be a UFD and $f\in R$ be nonzero. Then $\htt((f))=1$.
%\end{lem}
%\begin{proof}
%We know that $\htt((f))>0$. If $f= u p_1^{a_1} \cdots p_n^{a_n}$ for some unit $u$ and irreducibles $p_i$, then $\Min((f)) = \{ (p_1) ,\dots, (p_n)\}$: each such ideal is prime and contains $f$, and any prime ideal containing $f$ must contain some $p_i$ by the definition of prime. Thus, it suffices to show that if $f$ is irreducible, then the prime ideal $(f)$ has height $1$. If $0 \subsetneqq \q \subseteq (p)$, take some $x\in \q \smallsetminus 0$ and write $x=p^a v$ for some $v$ that does not have $p$ as a factor. Then, since $\q \subseteq (p)$, we have $v\notin \q$ , so by definition of prime, $p\in \q$; thus $\q=(p)$. This concludes the proof.
%\end{proof}

\begin{ex} Let $K$ be a field, and $R=K[x,y,z]/(xy,xz)$. In $K[x,y,z]$, we have $\Min((xy,xz))=\{(x),(y,z)\}$, so $\Min(R)=\{ (\bar{x}), (\bar{y},\bar{z})\}$. We then have 
\begin{eqnarray*}
\dim(R) &=& \max\left\{\dim \frac{R}{(\bar y,\bar z)}, \dim \frac{R}{(\bar x)}\right \}\\
&=& \max\left\{\dim K[x], \dim K[y,z] \right \}\\
&=&\max\{ 1 ,\geq 2\}\\
&\geq&2.
\end{eqnarray*}
In fact, once we believe that $\dim(K[y,z])=2$, we will believe $\dim(R)=2$.

We can write down an explicit chain of primes of $R$ of length 2: 
\[(\bar x)\subsetneqq (\bar x, \bar y)\subsetneqq (\bar x, \bar y, \bar z).\] 

In $K[x,y,z]$, we have $\htt((xy,xz)) = \min\{ \htt(x), \htt(y,z) \} = \min\{ 1, \geq 2\} = 1$.

Geometrically this corresponds to a union of a line and a plane. The dimension of this variety is the max of the dimensions of the irreducible components, which (should be) 2.
\end{ex}

We want to compute a nontrivial example of dimension. We will generalize the rough outline of this example later to prove our main theorems about dimension of finitely generated algebras over fields. We note a simple fact on integral extensions to prepare.

\begin{exer} Let $R\subseteq S$ be an integral inclusion of rings. Then for every nonzero $s\in S$, there is some $s'\in S$ such that $ss'\in R\smallsetminus 0$.
\end{exer}

\begin{ex}
Let $K$ be an infinite field. Let $R=K[t^3,t^4,t^5]$. We have shown that $\displaystyle R\cong \frac{K[x,y,z]}{(x^3-yz,y^2-xz,z^2-x^2y)}$, and that $R$ is the coordinate ring of the curve $X=\{ (t^3,t^4,t^5) \ | t\in K\}$ over an infinite field $K$. As $X$ is a curve / is parameterized by a single parameter we expect the dimension of the ring $R$ (equivalently of the variety $X$) to be $1$. Let's prove this.

$R$ is a domain, so $(0)$ is the unique minimal prime. We need to show that any nonzero prime ideal is maximal.

Set $S=K[t^3]\subseteq R$. We note that $t^3$ does not satisfy any algebraic relation over $K$, so $S$ is isomorphic to a polynomial ring in one variable (corresponding to $t^3$). Furthermore, this inclusion is integral, since $(t^4)^3- (t^3)^4=0$ and $(t^5)^3 - (t^3)^5=0$.

Let $\p\in \Spec(R)$ be nonzero. Note first that $\p \cap S \neq 0$, since if $f\in \p$, then there is some nonzero multiple of $f$ in $S$ by the exercise. Since $\dim(S)=1$, $\p \cap S$ is maximal. The inclusion
\[ \frac{S}{\p \cap S} \hookrightarrow \frac{R}{\p}\] is integral: an dependence relation for any representative yields a dependence relation. Since $\frac{S}{\p \cap S}$ is a domain, $\frac{R}{\p}$ is a field, and the inclusion is integral, we conclude that $\frac{S}{\p \cap S}$ is a field, so $\p \cap S$ is maximal.
\end{ex}


\begin{definition}
 A ring is {\em catenary}\index{catenary} if for every pair of primes $\q \supseteq \p$ in $R$, every saturated chain of primes $\p=\p_0 \subsetneqq \p_1  \subsetneqq \cdots \subsetneqq \p_n=\q $
	 has the same length.
	\item A ring is {\em equidimensional}\index{equidimensional} if every maximal ideal has the same finite height, and every minimal prime has the same dimension.
\end{definition}

The poset of ideals of an catenary ring is a {\em ranked poset} in the sense one would encounter in combinatorics, where the rank function is the height of an ideal.

It is difficult to come up with examples of rings that are not catenary, but they do exist. Nagata  gave the first example of a Noetherian noncatenary ring in the paper.



%\begin{lem}
%For a catenary domain $R$ which has a unique maximal ideal $\m$ and for any ideal $I$ 
%\[\htt(I)+\dim R/I = \dim R.\] 
%\end{lem}
%\begin{proof}
%Because $R$ is a local domain the set $\Spec(R)$ has a unique minimal element $(0)$ and a unique maximal element $\m$. Because $R$ is catenary, $\dim(R)$ is the length of {\em any} chain of primes connecting $(0)$ to $\m$ that cannot be refined.
%
%I will prove the claim first for primes, i.e. we'll prove that $\htt(\p)+\dim (R/\p) = \dim R$ for $\p\in \Spec(R)$.
%Note that $\htt(\p)$ is the length of any chain of primes connecting $(0)$ to $\p$ that cannot be refined (this uses the fact that $(0)$ is the unique minimal element of $\Spec(R)$). Furthermore, $\dim (R/\p)$  is the length of any chain of primes connecting $\p$ to $\m$ that cannot be refined (this uses the fact that $\p$ is the unique minimal element of $V(\p)$ and $\m$ is the unique maximal element of $V(\p)$). Finally, concatenating any two such chains we obtain a chain that connects $(0)$ to $\m$ and cannot be refined. The length of any such chain is $\dim R$.
%
%The claim for arbitrary $I$ can be deduced from the statement about primes (exercise).
%\end{proof}

 
 \begin{ex}
 Here is an example which shows that  the inequality $\dim(R/I) + \mathrm{height}(I) \leq \dim(R)$  can fail to be an equality.
 
 Let $R=\Z_{(2)}[x]$ and consider $\p=(2x-1)$. Now $\p$ is a prime of height 1 and $R/\p\cong \Q$, so $\dim(R/\p)=0$, and therefore $\dim(R/\p)+\htt(\p)=1$ whereas $\dim R\geq 2$ as attested by the chain $(0)\subsetneq (2) \subsetneq (2,x)$.  In fact, $\dim R=2$, but I won't justify this. 
 
 The ring $R$ in this example is in fact a catenary domain.  Notice that there are maximal ideals of distinct heights in this ring, for example the ideal $\p$ given above is a prime of height 1 whereas and another maximal ideal $\m=(2,x)$ has height 2. Thus this ring is not equidimensional.
 
  \end{ex}



%\begin{remark}
%	\begin{enumerate}
%
%	\item If $\dim(R)<\infty$, $R$ is a domain, and $f\neq 0$, then $\dim(R/(f)) < \dim(R)$.
%	\item If $R$ is equidimensional, then  $\dim(R/(f)) < \dim(R)$ if and only if $f\notin \bigcup\limits_{\p \in \Min(R)} \p$.
%	\item In general, $\dim(R/(f)) < \dim(R)$ if and only if  $f\notin \bigcup\limits_{\substack{\p \in \Min(R) \\ \dim(R/\p) = \dim(R)}} \p$.
%	\item $f\notin \bigcup_{\p \in \Min(R)} \p$ if and only if $\dim(R/(\p + (f))) < \dim(R/\p)$ for all $\p\in \Min(R)$.
%	
%\end{enumerate}
%\end{remark}
%
%


\Mar{25}

We give a related definition of dimension for modules.

\begin{definition} The \emph{dimension}\index{dimension of a module} of an $R$-module $M$ is defined as 
\[\dim(M)=\dim(R/\ann_R(M)).\]
\end{definition}

\begin{exer}
Show that if $M$ is finitely generated, then $\dim(M)$ is the same as the largest length of a chain of primes in $\Supp_R(M)$.
\end{exer}



\subsection{Over, up, down theorems}

In this section, we will collect theorems about the spectrum of a ring: theorems that assert that the map on Spec is surjective, and theorems about lifting chains of primes. 

It will be convenient to think in terms fo fibers. For a map of topological spaces $f: X\to Y$ (or in various other categories) and $y\in Y$, the \emph{fiber}\index{fiber of a map} over $y$ is the subspace $f^{-1}(y)= \{x\in X \ | \ f(x)=y\} \subseteq X$; if $f$ is continuous and $y\in Y$ is closed, then $f^{-1}(y) \subseteq X$ is closed. 


\begin{exer} Let $\phi:X\to Y$ be a morphism of affine varieties, with $X=Z(I) \subseteq \A^n$ (with coordinates $x_1,\dots,x_n$), $Y =Z(J) \subseteq \A^m$ (with coordinates $y_1,\dots,y_m$), and $y=(a_1,\dots,a_m)\in Y$. Then 
\[ \phi^{-1}(y) = Z(I, \phi^*(y_1-a_1),\dots,\phi^*(y_m-a_m)),\]
and hence 
\[K[\phi^{-1}(y)] \cong \frac{K[X]}{\cI(y) K[X]},\]
where $\cI(y) K[X]$ denotes the expansion of the ideal $\cI(y)\in K[Y]$ to $K[X]$ via the map $\phi^*$.
\end{exer}

\begin{defn}
Let $\psi:R\to S$ be a ring homomorphism and $\p\in \Spec(R)$ be a prime ideal. We define the \emph{fiber ring}\index{fiber ring}\index{\kappa_{\psi}(\p)} of $\psi$ over $\p$ as
\[ \kappa_{\psi}(\p) = (R\smallsetminus \p)^{-1}(S/\p S),\]
where, by abuse of notation, we write $R\smallsetminus \p$ for the image of $R\smallsetminus \p$ in $S$ (and $\p S$ for $\psi(\p) S$ as usual).

In the special case $\fm \subseteq R$ is maximal, $S/\fm S$ is an $R/\fm$-module, which is a vector space, so every element of $R\smallsetminus \fm$ acts as a unit on $S/\fm S$, so the localization is redundant, and 
\[ \kappa_\psi(\fm) = S/\fm S.\]

As another special case, for the identity map, we simply write $\kappa(\p)$\index{$\kappa(\p)$}. That is, \[\kappa(\p) = R_{\p} / \p R_\p.\]
\end{defn}

The point of this definition is the following.

\begin{lemma} Let $\psi:R\to S$ be a ring homomorphism and $\p\in \Spec(R)$ be a prime ideal. The natural map $S \to \kappa_{\psi}(\p)$ induces a homeomorphism (in particular, an order-preserving bijection)
\[ \Spec( \kappa_{\psi}(\p) ) \cong \{ \q \in \Spec(S) \ | \ \psi^*(\q) = \p \},\]
where the right-hand side obtains the subspace topology from $\Spec(S)$.
\end{lemma}
\begin{proof}
First, we recall that for any localization map or any quotient map, the induced map on Spec is a homeomorphism onto its image. 
Write our natural map as $S\to S/\psi(\p) S \to \psi(R\smallsetminus \p)^{-1}(S/\psi(\p) S)$. Then $\q$ is in the image of the induced map on Spec if and only if $\q \supseteq \psi(\p) S \ \text{and} \ \q \cap \psi(R\smallsetminus \p) = \varnothing$. The first condition is equivalent to $\q \supseteq \psi(\p)$, which in turn means $\psi^{-1}(\q) \supseteq \p$; the latter condition is equivaalent to $\psi^{-1}(\q) \subseteq \p$. Together, $\q$ is in the image if and only if $\psi^{-1}(\q) = \p$.
\end{proof}


\begin{lemma}[Image criterion] Let $\varphi:R \to S$ be a ring homomorphism, and $\p\in \Spec(R)$. Then $\p\in \im(\varphi^*)$ if and only if $\p S \cap R = \p$.
\end{lemma}
\begin{proof}
If $\p S \cap R = \p$, then 
\[ \frac{R}{\p} = \frac{R}{\p S \cap R} \hookrightarrow \frac{S}{\p S},\]
so, localizing at $(R\smallsetminus \p)$, we get an injection $\kappa(\p) \hookrightarrow \kappa_{\varphi}(\p)$. The latter ring is nonzero, so its spectrum is nonempty. Thus, there is a prime mapping to $\p$.

If $\p S \cap R \neq \p$, then $\p S \cap R \supsetneqq \p$ (the other containment always holds). Then, if $\q \cap R = \p$, we have $\q \supseteq \p S$, so $\q \cap R \supsetneqq \p$.
\end{proof}

Note that $\p S$ may not be prime, in general.

\begin{example}
Let $R=\CC[x^n] \subseteq S=\CC[x]$. The ideal $(x^n-1) R$ is prime, while $(x^n-1) S = (\prod_{i=0}^{n-1} x - \zeta^i) S$, where $\zeta$ is a primitive $n$th root of unity, is not. However, each of its minimal primes $(x-\zeta^i)S$ contracts to $(x^n-1)R$. Similarly, the ideal $x^n R$ is prime, while $x^n S$ is not radical.
\end{example}



\begin{corollary} If $R\subseteq S$ is a direct summand, then $\Spec(S) \to \Spec(R)$ is surjective.
\end{corollary}
\begin{proof} We know that $I S \cap R = I$ for all ideals in this case.
\end{proof}

We want to extend the idea of the last corollary to work for all integral extensions. The key idea is encapsulated in a definition.

\begin{definition} Let $R$ be a ring, $S$ an $R$-algebra, and $I$ an ideal. 
	\begin{itemize}
		\item An element $r$ of $R$ is \emph{integral} over $I$ \index{integral over an ideal} if it satisfies an equation of the form
		\[ r^n + a_1 r^{n-1} + \cdots + a_{n-1} r + a_n = 0 \qquad \text{with} \ a_i \in I^i \ \text{for all} \  i.\]
		\item An element of $S$ is integral over $I$ if the same condition holds.
		\item The \emph{integral closure}\index{integral closure of an ideal} of $I$ in $R$ is $\overline{I}$\index{$\overline{I}$}, the set of elements of $R$ that are integral over $I$.
		\item Similarly, we write $\overline{I}^S$\index{$\overline{I}^S$} for the integral closure of $I$ in $S$.
	\end{itemize}
\end{definition}

We leave a little exercise for you.

\begin{exer} Let $R\subseteq S$, $I$ be an ideal of $S$, and $t$ be an indeterminate. Consider the rings $R[It]\subseteq R[t] \subseteq S[t]$.
\begin{enumerate}
	\item $\overline{I}^S =\{ s \in S \ | \ st\in S[t] \ \text{is integral over the ring} \ R[It]\}$.
	\item $\overline{I}^S$ is an ideal.
\end{enumerate}
\end{exer}

We note that in older texts and papers (e.g., Atiyah-Macdonald and Kunz) a different definition is given for integral closure of an ideal. The one we use here is more-or-less universally accepted as the correct notion.

\begin{lemma}[Extension-contraction lemma for integral extensions] Let $R \subseteq S$ be integral, and $I$ be an ideal of $R$. Then, $IS \subseteq\overline{I}^S$. Hence, $I S \cap R \subseteq \overline{I}$.
\end{lemma}
\begin{proof}
Let $x\in IS$. We can write $x = \sum_{i=1}^t a_i s_i$ with $a_i\in I$. Taking $S'=R[s_1,\dots,s_t]$, we also have $x\in IS' $. Thus, it suffices to show the statements in the case $S$ is module-finite over $R$.

Let $S=\sum R b_i$. We have $x b_i = (\sum_k a_k s_k) b_i = \sum_j a_{ij} b_j$ with $a_{ij}\in I$. We can write this as a matrix-acts-like-a-scalar equation $x v = Av$, where $v=(b_1,\dots,b_u)$, and $A=[a_{ij}]$. By the adjoint trick, we have $\det(xI-A)v=0$. Since we can assume $b_1=1$, we have $\det(xI-A)=0$. The fact that this is the type of equation we want follows from the monomial expansion of the determinant: any monomial is a product of $n$ terms where some of the are copies of $x$, and the rest are elements of $I$.

The last statement follows from the fact that $\overline{I}^S \cap R = \overline{I}$, which is immediate from the definition.
\end{proof}

\Mar{28}

If $\p$ is in the image of the induced map on spec, it must be the contraction of some minimal prime of $\p S$, but not necessarily every minimal prime of $\p S$.

\begin{ex} Let $R=K[u,v] \xra{\alpha} S=K[x,y]$ via $\alpha(u)=x$, $\alpha(v)=xy$. Then $vS$ has two minimal primes $(x), (y)$. Note that $(x) \cap R = (u,v)$, but $(y) \cap R = (v)$.
\end{ex}

\begin{theorem}[Lying over] If $R\subseteq S$ is an integral inclusion then $\Spec(S) \to \Spec(R)$ is surjective.
\end{theorem}
\begin{proof}
 We observe that $\overline{I} \subseteq \sqrt{I}$. Thus, for $\p$ prime, by the previous lemma, $\p S \cap R = \p$, and the result follows from the image criterion.
\end{proof}

\begin{remark} Both ``integral'' and ``inclusion'' are important: the map $R\to R_f$ is a nonintegral inclusion if $f$ is a nonzerodivisor, and the image is the complement of $V(f)$; the map $R\to R/(f)$ is an integral noninclusion, and the the image is $V(f)$.
\end{remark}


\begin{theorem}[Incomparability]
If $\varphi: R \to S$ is integral, and $\q \subseteq \q'$ are such that $\varphi^*(\q)=\varphi^*(\q')$, then $\q=\q'$.
\end{theorem}
\begin{proof}
Since the map $R\to R/\ker(R)$ is injective on spectra, we can replace $R$ by the quotient and assume $\varphi$ is an integral inclusion.

Now, if $R\hookrightarrow S$ is integral, then $R/\p \hookrightarrow S/\p S$ (which is injective by the lemma above) is integral; take an integral equation for a representative. Furthermore, localizing at $(R\smallsetminus \p)$ preserves integrality: if $x\in S$ and $w\in R\smallsetminus \p$, then we have equations of the form
\[ x^n + r_1 x^{n-1} + \cdots + r_n = 0 \Longrightarrow (\frac{x}{w})^n + \frac{r_1}{w} (\frac{x}{w})^{n-1} + \cdots + \frac{r_n}{w^n}  =0.   \] 
We then have that $\kappa(\p)\hookrightarrow \kappa_{\varphi}(\p)$ is integral. If $\q$ is a prime of $\kappa_{\varphi}(\p)$, then $\kappa(\p)\subseteq \kappa_{\varphi}(\p) / \q$ is an integral inclusion from a field to a domain, and by a lemma from a while ago, we must have that $\kappa_{\varphi}(\p) / \q$ is a field. Therefore, $\kappa_{\varphi}(\p)$ is zero-dimensional. Since there are no inclusions between primes in $\kappa_{\varphi}(\p)$, there are no inclusions between primes that contract to $\p$.
\end{proof}



\begin{corollary}
If $R \to S$ is integral, and $S$ is Noetherian, then for any $\p\in \Spec(R)$, only finitely many primes contract to $\p$.
\end{corollary}

\begin{proof}
	For the first statement, this case the fiber ring $\kappa_{\varphi}(\p)$ of any prime is also Noetherian, hence has finitely many minimal primes. Every prime of the fiber is minimal, though.
\end{proof}

\begin{exer}  If $S=\sum_{i=1}^t R s_i$ is generated as an  $R$-module by $t$ elements, then for any prime of $R$, at most $t$ primes of $S$ map to $\p$.
\end{exer}
%We have $\kappa_{\phi}(\p) = \sum_{i=1}^t \kappa(\p) \bar{s_i}/1 $, and hence $\kappa_{\phi}(\p)$ is a zero-dimensional ring that is a $\kappa(\p)$-vector space of dimension at most $t$.  We have a minimal primary decomposition $(0)_{\kappa_{\phi}(\p)}=\q_1 \cap \cdots \cap \q_s$ where $\sqrt{\q_i}$ are distinct maximal ideals; these maximal ideals are in bijection with the primes mapping to $\p$ in $S$. Thus, for $i\neq j$, $V(\q_i + \q_j) = V(\q_i) \cap V(\q_j)=\varnothing$, so $\q_i + \q_j = \kappa_{\phi}(\p)$, and by the Chinese Remainder Theorem, $\kappa_{\phi}(\p)\cong \kappa_{\phi}(\p)/\q_1 \times \cdots \times  \kappa_{\phi}(\p)/\q_s$. The map $\kappa(\p) \to \kappa_{\phi}(\p)/\q_i$ is nonzero for each $i$ (since it is integral), so each factor is a $\kappa(\p)$-vector space. Considering vector space dimension, find that the number of factors $s$ is at most $t$.


\begin{corollary} If $R\to S$ is integral, then $\mathrm{height}(\q) \leq \mathrm{height}(\q \cap R)$ for any $\q\in \Spec(S)$. In particular, $\dim(S) \leq \dim(R)$.
\end{corollary}
\begin{proof}
	Given a chain of primes $\mathfrak{a}_0 \subsetneqq \cdots \subsetneqq \mathfrak{a}_n = \q$ in $\Spec(S)$, we can contract to $R$, and we get a chain of distinct primes in $\Spec(R)$, so the height of the latter is at least as big.
\end{proof}


\begin{theorem}[Going up]
	If $R\to S$ is integral, then for every $\p \subsetneqq \p'$ in $\Spec(R)$ and $\q$ in $\Spec(S)$ with $\q \cap R=\p$, there is some $\q'\in \Spec(S)$ with $\q \subsetneqq \q'$ and $\q' \cap R = \p'$.
\end{theorem}
\begin{proof} Consider the map $R/\p \to S/\q$. This is integral, as we observed above. It is also injective, so lying over applies. Thus, there is a prime $\mathfrak{a}$ of $S/\q$ that contracts to the prime $\p'/\p$ in $\Spec(R/\p)$. We can write $\mathfrak{a}=\q'/\q$ for some $\q'\in \Spec(S)$, and we must have that $\q'$ contracts to $\p'$.
\end{proof}

\begin{corollary}
	If $R\subseteq S$ is integral, then $\dim(R)=\dim(S)$.
\end{corollary}
\begin{proof}
	We just need to show that $\dim(R)\leq \dim(S)$. Given a chain of primes $\p_0 \subsetneqq \cdots \subsetneqq \p_n$ in $\Spec(R)$, by lying over, there is a prime $\q_0 \in \Spec(S)$ contracting to $\p_0$. Then by going up, we have $\q_0 \subsetneqq \q_1$ with $\q_1 \cap R = \p_1$. Continuing, we can build a chain of distinct primes in $S$ of length $n$.
\end{proof}

\Mar{30}

We have now established almost everything we might have hoped to be true about dimension for integral extensions. The only remaining issue is whether heights of primes are preserved. 

\begin{definition}
	A domain is \emph{normal}\index{normal domain} if it is integrally closed in its field of fractions.
\end{definition}

\begin{lemma}
	A unique factorization domain is normal: in particular, a polynomial ring over a field is normal.
\end{lemma}
\begin{proof}
	Let $R$ be a UFD, and $r/s\in \mathrm{frac}(R)$ be integral over $R$. We can assume that $r$ and $s$ have no common factor. Then we have for some $a_i$'s in $R$
	\[ \frac{r^n}{s^n} + a_1  \frac{r^{n-1}}{s^{n-1}} + \cdots  + a_n = 0 \quad \Rightarrow \quad r^n = -( a_1 r^{n-1} s + \cdots + a_n s^n ).\]
	Any irreducible factor of $s$ must then divide $r^n$, and hence divide $r$; if $s$ is not a unit then this contradicts that there is no common factor. Thus, $r/s\in R$.
\end{proof}

\begin{lemma} Let $R$ be a normal domain, $x$ be an element integral over $R$ in some larger domain. Let $K$ be the fraction field of $R$, and $f(t)\in K[t]$ be the minimal polynomial of $x$ over $K$.
	\begin{enumerate}
		\item If $x$ is integral over $R$, then $f(t)\in R[t]\subseteq K[t]$.
		\item If $x$ is integral over a prime $\p$, then $f(t)$ has all of its nonleading coefficients in $\p$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	Let $x$ be integral over $R$. Fix an algebraic closure of $K$ containing $x$, and let $x_1=x,x_2,\dots,x_u$ be the roots of $f$. Since $f(t)$ divides a monic equation for $x$, each $x_i$ is integral over $R$.
	
	Let $S=R[x_1,\dots,x_u] \subseteq \overline{K}$. This is a module-finite extension of $R$, so all of its elements are integral over $R$. The coefficients of $f(t)$ are elementary symmetric polynomials in the $x$'s, hence they lie in $S$. But, $S\cap K = R$ since $R$ is normal. Thus, the first statement holds.
	
	Now, let $x$ be integral over $\p$. All of the $x$'s are integral over $\p$ by the same argument as above. Since each $x_j\in \overline{\p}^S$, any elementary symmetric polynomial in the $x$'s lies in $\overline{\p}^S$. Thus, the nonleading coefficients lie in $\overline{\p}^S \cap R = \p$.
\end{proof}



\begin{theorem}[Going down]
Suppose that $R$ is a normal domain, $S$ is a domain, and $R\subseteq S$ is integral. Then, for every $\p' \subsetneqq \p$ in $\Spec(R)$ and $\q$ in $\Spec(S)$ with $\q \cap R=\p$, there is some $\q'\in \Spec(S)$ with $\q' \subsetneqq \q$ and $\q' \cap R = \p'$. In a picture:
\[ \xymatrix{ \exists \q' \ar[d] &\subseteq& \q \ar[d]\\
\p' & \subseteq & \p  }\]
\end{theorem}
\begin{proof}
 Let $W=(S\smallsetminus \q)(R\smallsetminus\p')$ be the multiplicative set consisting of products of elements in $S\smallsetminus\q$ and $R\smallsetminus \p'$. Note that each of these sets contains $1$, so each set is in the product. We want to show that $W \cap \p'S$ is empty. It will follow that $W^{-1} (S/\p' S)=(S\smallsetminus \q)^{-1} \kappa_S(\p')$ has a prime ideal, and hence there is a prime of $S$ contained in $\q$ contracting to~$\p'$.

To that end, suppose $x\in \p' S \cap W$. Since $x \in\p' S$, it is integral over $\p'$, so write $x=rs$ with $r\in R\smallsetminus \p', s\in S \smallsetminus \q$, and consider the minimal polynomial of $x$ over $\mathrm{frac}(R)$:
\[ h(x) = x^n + a_1 x^{n-1} + \cdots + a_n = 0. \]
By the lemma above, each $a_i\in \p' \subseteq R$. Then, since $r\in K$, substituting $x=rs$ yields and dividing by $r^n$ yields a polynomial that, viewed as a polynomial in $s$, is irreducible. That is, the minimal polynomial of $s$ is 
\[ g(s) = s^n + \frac{a_1}{r} s^{n-1} + \cdots + \frac{a_n}{r^n} = 0.\]
Since $s\in S$, hence is integral over $R$, the lemma above says that each $\frac{a_i}{r^i}=: v_i\in R$. Since $r\notin \p'$, and $r^i v_i =a_i \in\p'$, we have $v_i\in \p'$, and the equation $g(s)=0$ then shows that $s\in \sqrt{\p' S}$. Since $\q \in \Spec(S)$ contains $\p S$ and hence $\p'S$, we have $s\in \sqrt{\p' S}\subseteq \q$. This is the desired contradiction.
\end{proof}


%\begin{remark} We have used the fact that our rings are domains to put the theory of minimal polynomials to use. The one hypothesis we can weaken is that the target is a domain: it suffices to assume that it is torisonfree as a module over the source. Here's why we can't get rind of more hypotheses.
%
%Let $R=K[x]\subseteq S=K[x,y]/(xy,y^2-y)$. $R$ is a normal domain, and the inclusion is integral: $y^2-y=0$ is an integral dependence relation for $y$ over $R$, so $S$ is generated by one integral element. Now, $(1-y)$ is a minimal prime of $S$: $y\in S\smallsetminus (1-y)$, so $x$ goes to zero in the localization (since $xy=0$) and $1-y$ goes to zero in the localization (since $y(1-y)=0$), so the localization is a copy of $K$, which has only one prime, $(0)$. We have $x=x-xy=x(1-y)\in (1-y)$, so the contraction contains $(x)$, so must be $(x)$. But, by minimality, we can't ``go down'' from $(1-y)$ to a prime lying over $(0)$.
%
%The normality hypothesis is important too. Take $R=K[x(1-x),x^2(1-x),y,xy]\subseteq S=K[x,y]$. The element $x$ is integral over $R$: $x(1-x)\in R$ is a recipe: $x$ is a root of $z^2-z-x(1-x)$. Note that $x$ is in the fraction field of $R$, so this element shows both that $S$ is integral over $R$, and that $R$ is not normal. Now, $\q=(1-x,y)\subseteq S$ is a maximal ideal lying over the maximal ideal $\p$ generated by the specified generating set in $R$. We have $xS \cap R = (x(1-x),x^2(1-x),xy)R=\p'$, but we claim that no prime contained in $\q$ lies over $\p'$. Such a prime must contain $x(1-x)$ and $xy$, but not $x$ (this would make it the unit ideal), so must contain $y$ and $1-x$, and the contraction is then $\p$, which is too big!
%\end{remark}


\begin{corollary}
If $R$ is a normal domain, $S$ is a domain, and $R\subseteq S$ is integral, then $\mathrm{height}(\q)=\mathrm{height}(\q \cap R)$ for any $\q\in \Spec(S)$.
\end{corollary}
\begin{proof}
We already know that $\htt(\q) \leq \htt(\q \cap R)$. Now, take a maximal chain up to $\q\cap R$, and apply going down to get a chain just as long that goes up to $\q$.
\end{proof}


\


%\begin{exer} Show that if $R$ is a normal domain, $S$ is a Noetherian domain, and $R \subseteq S$ is integral, then $\htt(I) = \htt(I \cap R)$ for all ideals $I$ of $S$. You may want to start by showing $\sqrt{I \cap R} = \sqrt{I} \cap R$.
%\end{exer}

\Apr{1}

\subsection{Noether normalization and dimension of affine rings}

\begin{lemma}[Making a pure-power leading term]
%\begin{enumerate}
%\item 
Let $A$ be a domain, and $f\in R=A[x_1,\dots,x_n]$ be a (not necessarily homogeneous) polynomial of degree at most $N$. The $A$-algebra automorphism of $R$ given by $\phi(x_i)=x_i + x_n^{N^{n-i}}$ for $i<n$ and $\phi(x_n)=x_n$ maps $f$ to a polynomial that, viewed as a polynomial in $x_n$ with coefficients in $A[x_1,\dots,x_{n-1}]$, has leading term $d x_n^a$ for some $d\in A$, $a\in \NN$.
%\item 
%Let $K$ be an infinite field, and $f\in R=K[x_1,\dots,x_n]$, with $|x_i|=1$ be a homogeneous polynomial of degree~$N$. There is a degree-preserving $K$-algebra automorphism of $R$ given by $\phi(x_i) = x_i + a_i x_n$ for $i<n$ and $\phi(x_n)=x_n$ that maps $f$ to a polynomial that viewed as a polynomial in $x_n$ with coefficients in $K[x_1,\dots,x_{n-1}]$, has leading term $k x_n^N$ for some (nonzero) $k\in K$.
%\end{enumerate}
\end{lemma}
\begin{proof}
%\begin{enumerate}
%\item 
The map $\phi$ sends a monomial term $d x_1^{a_1} \cdots x_n^{a_n}$ to a polynomial with unique highest degree term $d x_n^{a_1 N^{n-1} + a_2 N^{n-2} + \cdots + a_{n-1} N + a_n}$. Since each $a_i$ is less than $N$ in each monomial, the map $(a_1,\dots,a_n)\mapsto a_1 N^{n-1} + a_2 N^{n-2} + \cdots + a_{n-1} N + a_n$ is injective when restricted to the set of exponent tuples; thus, none of the terms can cancel. We find that the leading term is of the promised form.
%\item We just need to show that the $x^N$ coefficient is nonzero for some choice of $a$'s. You can check that the coefficient of the $x^N$ term is $f(-a_1,\dots,-a_{n-1},1)$. But if this, thought of as a polynomial in the $a$'s, is identically zero, then $f$ must be the zero polynomial.\qedhere
%\end{enumerate}
\end{proof}



\begin{theorem}[Noether Normalization]
%\begin{enumerate} 
%\item
 Let $A$ be a domain, and $R$ be a finitely generated $A$-algebra. Then, there is some nonzero $a\in A$ and $x_1,\dots,x_t\in R$ algebraically independent over $A$ such that $R_a$ is module-finite over $A_a[x_1,\dots,x_t]$. In particular, if $A=K$ is a field, then $R$ is module-finite over $K[x_1,\dots,x_t]$.
%\item Let $K$ be an infinite field, and $R$ be a positively graded $K$-algebra that is generated by elements of degree one. Then there are homogeneous elements $x_1,\dots,x_t\in R_1$ algebraically independent over $K$ such that $R$ is module-finite over $K[x_1,\dots,x_t]$.
%\end{enumerate}
\end{theorem}
\begin{proof}
We proceed by induction on the number of generators $n$ of $R$ over $A$, with the case $n=0$ trivial.

Now, suppose that we know the result for $A$-algebras generated by at most $n-1$ elements. If $R=A[r_1,\dots,r_n]$, with $r_1,\dots,r_n$ algebraically independent over $A$, we are done. Assume that there is some relation on the $r$'s: there is some $f(x_1,\dots,x_n)\in A[x_1,\dots,x_n]$ such that $f(r_1,\dots,r_n)=0$. By taking an $A$-algebra automorphism (changing our generators), we can assume that $f$ has leading term $a x_n^N$ (in terms of $x_n$) for some $a$. Then, $f$ is monic in $x_n$ after inverting $a$, so $R_a$ is module-finite over $A_a[r'_1,\dots,r'_{n-1}]$. By hypothesis, $A_{ab}[r'_1,\dots,r'_{n-1}]$ is module-finite over $A_{ab}[r''_1,\dots,r''_s]$ for some $b\in A$ and $r''_1,\dots,r''_s$ that are algebraically independent over $A$. Since $R_{ab}$ is module-finite over $A_{ab}[r'_1,\dots,r'_{n-1}]$, we are done.

%In the graded case, we use the graded part of the previous lemma.
\end{proof}


%\begin{remark} There also exist Noether normalizations for quotients of power series rings over fields: after a change of coordinates, one can rewrite any nonzero power series in $K\llbracket x_1,\dots, x_n \rrbracket$ as a series of the form $u (x_n^d + a_{d-1} x_n^{d-1} + \cdots + a_0)$  for a unit $u$ and $a_0,\dots,a_{d-1}\in K \llbracket x_1,\dots,x_{n-1}\rrbracket$. This is called \emph{Weierstrass preparation}. The proof of the Noether normalization theorem proceeds in essentially the same way. Thus, given $K\llbracket x_1,\dots, x_n \rrbracket / I$, we have some module-finite inclusion of another power series ring $K\llbracket z_1,\dots, z_d \rrbracket \subseteq K\llbracket x_1,\dots, x_n \rrbracket/I$.
%	\end{remark}
	
	
	

\begin{theorem} Let $R$ be a finitely generated domain over a field $K$. Let $K[z_1,\dots,z_d]$ be any Noether normalization for $R$. Then, for any maximal ideal $\m$ of $R$, the length of any saturated chain of primes from $0$ to $\m$ is $d$. In particular, the dimension of $R$ is $d$.
	
	The same holds in a quotient of a power series ring over a field.
	\end{theorem}
\begin{proof}
	We prove by induction on $d$ that for any finitely generated domain with a Noether normalization with $d$ algebraically independent elements, any saturated chain of primes ending in a maximal ideal has length $d$.
	
	When $d=0$, $R$ is a domain that is integral over a field, hence is a field, so the statement follows trivially.
	
	Pick a saturated chain
	\[ 0 \subsetneqq \q_1 \subsetneqq\cdots \subsetneqq  \q_k = \m \]
	and consider the contractions to $A=K[z_1,\dots,z_d]$:
		\[ 0 \subsetneqq \p_1 \subsetneqq\cdots \subsetneqq  \p_k. \]
	By the saturated condition, $\q_1$ has height 1, and so does $\p_1$, since we have a module-finite inclusion of a normal domain into a domain. Since $A$ is a UFD, $\p_1=(f)$ for some prime element $f$. After a change of variables, we can assume that $f$ is monic in $z_d$ over $K[z_1,\dots,z_{d-1}]$. Then,
	\[ 0 = \q_1/\q_1 \subsetneqq \q_2/\q_1 \subsetneqq \cdots\subsetneqq  \q_k/\q_1 =\m/\q_1 \]
	is a saturated chain in the affine domain $R/\q_1$ to the maximal ideal $\m/\q_1$. Now, $K[z_1,\dots,z_{d-1}] \subseteq A/(f) \subseteq R/\q_1$ are module-finite, and we can apply the induction hypothesis to say that the chain we found in $R/\q_1$ has length $d-1$, so $k-1=d-1$, and $k=d$.
	
	The same proof holds for quotients of power series rings.
\end{proof}

\begin{corollary} The dimension of the polynomial ring $K[x_1,\dots,x_d]$ is $d$.
\end{corollary}

\begin{corollary}
	If $R$ is a $K$-algebra, the dimension of $R$ is less than or equal to the minimal size of a generating set for $R$. If equality holds for some finite generating set, then $R$ is isomorphic to a polynomial ring over $K$, and the generators are algebraically independent.
	\end{corollary}
	\begin{proof}
	The first statement is trivial unless $R$ is finitely generated, in which case we can write $R=K[f_1,\dots,f_s] \cong K[x_1,\dots,x_s]/I$ for some ideal $I$. We have $\dim(R)\leq s$, for certain. If $I\neq 0$, then $\dim(R)< s$, since the zero ideal is not contained in $I$.
	\end{proof}


\begin{comment}	
\begin{corollary}
	Let $R$ be a finitely generated algebra oor a quotient of a power series ring over a field.
	\begin{itemize}
		\item $R$ is catenary.
\end{itemize}
If additionally $R$ is a domain, then
	\begin{itemize}
		\item $R$ is equidimensional, and
		\item $\htt(I)=\dim(R)-\dim(R/I)$ for all ideals $I$.
	\end{itemize}
\end{corollary}
\begin{proof}
	Let $\p\subseteq \q$ be primes in $R$. We can quotient out by $\p$, and assume that $R$ is a domain and $\p=0$. Fix a saturated chain $C$ from $\q$ to a maximal ideal $\m$. Given two saturated chains $C'$, $C''$ from $0$ to $\q$, the concatenations $C'|C$ and $C''|C$ are saturated chains from $0$ to $\m$, and hence must have the same length. It follows that $C'$ and $C''$ have the same length.
	
	Equidimensionality is clear from the theorem.
	
	We have $\htt(I)=\min\{\htt(\p) \ | \ \p\in \Min(I)\}$ and $\dim(R/I)=\max\{\dim(R/\p) \ | \ \p\in \Min(I)\}$. Thus, it suffices to show the equality for prime ideals. Now, take a saturated chain of primes $C$ from $0$ to $\p$, and a saturated chain $C'$ from $\p$ to a maximal ideal $\m$. $C$ has length $\htt(\p)$ by catenarity and definition of height, $C'$ has length $\dim(R/\p)$ by the theorem, and $C|C'$ has length $\dim(R)$ by the theorem.
\end{proof}


Recall that the \DEF{transcendence degree} of a field extension is the size of a transcendence basis.

\begin{corollary}
	If $R$ is a finitely generated domain over a field $K$, then $\dim(R) = \mathrm{trdeg}_K(\mathrm{frac}(R))$.
\end{corollary}
\begin{proof}
	If $R\subseteq S$ is module-finite, then $\mathrm{frac}(R)\subseteq \mathrm{frac}(S)$ is algebraic, and hence they have the same transcendence degree over $K$. In particular, if $A=K[z_1,\dots,z_d]$ is a Noether normalization for $R$, 
	\[\mathrm{trdeg}_K(\mathrm{frac}(R))= \mathrm{trdeg}_K(\mathrm{frac}(A)) = \mathrm{trdeg}_K(K(z_1,\dots,z_d)) = d = \dim(A) = \dim(R).\qedhere\]
\end{proof}

\begin{ex} Let us compute the dimension of the ring $R=\frac{K[a,b,c,d]}{(b^2-ac,c^2-bd,bc-ad)}$. We claim that $K[a,d]\subseteq R$ is a Noether normalization. The inclusion is integral, since $b^2=ac$ implies $b^4=a^2 c^2 = abd$, so $b$ satisfies $t^4 - ad t =0$; similarly with $c$. Alternatively, one can use the relations to take any polynomial expression in $a,b,c,d$ and reduce the $b,c$-degree to at most $1$; any two distinct expressions with $b,c$-degree at most 1 are not equivalent, so $R= K[a,d] \oplus b K[a,d] \olpus c K[a,d]$. In particular, $a,d$ are algebraically independent in $R$. We conclude that the dimension is two.

Also, there is an isomorphism $R\cong K[x^3,x^2 y, xy^2, y^3]$ (which can be verified with the help of the computation above). The latter expression makes clear that $R$ is a domain, and its fraction field is $K(x^3,x^2 y, xy^2, y^3) = K(x^3,y/x)$, which has transcendence degree two over $K$. We again see that the dimension is two.
\end{ex}

\end{comment}
\printindex































\end{document}







  
 


